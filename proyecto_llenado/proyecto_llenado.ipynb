{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a58ce4",
   "metadata": {},
   "source": [
    "# Proyecto 1 — Estación de llenado y taponado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3bd33",
   "metadata": {},
   "source": [
    "Importación de las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "6f4a8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d78916",
   "metadata": {},
   "source": [
    "Definir las rutas de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "49beaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "\n",
    "telemetria_file = data_path / \"telemetria.csv\"\n",
    "eventos_file = data_path / \"eventos.csv\"\n",
    "botellas_file = data_path / \"botellas.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba8245",
   "metadata": {},
   "source": [
    "# FASE 1 --->Ingesta y validación (Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c0a79",
   "metadata": {},
   "source": [
    "\n",
    "PASO 1: Carga y tipado de datos\n",
    "\n",
    "    1.1 Definir tipos de datos explícitos para cada CSV utilizando un diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "faa031ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_tel = {\n",
    "    'temp_prod': 'float32',\n",
    "    'vel_cinta': 'float32',\n",
    "    'caudal': 'float32',\n",
    "    'energia_kwh': 'float64'\n",
    "}\n",
    "\n",
    "dtype_evt = {\n",
    "    'tipo': 'category',\n",
    "    'id_botella': 'Int64'\n",
    "}\n",
    "\n",
    "dtype_pz = {\n",
    "    'id_botella': 'int64',\n",
    "    'peso_neto': 'float32',\n",
    "    'formato': 'category'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db836bc4",
   "metadata": {},
   "source": [
    "    1.2 Cargar los csv en los dataFrames parseando el tiempo a datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "0f12c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar telemetría con parseo de fecha\n",
    "df_tel = pd.read_csv(\n",
    "    telemetria_file,\n",
    "    dtype=dtype_tel,\n",
    "    parse_dates=['ts'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "# Convertir ts a UTC y establecer como índice\n",
    "df_tel['ts'] = pd.to_datetime(df_tel['ts'], utc=True) # Convierte a datetime con zona horaria UTC\n",
    "df_tel = df_tel.set_index('ts').sort_index() # Establece la columna de tiempo como índice del DataFrame\n",
    "\n",
    "# Cargar eventos\n",
    "df_evt = pd.read_csv(\n",
    "    eventos_file,\n",
    "    dtype=dtype_evt,\n",
    "    parse_dates=['ts_ini', 'ts_fin'],\n",
    "    date_format='ISO8601'\n",
    ") # Lee el CSV y convierte automáticamente las columnas de fecha\n",
    "df_evt['ts_ini'] = pd.to_datetime(df_evt['ts_ini'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt['ts_fin'] = pd.to_datetime(df_evt['ts_fin'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt = df_evt.sort_values('ts_ini').reset_index(drop=True)\n",
    "\n",
    "# Cargar botellas\n",
    "df_pz = pd.read_csv(\n",
    "    botellas_file,\n",
    "    dtype=dtype_pz,\n",
    "    parse_dates=['ts_ciclo'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "df_pz['ts_ciclo'] = pd.to_datetime(df_pz['ts_ciclo'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef66b8",
   "metadata": {},
   "source": [
    "PASO 2. Orden y duplicados\n",
    "\n",
    "    2.1 Telemetría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "84130e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemetria:\n",
      "Duplicados eliminados: 0\n",
      "Índice monótono: True\n",
      "No hay timestamps duplicados\n"
     ]
    }
   ],
   "source": [
    "print(\"Telemetria:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "duplicados_antes_tel = df_tel.duplicated().sum()\n",
    "df_tel = df_tel[~df_tel.duplicated(keep='first')]\n",
    "\n",
    "#df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Verificar monotonía del índice\n",
    "es_monotono_tel = df_tel.index.is_monotonic_increasing #Comprobacion de la monotonia: Los indices temporales avanzan correctamente de menor a mayor\n",
    "\n",
    "print(f\"Duplicados eliminados: {duplicados_antes_tel}\")\n",
    "print(f\"Índice monótono: {es_monotono_tel}\")\n",
    "\n",
    "# Verificar si hay duplicados en el índice temporal\n",
    "duplicados_index = df_tel.index.duplicated().sum()\n",
    "if duplicados_index > 0:\n",
    "    print(f\"Hay {duplicados_index} timestamps duplicados en el índice\")\n",
    "    df_tel = df_tel[~df_tel.index.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\"No hay timestamps duplicados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858598a8",
   "metadata": {},
   "source": [
    "    2.2 Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "7e0c877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventos:\n",
      "Duplicados eliminados: 0\n",
      "Orden por ts_ini monótono: True\n",
      "Eventos con ts_fin < ts_ini: 0\n",
      "Timestamps ts_ini duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Eventos:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "dup_evt = df_evt.duplicated().sum()\n",
    "df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por tiempo de inicio (y fin como desempate)\n",
    "df_evt = df_evt.sort_values(['ts_ini', 'ts_fin']).reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_evt = df_evt['ts_ini'].is_monotonic_increasing\n",
    "neg_dur = (df_evt['ts_fin'] < df_evt['ts_ini']).sum()\n",
    "dup_ts_ini = df_evt['ts_ini'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_evt}\")\n",
    "print(f\"Orden por ts_ini monótono: {es_monotono_evt}\")\n",
    "print(f\"Eventos con ts_fin < ts_ini: {neg_dur}\")\n",
    "print(f\"Timestamps ts_ini duplicados: {dup_ts_ini}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28764a4",
   "metadata": {},
   "source": [
    "    2.3 Botellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b9fc0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Botellas:\n",
      "Duplicados eliminados: 0\n",
      "Orden por ts_ciclo monótono: True\n",
      "Timestamps ts_ciclo duplicados: 0\n",
      "id_botella duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Botellas:\")\n",
    "dup_pz = df_pz.duplicated().sum()\n",
    "df_pz = df_pz[~df_pz.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por ts_ciclo\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_pz = df_pz['ts_ciclo'].is_monotonic_increasing\n",
    "dup_ts_ciclo = df_pz['ts_ciclo'].duplicated().sum()\n",
    "dup_id_botella = df_pz['id_botella'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_pz}\")\n",
    "print(f\"Orden por ts_ciclo monótono: {es_monotono_pz}\")\n",
    "print(f\"Timestamps ts_ciclo duplicados: {dup_ts_ciclo}\")\n",
    "print(f\"id_botella duplicados: {dup_id_botella}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0f7dd",
   "metadata": {},
   "source": [
    "PASO 3: Validaciones de rango\n",
    "\n",
    "    3.1 Marcar valores fuera de rango (sin eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "c35d8d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDACIÓN DE RANGOS\n",
      "============================================================\n",
      "temp_prod fuera de [18.0, 35.0] °C: 0 (0.00%)\n",
      "vel_cinta fuera de [0.0, 0.5] m/s: 0 (0.00%)\n",
      "caudal fuera de [0.0, 12.0] ml/s: 0 (0.00%)\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "           temp_prod      vel_cinta         caudal    energia_kwh\n",
      "count  129601.000000  129601.000000  129601.000000  129601.000000\n",
      "mean       25.646635       0.269995       7.735915      64.876601\n",
      "std         2.545803       0.092667       2.532649      37.845824\n",
      "min        18.000000       0.000000       0.000000       0.000000\n",
      "25%        23.802999       0.246000       7.443000      31.746546\n",
      "50%        25.648001       0.284000       8.321000      64.762093\n",
      "75%        27.365999       0.330000       9.101000      97.557688\n",
      "max        33.855000       0.380000      11.723000     130.067508\n"
     ]
    }
   ],
   "source": [
    "RANGO_TEMP = (18.0,35.0)\n",
    "RANGO_VEL = (0.0,0.5)\n",
    "RANGO_CAUDAL = (0.0,12.0)\n",
    "\n",
    "df_tel['fuera_RANGO_TEMP'] = (df_tel['temp_prod'] < RANGO_TEMP[0]) | (df_tel['temp_prod'] > RANGO_TEMP[1])\n",
    "df_tel['fuera_RANGO_VEL'] = (df_tel['vel_cinta'] < RANGO_VEL[0]) | (df_tel['vel_cinta'] > RANGO_VEL[1])\n",
    "df_tel['fuera_RANGO_CAUDAL'] = (df_tel['caudal'] < RANGO_CAUDAL[0]) | (df_tel['caudal'] > RANGO_CAUDAL[1])\n",
    "\n",
    "n_temp_fuera = df_tel['fuera_RANGO_TEMP'].sum()\n",
    "n_vel_fuera = df_tel['fuera_RANGO_VEL'].sum()\n",
    "n_caudal_fuera = df_tel['fuera_RANGO_CAUDAL'].sum()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE RANGOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"temp_prod fuera de [{RANGO_TEMP[0]}, {RANGO_TEMP[1]}] °C: {n_temp_fuera} ({n_temp_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"vel_cinta fuera de [{RANGO_VEL[0]}, {RANGO_VEL[1]}] m/s: {n_vel_fuera} ({n_vel_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"caudal fuera de [{RANGO_CAUDAL[0]}, {RANGO_CAUDAL[1]}] ml/s: {n_caudal_fuera} ({n_caudal_fuera/len(df_tel)*100:.2f}%)\")\n",
    "\n",
    "# Mostrar estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df_tel[['temp_prod', 'vel_cinta', 'caudal', 'energia_kwh']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3eeaf",
   "metadata": {},
   "source": [
    "    3.2 Validar que energia_kwh no decrece (salvo cuantización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "f3a121c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDACIÓN DE ENERGÍA NO DECRECIENTE\n",
      "============================================================\n",
      "Total de cambios: 129,600\n",
      "Decrementos detectados: 0 (0.000%)\n",
      "\n",
      " No se detectaron decrementos en energia_kwh\n"
     ]
    }
   ],
   "source": [
    "# Calcular diferencias entre valores consecutivos de energía\n",
    "df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "\n",
    "# Contar cuántas veces la energía DECRECE (delta < 0)\n",
    "# Nota: diff() genera NaN en la primera fila, lo ignoramos\n",
    "decrementos = (df_tel['delta_energia'] < 0).sum() \n",
    "total_cambios = df_tel['delta_energia'].notna().sum() #Va a contar cuantas veces decrece\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE ENERGÍA NO DECRECIENTE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de cambios: {total_cambios:,}\")\n",
    "print(f\"Decrementos detectados: {decrementos} ({decrementos/total_cambios*100:.3f}%)\")\n",
    "\n",
    "# Mostrar algunos ejemplos de decrementos (si existen)\n",
    "if decrementos > 0:\n",
    "    print(\"\\n Ejemplos de energía que decrece:\")\n",
    "    ejemplos_decremento = df_tel[df_tel['delta_energia'] < 0][['energia_kwh', 'delta_energia']].head(10)\n",
    "    print(ejemplos_decremento)\n",
    "    \n",
    "    # Estadísticas de los decrementos\n",
    "    print(\"\\n Estadísticas de los decrementos:\")\n",
    "    print(df_tel[df_tel['delta_energia'] < 0]['delta_energia'].describe())\n",
    "else:\n",
    "    print(\"\\n No se detectaron decrementos en energia_kwh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01bab0",
   "metadata": {},
   "source": [
    "PASO 4: Monotonicidad de energía (corrección de decrementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "23534c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se requieren correcciones en energia_kwh\n",
      "La señal es naturalmente monótona creciente\n",
      "\n",
      "Verificación final: 0 decrementos después de corrección\n"
     ]
    }
   ],
   "source": [
    "# PASO 4: Corregir decrementos de energía (si los hubiera)\n",
    "# Guardamos la columna original para comparación\n",
    "df_tel['energia_kwh_original'] = df_tel['energia_kwh'].copy()\n",
    "\n",
    "# Identificar decrementos\n",
    "decrementos_mask = df_tel['delta_energia'] < 0\n",
    "n_correcciones = decrementos_mask.sum()\n",
    "\n",
    "if n_correcciones > 0:\n",
    "    print(f\"Se encontraron {n_correcciones} decrementos. Corrigiendo...\")\n",
    "    \n",
    "    # Hacer clip de deltas negativos a 0\n",
    "    df_tel['delta_energia_corregida'] = df_tel['delta_energia'].clip(lower=0)\n",
    "    \n",
    "    # Reconstruir energía acumulada desde el primer valor\n",
    "    energia_inicial = df_tel['energia_kwh'].iloc[0]\n",
    "    df_tel['energia_kwh'] = energia_inicial + df_tel['delta_energia_corregida'].fillna(0).cumsum()\n",
    "    \n",
    "    # Recalcular delta_energia con valores corregidos\n",
    "    df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "    \n",
    "    print(f\"{n_correcciones} correcciones aplicadas\")\n",
    "else:\n",
    "    print(\"No se requieren correcciones en energia_kwh\")\n",
    "    print(\"La señal es naturalmente monótona creciente\")\n",
    "\n",
    "# Verificación final\n",
    "decrementos_final = (df_tel['delta_energia'] < 0).sum()\n",
    "print(f\"\\nVerificación final: {decrementos_final} decrementos después de corrección\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2d090",
   "metadata": {},
   "source": [
    "PASO 5: Frecuencia y huecos temporales\n",
    "\n",
    "    5.1 Confirmar frecuencia nominal de 1 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "873af9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISIS DE FRECUENCIA DE MUESTREO\n",
      "============================================================\n",
      "\n",
      "Muestras con intervalo de 1s: 129600/129600\n",
      "\n",
      "Huecos detectados (intervalos > 1s): 0\n",
      "El numero de huecos es: 0\n",
      "La frecuencia nominal es de 1 Hz. Todos los saltos son de un segundo\n",
      "No es necesario interpolar ni marcar segmentos invalidos\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Analizar la frecuencia de muestreo\n",
    "print(\"=\"*60)\n",
    "print(\"ANÁLISIS DE FRECUENCIA DE MUESTREO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular diferencias de tiempo entre muestras consecutivas\n",
    "time_diffs = df_tel.index.to_series().diff()\n",
    "\n",
    "# Contar muestras con intervalo de 1 segundo\n",
    "intervalo_1s = time_diffs == pd.Timedelta(seconds=1)\n",
    "n_1s = intervalo_1s.sum()\n",
    "total = len(time_diffs) - 1  # -1 porque el primer valor es NaN\n",
    "\n",
    "print(f\"\\nMuestras con intervalo de 1s: {n_1s}/{total}\")\n",
    "\n",
    "# Identificar huecos (intervalos > 1s)\n",
    "huecos = time_diffs[time_diffs > pd.Timedelta(seconds=1)]\n",
    "n_huecos = len(huecos)\n",
    "\n",
    "print(f\"\\nHuecos detectados (intervalos > 1s): {n_huecos}\")\n",
    "\n",
    "if n_huecos > 0:\n",
    "    print(f\"\\nEstadísticas de los huecos:\")\n",
    "    print(huecos.describe())\n",
    "    \n",
    "    # Clasificar huecos\n",
    "    huecos_pequenos = huecos[huecos <= pd.Timedelta(seconds=10)]\n",
    "    huecos_grandes = huecos[huecos > pd.Timedelta(seconds=10)]\n",
    "    \n",
    "    print(f\"\\nHuecos pequeños (≤10s): {len(huecos_pequenos)}\")\n",
    "    print(f\"Huecos grandes (>10s): {len(huecos_grandes)}\")\n",
    "else:\n",
    "    print(f\"El numero de huecos es: {n_huecos}\")\n",
    "    print(\"La frecuencia nominal es de 1 Hz. Todos los saltos son de un segundo\")\n",
    "    print(\"No es necesario interpolar ni marcar segmentos invalidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e235834",
   "metadata": {},
   "source": [
    "    5.2 Reindexar a rejilla de 1 segundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "01a14063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REINDEXACIÓN A REJILLA DE 1 SEGUNDO\n",
      "============================================================\n",
      "\n",
      "Rango temporal:\n",
      "   Inicio: 2025-02-12 08:00:00+00:00\n",
      "   Fin: 2025-02-13 20:00:00+00:00\n",
      "   Duración: 1 days 12:00:00\n",
      "\n",
      "Tamaño de los datos:\n",
      "   Muestras originales: 129,601\n",
      "   Rejilla de 1s: 129,601\n",
      "   Diferencia (huecos): 0\n",
      "\n",
      "DataFrame reindexado\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Reindexar a rejilla regular de 1 segundo\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REINDEXACIÓN A REJILLA DE 1 SEGUNDO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear rejilla temporal de 1s desde el primer al último timestamp\n",
    "ts_inicio = df_tel.index.min()\n",
    "ts_fin = df_tel.index.max()\n",
    "rejilla_1s = pd.date_range(start=ts_inicio, end=ts_fin, freq='1s')\n",
    "\n",
    "print(f\"\\nRango temporal:\")\n",
    "print(f\"   Inicio: {ts_inicio}\")\n",
    "print(f\"   Fin: {ts_fin}\")\n",
    "print(f\"   Duración: {ts_fin - ts_inicio}\")\n",
    "\n",
    "print(f\"\\nTamaño de los datos:\")\n",
    "print(f\"   Muestras originales: {len(df_tel):,}\")\n",
    "print(f\"   Rejilla de 1s: {len(rejilla_1s):,}\")\n",
    "print(f\"   Diferencia (huecos): {len(rejilla_1s) - len(df_tel):,}\")\n",
    "\n",
    "# Reindexar el DataFrame a la rejilla de 1s\n",
    "df_tel = df_tel.reindex(rejilla_1s)\n",
    "\n",
    "print(f\"\\nDataFrame reindexado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3405109",
   "metadata": {},
   "source": [
    "5.3 Rellenar huecos pequeños (≤10s) con interpolación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "359c9c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RELLENADO DE HUECOS PEQUEÑOS (≤10s)\n",
      "============================================================\n",
      "\n",
      "Bloques de NaN detectados:\n",
      "   Total de bloques: 0\n",
      "   Bloques ≤10s: 0 (se interpolarán)\n",
      "   Bloques >10s: 0 (se marcarán como inválidos)\n",
      "\n",
      "Interpolando temp_prod y caudal...\n",
      "Forward-fill en vel_cinta...\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Rellenar huecos ≤ 10s\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELLENADO DE HUECOS PEQUEÑOS (≤10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identificar bloques de NaN consecutivos\n",
    "df_tel['es_nan'] = df_tel['temp_prod'].isna()\n",
    "df_tel['bloque_nan'] = (df_tel['es_nan'] != df_tel['es_nan'].shift()).cumsum()\n",
    "\n",
    "# Calcular tamaño de cada bloque de NaN\n",
    "tamano_bloques = df_tel[df_tel['es_nan']].groupby('bloque_nan').size()\n",
    "\n",
    "# Clasificar bloques\n",
    "bloques_pequenos = tamano_bloques[tamano_bloques <= 10]\n",
    "bloques_grandes = tamano_bloques[tamano_bloques > 10]\n",
    "\n",
    "print(f\"\\nBloques de NaN detectados:\")\n",
    "print(f\"   Total de bloques: {len(tamano_bloques)}\")\n",
    "print(f\"   Bloques ≤10s: {len(bloques_pequenos)} (se interpolarán)\")\n",
    "print(f\"   Bloques >10s: {len(bloques_grandes)} (se marcarán como inválidos)\")\n",
    "\n",
    "# Crear máscara para huecos pequeños (≤10s)\n",
    "mask_huecos_pequenos = df_tel['bloque_nan'].isin(bloques_pequenos.index) & df_tel['es_nan']\n",
    "\n",
    "# Interpolación lineal para temp_prod y caudal en huecos pequeños\n",
    "print(f\"\\nInterpolando temp_prod y caudal...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'temp_prod'] = df_tel['temp_prod'].interpolate(method='linear', limit=10)\n",
    "df_tel.loc[mask_huecos_pequenos, 'caudal'] = df_tel['caudal'].interpolate(method='linear', limit=10)\n",
    "\n",
    "# Forward-fill para vel_cinta (propagar último valor válido)\n",
    "print(f\"Forward-fill en vel_cinta...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'vel_cinta'] = df_tel['vel_cinta'].ffill(limit=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c32aca",
   "metadata": {},
   "source": [
    "    5.4 Marcar huecos grandes (>10s) como inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "06242975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARCADO DE HUECOS GRANDES (>10s)\n",
      "============================================================\n",
      "\n",
      "Segmentos marcados como inválidos:\n",
      "   Total de segundos inválidos: 0\n",
      "   Porcentaje: 0.00%\n",
      "\n",
      "✅ Proceso de huecos completado\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Marcar huecos grandes como inválidos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MARCADO DE HUECOS GRANDES (>10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna para marcar segmentos inválidos\n",
    "mask_huecos_grandes = df_tel['bloque_nan'].isin(bloques_grandes.index) & df_tel['es_nan']\n",
    "df_tel['segmento_invalido'] = mask_huecos_grandes\n",
    "\n",
    "# Contar segundos marcados como inválidos\n",
    "n_invalidos = df_tel['segmento_invalido'].sum()\n",
    "total_segundos = len(df_tel)\n",
    "\n",
    "print(f\"\\nSegmentos marcados como inválidos:\")\n",
    "print(f\"   Total de segundos inválidos: {n_invalidos:,}\")\n",
    "print(f\"   Porcentaje: {n_invalidos/total_segundos*100:.2f}%\")\n",
    "\n",
    "if len(bloques_grandes) > 0:\n",
    "    print(f\"\\nDetalle de huecos grandes:\")\n",
    "    for i, (bloque_id, tamano) in enumerate(bloques_grandes.items(), 1):\n",
    "        inicio_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.min()\n",
    "        fin_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.max()\n",
    "        print(f\"   Hueco {i}: {tamano}s desde {inicio_hueco} hasta {fin_hueco}\")\n",
    "        if i >= 5:\n",
    "            print(f\"   ... y {len(bloques_grandes)-5} huecos más\")\n",
    "            break\n",
    "\n",
    "# Limpiar columnas auxiliares\n",
    "df_tel = df_tel.drop(columns=['es_nan', 'bloque_nan'])\n",
    "\n",
    "print(f\"\\n✅ Proceso de huecos completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e50ca",
   "metadata": {},
   "source": [
    "PASO 6: Detección de atípicos\n",
    "\n",
    "    6.1 Detección por z-score (umbral ±3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "ee0c9b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DETECCIÓN DE ATÍPICOS POR Z-SCORE\n",
      "============================================================\n",
      "\n",
      "Atípicos detectados (|z-score| > 3):\n",
      "   temp_prod: 43 (0.033%)\n",
      "   vel_cinta: 0 (0.000%)\n",
      "   caudal: 10833 (8.359%)\n",
      "\n",
      "Ejemplos de atípicos en temp_prod:\n",
      "                           temp_prod    z_temp\n",
      "2025-02-13 03:59:56+00:00       18.0 -3.003624\n",
      "2025-02-13 03:59:57+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:03+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:04+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:05+00:00       18.0 -3.003624\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Detección de atípicos por z-score\n",
    "print(\"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR Z-SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral estándar: valores con |z-score| > 3 son atípicos\n",
    "UMBRAL_Z = 3\n",
    "\n",
    "# Calcular z-score para cada variable\n",
    "# z-score = (valor - media) / desviación estándar\n",
    "df_tel['z_temp'] = (df_tel['temp_prod'] - df_tel['temp_prod'].mean()) / df_tel['temp_prod'].std()\n",
    "df_tel['z_vel'] = (df_tel['vel_cinta'] - df_tel['vel_cinta'].mean()) / df_tel['vel_cinta'].std()\n",
    "df_tel['z_caudal'] = (df_tel['caudal'] - df_tel['caudal'].mean()) / df_tel['caudal'].std()\n",
    "\n",
    "# Marcar atípicos (|z| > 3)\n",
    "df_tel['atipico_z_temp'] = df_tel['z_temp'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_vel'] = df_tel['z_vel'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_caudal'] = df_tel['z_caudal'].abs() > UMBRAL_Z\n",
    "\n",
    "# Contar atípicos detectados\n",
    "n_atip_temp = df_tel['atipico_z_temp'].sum()\n",
    "n_atip_vel = df_tel['atipico_z_vel'].sum()\n",
    "n_atip_caudal = df_tel['atipico_z_caudal'].sum()\n",
    "\n",
    "print(f\"\\nAtípicos detectados (|z-score| > {UMBRAL_Z}):\")\n",
    "print(f\"   temp_prod: {n_atip_temp} ({n_atip_temp/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   vel_cinta: {n_atip_vel} ({n_atip_vel/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   caudal: {n_atip_caudal} ({n_atip_caudal/len(df_tel)*100:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplos si existen\n",
    "if n_atip_temp > 0:\n",
    "    print(\"\\nEjemplos de atípicos en temp_prod:\")\n",
    "    print(df_tel[df_tel['atipico_z_temp']][['temp_prod', 'z_temp']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b40235",
   "metadata": {},
   "source": [
    "    6.2 Detección por IQR (rango intercuartílico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "5b2d62e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETECCIÓN DE ATÍPICOS POR IQR\n",
      "============================================================\n",
      "\n",
      "temp_prod:\n",
      "   Q1: 23.803\n",
      "   Q3: 27.366\n",
      "   IQR: 3.563\n",
      "   Límites: [18.458, 32.710]\n",
      "   Atípicos: 125 (0.096%)\n",
      "\n",
      "vel_cinta:\n",
      "   Q1: 0.246\n",
      "   Q3: 0.330\n",
      "   IQR: 0.084\n",
      "   Límites: [0.120, 0.456]\n",
      "   Atípicos: 10833 (8.359%)\n",
      "\n",
      "caudal:\n",
      "   Q1: 7.443\n",
      "   Q3: 9.101\n",
      "   IQR: 1.658\n",
      "   Límites: [4.956, 11.588]\n",
      "   Atípicos: 10834 (8.360%)\n"
     ]
    }
   ],
   "source": [
    "# 6.2 Detección de atípicos por IQR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR IQR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular cuartiles y rango intercuartílico (IQR)\n",
    "# IQR = Q3 - Q1\n",
    "# Límites: [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
    "\n",
    "for var in ['temp_prod', 'vel_cinta', 'caudal']:\n",
    "    Q1 = df_tel[var].quantile(0.25)\n",
    "    Q3 = df_tel[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Marcar atípicos\n",
    "    col_name = f'atipico_iqr_{var.split(\"_\")[0]}'  # atipico_iqr_temp, atipico_iqr_vel, atipico_iqr_caudal\n",
    "    df_tel[col_name] = (df_tel[var] < limite_inferior) | (df_tel[var] > limite_superior)\n",
    "    \n",
    "    n_atipicos = df_tel[col_name].sum()\n",
    "    \n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"   Q1: {Q1:.3f}\")\n",
    "    print(f\"   Q3: {Q3:.3f}\")\n",
    "    print(f\"   IQR: {IQR:.3f}\")\n",
    "    print(f\"   Límites: [{limite_inferior:.3f}, {limite_superior:.3f}]\")\n",
    "    print(f\"   Atípicos: {n_atipicos} ({n_atipicos/len(df_tel)*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad4f3e3",
   "metadata": {},
   "source": [
    "    6.3 Consolidar marcas de atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "362cd0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONSOLIDACIÓN DE ATÍPICOS\n",
      "============================================================\n",
      "\n",
      "Registros con al menos un valor atípico:\n",
      "   Total: 10,959\n",
      "   Porcentaje: 8.46%\n",
      "\n",
      "Comparación de métodos:\n",
      "   Z-score: 10,876\n",
      "   IQR: 10,959\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Consolidar detección de atípicos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONSOLIDACIÓN DE ATÍPICOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna que marca si hay algún atípico (OR lógico)\n",
    "# Un registro es atípico si al menos una variable lo es (por cualquier método)\n",
    "df_tel['es_atipico'] = (\n",
    "    df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal'] |\n",
    "    df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']\n",
    ")\n",
    "\n",
    "total_atipicos = df_tel['es_atipico'].sum()\n",
    "porcentaje = total_atipicos / len(df_tel) * 100\n",
    "\n",
    "print(f\"\\nRegistros con al menos un valor atípico:\")\n",
    "print(f\"   Total: {total_atipicos:,}\")\n",
    "print(f\"   Porcentaje: {porcentaje:.2f}%\")\n",
    "\n",
    "# Resumen por método\n",
    "print(f\"\\nComparación de métodos:\")\n",
    "print(f\"   Z-score: {(df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal']).sum():,}\")\n",
    "print(f\"   IQR: {(df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a92c2f",
   "metadata": {},
   "source": [
    "PASO 7: Etiqueta RUN/STOP por segundo\n",
    "\n",
    "    7.1 Construir máscara de paradas desde eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9bb9b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONSTRUCCIÓN DE MÁSCARA RUN/STOP\n",
      "============================================================\n",
      "\n",
      "Eventos de parada encontrados:\n",
      "   Total: 78\n",
      "   micro_parada: 71\n",
      "   cambio_formato: 5\n",
      "   limpieza: 2\n",
      "\n",
      "Segundos marcados como STOP por eventos: 10,755 (8.30%)\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Construir máscara STOP_evt desde eventos.csv\n",
    "print(\"=\"*60)\n",
    "print(\"CONSTRUCCIÓN DE MÁSCARA RUN/STOP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filtrar eventos que implican parada\n",
    "eventos_parada = df_evt[df_evt['tipo'].isin(['micro_parada', 'cambio_formato', 'limpieza'])].copy()\n",
    "\n",
    "print(f\"\\nEventos de parada encontrados:\")\n",
    "print(f\"   Total: {len(eventos_parada)}\")\n",
    "print(f\"   micro_parada: {(eventos_parada['tipo'] == 'micro_parada').sum()}\")\n",
    "print(f\"   cambio_formato: {(eventos_parada['tipo'] == 'cambio_formato').sum()}\")\n",
    "print(f\"   limpieza: {(eventos_parada['tipo'] == 'limpieza').sum()}\")\n",
    "\n",
    "# Inicializar columna STOP_evt en False (por defecto está en marcha)\n",
    "df_tel['STOP_evt'] = False\n",
    "\n",
    "# Marcar como True los segundos que caen en intervalos [ts_ini, ts_fin)\n",
    "for idx, evento in eventos_parada.iterrows():\n",
    "    mascara_tiempo = (df_tel.index >= evento['ts_ini']) & (df_tel.index < evento['ts_fin'])\n",
    "    df_tel.loc[mascara_tiempo, 'STOP_evt'] = True\n",
    "\n",
    "n_stop_evt = df_tel['STOP_evt'].sum()\n",
    "print(f\"\\nSegundos marcados como STOP por eventos: {n_stop_evt:,} ({n_stop_evt/len(df_tel)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9425947",
   "metadata": {},
   "source": [
    "7.2 Definir RUN basado en velocidad de cinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "119ee02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEFINICIÓN DE RUN_vel\n",
      "============================================================\n",
      "\n",
      "Umbral de velocidad: 0.05 m/s\n",
      "Segundos con RUN_vel=True: 118,768\n",
      "Segundos con RUN_vel=False: 10,833\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Definir RUN_vel basado en velocidad de cinta\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEFINICIÓN DE RUN_vel\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral de velocidad para considerar que la máquina está en marcha\n",
    "UMBRAL_VEL_RUN = 0.05  # m/s\n",
    "\n",
    "# RUN_vel = True si vel_cinta >= 0.05 m/s\n",
    "df_tel['RUN_vel'] = df_tel['vel_cinta'] >= UMBRAL_VEL_RUN\n",
    "\n",
    "n_run_vel = df_tel['RUN_vel'].sum()\n",
    "print(f\"\\nUmbral de velocidad: {UMBRAL_VEL_RUN} m/s\")\n",
    "print(f\"Segundos con RUN_vel=True: {n_run_vel:,}\")\n",
    "print(f\"Segundos con RUN_vel=False: {len(df_tel)-n_run_vel:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252d970",
   "metadata": {},
   "source": [
    "7.3 Combinar en estado final (RUN/STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a5def909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMBINACIÓN DE CONDICIONES\n",
      "============================================================\n",
      "\n",
      "Distribución de estados:\n",
      "   RUN: 118,768\n",
      "   STOP: 10,833\n",
      "\n",
      "Transiciones de estado detectadas: 151\n"
     ]
    }
   ],
   "source": [
    "# 7.3 Definir estado final: RUN si RUN_vel=True Y STOP_evt=False\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINACIÓN DE CONDICIONES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# estado = RUN si (RUN_vel AND NOT STOP_evt), STOP en otro caso\n",
    "df_tel['estado'] = 'STOP'\n",
    "df_tel.loc[df_tel['RUN_vel'] & ~df_tel['STOP_evt'], 'estado'] = 'RUN'\n",
    "\n",
    "# Convertir a tipo category para ahorrar memoria\n",
    "df_tel['estado'] = df_tel['estado'].astype('category')\n",
    "\n",
    "# Contar estados\n",
    "n_run = (df_tel['estado'] == 'RUN').sum()\n",
    "n_stop = (df_tel['estado'] == 'STOP').sum()\n",
    "\n",
    "print(f\"\\nDistribución de estados:\")\n",
    "print(f\"   RUN: {n_run:,}\")\n",
    "print(f\"   STOP: {n_stop:,}\")\n",
    "\n",
    "# Análisis de transiciones\n",
    "df_tel['cambio_estado'] = df_tel['estado'] != df_tel['estado'].shift()\n",
    "n_transiciones = df_tel['cambio_estado'].sum() - 1  # -1 para excluir el primer valor\n",
    "\n",
    "print(f\"\\nTransiciones de estado detectadas: {n_transiciones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c44588",
   "metadata": {},
   "source": [
    "PASO 8: Agregación a 1 minuto (diagnóstico temprano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "2c3ea154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGREGACIÓN A 1 MINUTO\n",
      "============================================================\n",
      "\n",
      "DataFrame agregado:\n",
      "   Registros originales (1s): 129,601\n",
      "   Registros agregados (1min): 2,161\n",
      "   Rango temporal: 2025-02-12 08:00:00+00:00 a 2025-02-13 20:00:00+00:00\n",
      "\n",
      "Columnas creadas:\n",
      "   - temp_mean\n",
      "   - temp_p95\n",
      "   - caudal_mean\n",
      "   - vel_cinta_mean\n",
      "   - energia_kwh\n",
      "   - segundos_stop\n",
      "   - pct_stop\n",
      "   - segundos_run\n",
      "   - pct_run\n",
      "   - delta_energia_min\n",
      "\n",
      "Estadísticas de disponibilidad:\n",
      "   Media % RUN por minuto: 91.65%\n",
      "   Media % STOP por minuto: 8.35%\n",
      "   Minutos con 100% RUN: 1910 (88.39%)\n",
      "   Minutos con 100% STOP: 120 (5.55%)\n",
      "\n",
      "Primeros registros:\n",
      "                           temp_mean  temp_p95  caudal_mean  vel_cinta_mean  \\\n",
      "2025-02-12 08:00:00+00:00  24.997999    25.672          0.0             0.0   \n",
      "2025-02-12 08:01:00+00:00  24.575001    24.756          0.0             0.0   \n",
      "2025-02-12 08:02:00+00:00  24.604000    24.876          0.0             0.0   \n",
      "2025-02-12 08:03:00+00:00  25.184000    25.523          0.0             0.0   \n",
      "2025-02-12 08:04:00+00:00  25.219000    25.513          0.0             0.0   \n",
      "\n",
      "                           energia_kwh  segundos_stop  pct_stop  segundos_run  \\\n",
      "2025-02-12 08:00:00+00:00        0.018             60     100.0             0   \n",
      "2025-02-12 08:01:00+00:00        0.038             60     100.0             0   \n",
      "2025-02-12 08:02:00+00:00        0.057             60     100.0             0   \n",
      "2025-02-12 08:03:00+00:00        0.076             60     100.0             0   \n",
      "2025-02-12 08:04:00+00:00        0.096             60     100.0             0   \n",
      "\n",
      "                           pct_run  delta_energia_min  \n",
      "2025-02-12 08:00:00+00:00      0.0                NaN  \n",
      "2025-02-12 08:01:00+00:00      0.0              0.020  \n",
      "2025-02-12 08:02:00+00:00      0.0              0.019  \n",
      "2025-02-12 08:03:00+00:00      0.0              0.019  \n",
      "2025-02-12 08:04:00+00:00      0.0              0.020  \n"
     ]
    }
   ],
   "source": [
    "# PASO 8: Agregación temporal a 1 minuto\n",
    "print(\"=\"*60)\n",
    "print(\"AGREGACIÓN A 1 MINUTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear agregaciones por minuto\n",
    "df_1min = df_tel.resample('1min').agg({\n",
    "    'temp_prod': ['mean', lambda x: x.quantile(0.95)],\n",
    "    'caudal': 'mean',\n",
    "    'vel_cinta': 'mean',\n",
    "    'energia_kwh': 'last',  # Último valor del minuto (acumulado)\n",
    "    'estado': lambda x: (x == 'STOP').sum()  # Contar segundos en STOP\n",
    "}).round(3)\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_1min.columns = ['temp_mean', 'temp_p95', 'caudal_mean', 'vel_cinta_mean', 'energia_kwh', 'segundos_stop']\n",
    "\n",
    "# Calcular métricas derivadas\n",
    "df_1min['pct_stop'] = (df_1min['segundos_stop'] / 60 * 100).round(2)\n",
    "df_1min['segundos_run'] = 60 - df_1min['segundos_stop']\n",
    "df_1min['pct_run'] = (df_1min['segundos_run'] / 60 * 100).round(2)\n",
    "\n",
    "# Calcular delta de energía por minuto\n",
    "df_1min['delta_energia_min'] = df_1min['energia_kwh'].diff()\n",
    "\n",
    "# Información del resultado\n",
    "print(f\"\\nDataFrame agregado:\")\n",
    "print(f\"   Registros originales (1s): {len(df_tel):,}\")\n",
    "print(f\"   Registros agregados (1min): {len(df_1min):,}\")\n",
    "print(f\"   Rango temporal: {df_1min.index.min()} a {df_1min.index.max()}\")\n",
    "\n",
    "print(f\"\\nColumnas creadas:\")\n",
    "for col in df_1min.columns:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(f\"\\nEstadísticas de disponibilidad:\")\n",
    "print(f\"   Media % RUN por minuto: {df_1min['pct_run'].mean():.2f}%\")\n",
    "print(f\"   Media % STOP por minuto: {df_1min['pct_stop'].mean():.2f}%\")\n",
    "print(f\"   Minutos con 100% RUN: {(df_1min['pct_run'] == 100).sum()} ({(df_1min['pct_run'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "print(f\"   Minutos con 100% STOP: {(df_1min['pct_stop'] == 100).sum()} ({(df_1min['pct_stop'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "print(df_1min.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7288176",
   "metadata": {},
   "source": [
    "# FASE 2: Ingeniería de variables y KPIs (NumPy + Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ba5c6",
   "metadata": {},
   "source": [
    "PASO 1: Cálculo de potencia instantánea desde energía acumulada\n",
    "\n",
    "    Fórmula: P_kW = ΔE / Δt (donde Δt está en horas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ef3fe",
   "metadata": {},
   "source": [
    "### Fórmulas implementadas\n",
    "\n",
    "**Cálculo de potencia instantánea:**\n",
    "\n",
    "$$\\Delta E_i = \\max\\{E_i - E_{i-1}, 0\\}$$\n",
    "\n",
    "$$\\Delta t_i = \\frac{t_i - t_{i-1}}{3600} \\text{ (horas)}$$\n",
    "\n",
    "$$P_{\\text{kW},i} = \\frac{\\Delta E_i}{\\Delta t_i}$$\n",
    "\n",
    "$$P_{\\text{W},i} = 1000 \\cdot P_{\\text{kW},i}$$\n",
    "\n",
    "**Suavizado opcional (media móvil):**\n",
    "- Ventana: 5 segundos (centrada)\n",
    "- Objetivo: Mitigar efectos de cuantización del contador de energía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "31d17c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CÁLCULO DE POTENCIA INSTANTÁNEA\n",
      "============================================================\n",
      "\n",
      "Primeros 10 valores calculados:\n",
      "                           energia_kwh  delta_energia  delta_tiempo_h    P_kW  \\\n",
      "2025-02-12 08:00:00+00:00     0.000000            NaN             NaN  0.0000   \n",
      "2025-02-12 08:00:01+00:00     0.000336       0.000336        0.000278  1.2096   \n",
      "2025-02-12 08:00:02+00:00     0.000625       0.000289        0.000278  1.0404   \n",
      "2025-02-12 08:00:03+00:00     0.000943       0.000318        0.000278  1.1448   \n",
      "2025-02-12 08:00:04+00:00     0.001175       0.000232        0.000278  0.8352   \n",
      "2025-02-12 08:00:05+00:00     0.001420       0.000245        0.000278  0.8820   \n",
      "2025-02-12 08:00:06+00:00     0.001709       0.000289        0.000278  1.0404   \n",
      "2025-02-12 08:00:07+00:00     0.002075       0.000366        0.000278  1.3176   \n",
      "2025-02-12 08:00:08+00:00     0.002328       0.000253        0.000278  0.9108   \n",
      "2025-02-12 08:00:09+00:00     0.002617       0.000289        0.000278  1.0404   \n",
      "\n",
      "                           P_kW_suavizada  \n",
      "2025-02-12 08:00:00+00:00         0.75000  \n",
      "2025-02-12 08:00:01+00:00         0.84870  \n",
      "2025-02-12 08:00:02+00:00         0.84600  \n",
      "2025-02-12 08:00:03+00:00         1.02240  \n",
      "2025-02-12 08:00:04+00:00         0.98856  \n",
      "2025-02-12 08:00:05+00:00         1.04400  \n",
      "2025-02-12 08:00:06+00:00         0.99720  \n",
      "2025-02-12 08:00:07+00:00         1.03824  \n",
      "2025-02-12 08:00:08+00:00         1.15416  \n",
      "2025-02-12 08:00:09+00:00         1.24200  \n",
      "\n",
      "✅ Potencia instantánea calculada\n"
     ]
    }
   ],
   "source": [
    "# PASO 9: Calcular potencia instantánea\n",
    "print(\"=\"*60)\n",
    "print(\"CÁLCULO DE POTENCIA INSTANTÁNEA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular delta de energía (ya lo teníamos del Paso 4)\n",
    "# df_tel['delta_energia'] ya existe\n",
    "\n",
    "# Calcular delta de tiempo en horas\n",
    "df_tel['delta_tiempo_h'] = df_tel.index.to_series().diff().dt.total_seconds() / 3600\n",
    "\n",
    "# Calcular potencia en kW: P = ΔE / Δt\n",
    "# Evitar división por cero\n",
    "df_tel['P_kW'] = np.where(\n",
    "    df_tel['delta_tiempo_h'] > 0,\n",
    "    df_tel['delta_energia'] / df_tel['delta_tiempo_h'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Suavizar potencia con media móvil de 5 segundos para mitigar cuantización\n",
    "df_tel['P_kW_suavizada'] = df_tel['P_kW'].rolling(window=5, center=True, min_periods=1).mean()\n",
    "\n",
    "# Mostrar resultados de las fórmulas aplicadas\n",
    "print(\"\\nPrimeros 10 valores calculados:\")\n",
    "print(df_tel[['energia_kwh', 'delta_energia', 'delta_tiempo_h', 'P_kW', 'P_kW_suavizada']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Potencia instantánea calculada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d904d0",
   "metadata": {},
   "source": [
    "PASO 2: Agregación a 1 minuto (telemetría)\n",
    "\n",
    "### Fórmulas de agregación\n",
    "\n",
    "Para cada minuto $m$:\n",
    "\n",
    "$$\\text{temp\\_mean}(m) = \\text{mean}(T)$$\n",
    "\n",
    "$$\\text{temp\\_p95}(m) = \\text{p95}(T)$$\n",
    "\n",
    "$$\\text{caudal\\_mean}(m) = \\text{mean}(q)$$\n",
    "\n",
    "$$\\text{P\\_kW\\_mean}(m) = \\text{mean}(P)$$\n",
    "\n",
    "$$\\%\\text{STOP}(m) = 100 \\cdot \\frac{\\#\\{i \\in m : \\text{estado}_i = \\text{STOP}\\}}{60}$$\n",
    "\n",
    "Estas series minuto servirán como base para KPIs horarios/por turno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e596a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGREGACIÓN A 1 MINUTO (TELEMETRÍA)\n",
      "============================================================\n",
      "\n",
      "Primeros registros:\n",
      "                           temp_mean  temp_p95  caudal_mean  P_kW_mean  \\\n",
      "2025-02-12 08:00:00+00:00  24.997999    25.672        0.000      1.104   \n",
      "2025-02-12 08:01:00+00:00  24.575001    24.756        0.000      1.155   \n",
      "2025-02-12 08:02:00+00:00  24.604000    24.876        0.000      1.141   \n",
      "2025-02-12 08:03:00+00:00  25.184000    25.523        0.000      1.167   \n",
      "2025-02-12 08:04:00+00:00  25.219000    25.513        0.000      1.208   \n",
      "2025-02-12 08:05:00+00:00  25.625000    25.908        0.000      1.118   \n",
      "2025-02-12 08:06:00+00:00  25.892000    26.101        0.000      1.199   \n",
      "2025-02-12 08:07:00+00:00  26.014999    26.525        0.000      1.208   \n",
      "2025-02-12 08:08:00+00:00  25.455000    25.874        8.709      3.881   \n",
      "2025-02-12 08:09:00+00:00  24.711000    24.880        9.011      3.837   \n",
      "\n",
      "                           segundos_stop  pct_STOP  \n",
      "2025-02-12 08:00:00+00:00             60    100.00  \n",
      "2025-02-12 08:01:00+00:00             60    100.00  \n",
      "2025-02-12 08:02:00+00:00             60    100.00  \n",
      "2025-02-12 08:03:00+00:00             60    100.00  \n",
      "2025-02-12 08:04:00+00:00             60    100.00  \n",
      "2025-02-12 08:05:00+00:00             60    100.00  \n",
      "2025-02-12 08:06:00+00:00             60    100.00  \n",
      "2025-02-12 08:07:00+00:00             60    100.00  \n",
      "2025-02-12 08:08:00+00:00              1      1.67  \n",
      "2025-02-12 08:09:00+00:00              0      0.00  \n",
      "\n",
      "✅ Agregación a 1 minuto completada\n"
     ]
    }
   ],
   "source": [
    "# PASO 10: Agregación a 1 minuto (telemetría)\n",
    "print(\"=\"*60)\n",
    "print(\"AGREGACIÓN A 1 MINUTO (TELEMETRÍA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear agregaciones por minuto aplicando las fórmulas\n",
    "df_1min = df_tel.resample('1min').agg({\n",
    "    'temp_prod': ['mean', lambda x: x.quantile(0.95)],\n",
    "    'caudal': 'mean',\n",
    "    'P_kW': 'mean',\n",
    "    'estado': lambda x: (x == 'STOP').sum()\n",
    "}).round(3)\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_1min.columns = ['temp_mean', 'temp_p95', 'caudal_mean', 'P_kW_mean', 'segundos_stop']\n",
    "\n",
    "# Calcular %STOP\n",
    "df_1min['pct_STOP'] = ((df_1min['segundos_stop'] / 60) * 100).round(2)\n",
    "\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "print(df_1min.head(10))\n",
    "\n",
    "print(f\"\\n✅ Agregación a 1 minuto completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d84efa6",
   "metadata": {},
   "source": [
    "PASO 3: Clasificación de botellas por tolerancia de peso\n",
    "\n",
    "### Objetivo de masa por formato\n",
    "\n",
    "$$m_{\\text{obj}}(250) = 250\\text{ g}, \\quad m_{\\text{obj}}(500) = 500\\text{ g}$$\n",
    "\n",
    "### Criterio de tolerancia\n",
    "\n",
    "Con tolerancia típica del ±2%, una unidad está dentro de tolerancia si:\n",
    "\n",
    "$$|\\text{peso\\_lleno\\_g} - m_{\\text{obj}}(f)| \\leq 0.02 \\cdot m_{\\text{obj}}(f)$$\n",
    "\n",
    "Donde:\n",
    "- $\\text{peso\\_lleno\\_g}$ es el peso neto de la botella (en gramos)\n",
    "- $f$ es el formato (250 o 500)\n",
    "- $m_{\\text{obj}}(f)$ es la masa objetivo según el formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f07e7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\n",
      "============================================================\n",
      "\n",
      "Primeros registros clasificados:\n",
      "   id_botella  formato_ml  peso_lleno_g  masa_objetivo  desviacion_abs  \\\n",
      "0           1         500        499.69          500.0            0.31   \n",
      "1           2         500        498.71          500.0            1.29   \n",
      "2           3         500        501.08          500.0            1.08   \n",
      "3           4         500        503.04          500.0            3.04   \n",
      "4           5         500        498.84          500.0            1.16   \n",
      "5           6         500        495.89          500.0            4.11   \n",
      "6           7         500        499.17          500.0            0.83   \n",
      "7           8         500        502.65          500.0            2.65   \n",
      "8           9         500        503.23          500.0            3.23   \n",
      "9          10         500        497.43          500.0            2.57   \n",
      "\n",
      "   dentro_tolerancia  \n",
      "0               True  \n",
      "1               True  \n",
      "2               True  \n",
      "3               True  \n",
      "4               True  \n",
      "5               True  \n",
      "6               True  \n",
      "7               True  \n",
      "8               True  \n",
      "9               True  \n",
      "\n",
      "✅ Clasificación completada\n"
     ]
    }
   ],
   "source": [
    "# PASO 11: Clasificación de botellas por tolerancia de peso\n",
    "print(\"=\"*60)\n",
    "print(\"CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir masa objetivo según formato\n",
    "MASA_OBJ = {250: 250.0, 500: 500.0}\n",
    "TOLERANCIA = 0.02  # ±2%\n",
    "\n",
    "# Crear columna con masa objetivo según el formato de cada botella\n",
    "df_pz['masa_objetivo'] = df_pz['formato_ml'].map(MASA_OBJ)\n",
    "\n",
    "# Calcular desviación absoluta respecto al objetivo\n",
    "df_pz['desviacion_abs'] = np.abs(df_pz['peso_lleno_g'] - df_pz['masa_objetivo'])\n",
    "\n",
    "# Calcular límite de tolerancia (2% de la masa objetivo)\n",
    "df_pz['limite_tolerancia'] = TOLERANCIA * df_pz['masa_objetivo']\n",
    "\n",
    "# Clasificar: dentro_tolerancia = True si |peso_neto - m_obj| ≤ 0.02 * m_obj\n",
    "df_pz['dentro_tolerancia'] = df_pz['desviacion_abs'] <= df_pz['limite_tolerancia']\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"\\nPrimeros registros clasificados:\")\n",
    "print(df_pz[['id_botella', 'formato_ml', 'peso_lleno_g', 'masa_objetivo', 'desviacion_abs', 'dentro_tolerancia']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Clasificación completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4796f2",
   "metadata": {},
   "source": [
    "PASO 4: KPIs por hora y por turno\n",
    "\n",
    "### Definiciones de KPIs\n",
    "\n",
    "Sea $W$ la ventana temporal (hora o turno). Los KPIs se calculan como:\n",
    "\n",
    "#### 1. Throughput (unidades/hora)\n",
    "$$\\text{Throughput}(W) = \\frac{N_W}{\\text{horas}(W)}$$\n",
    "\n",
    "Donde $N_W$ es el número total de botellas producidas en la ventana $W$.\n",
    "\n",
    "#### 2. Scrap (% no conforme)\n",
    "$$\\text{Scrap}(W) = 100 \\cdot \\frac{NG_W}{OK_W + NG_W} \\quad \\text{(si } N_W > 0\\text{; en otro caso NaN)}$$\n",
    "\n",
    "Donde:\n",
    "- $NG_W$ = botellas no conformes (fuera de tolerancia)\n",
    "- $OK_W$ = botellas conformes (dentro de tolerancia)\n",
    "\n",
    "#### 3. Tiempo en marcha (horas)\n",
    "$$\\text{Tiempo en marcha}(W) = t_{\\text{RUN}}(W)$$\n",
    "\n",
    "Suma de las horas en estado RUN durante la ventana $W$.\n",
    "\n",
    "#### 4. Energía específica (Wh/unidad)\n",
    "$$\\text{Wh/ud}(W) = \\frac{1000 \\cdot \\Delta E_{\\text{kWh}}(W)}{N_W} \\quad \\text{(si } N_W > 0\\text{; en otro caso NaN)}$$\n",
    "\n",
    "Donde $\\Delta E_{\\text{kWh}}(W)$ es el incremento de energía durante la ventana $W$.\n",
    "\n",
    "#### 5. % dentro de tolerancia\n",
    "$$\\%\\text{Tol}(W) = 100 \\cdot \\frac{\\#\\{\\text{unidades en tolerancia}\\}}{N_W} \\quad \\text{(si } N_W > 0\\text{)}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Ventanas temporales\n",
    "\n",
    "- **Por hora**: Agregación con `resample('1h')`\n",
    "- **Por turno**: Definir turnos (ej: 06:00-14:00, 14:00-22:00, 22:00-06:00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "998aec62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CÁLCULO DE KPIs POR HORA Y POR TURNO\n",
      "============================================================\n",
      "\n",
      "--- KPIs POR HORA ---\n",
      "\n",
      "KPIs por hora calculados: 37 horas\n",
      "\n",
      "Primeras horas:\n",
      "                           N_botellas  throughput_ud_h  scrap_pct  horas_RUN  \\\n",
      "2025-02-12 08:00:00+00:00      1039.0           1039.0       0.96       0.87   \n",
      "2025-02-12 09:00:00+00:00      1165.0           1165.0       1.12       0.97   \n",
      "2025-02-12 10:00:00+00:00      1066.0           1066.0       0.66       0.89   \n",
      "2025-02-12 11:00:00+00:00       771.0            771.0       1.82       0.64   \n",
      "2025-02-12 12:00:00+00:00      1036.0           1036.0       0.68       0.86   \n",
      "2025-02-12 13:00:00+00:00      1129.0           1129.0       1.33       0.94   \n",
      "2025-02-12 14:00:00+00:00      1169.0           1169.0       1.54       0.97   \n",
      "2025-02-12 15:00:00+00:00      1302.0           1302.0       1.61       0.78   \n",
      "2025-02-12 16:00:00+00:00      1720.0           1720.0       1.05       0.96   \n",
      "2025-02-12 17:00:00+00:00      1746.0           1746.0       1.49       0.97   \n",
      "\n",
      "                           energia_Wh_ud  pct_tolerancia  \n",
      "2025-02-12 08:00:00+00:00           3.41           99.04  \n",
      "2025-02-12 09:00:00+00:00           3.20           98.88  \n",
      "2025-02-12 10:00:00+00:00           3.31           99.34  \n",
      "2025-02-12 11:00:00+00:00           3.77           98.18  \n",
      "2025-02-12 12:00:00+00:00           3.44           99.32  \n",
      "2025-02-12 13:00:00+00:00           3.32           98.67  \n",
      "2025-02-12 14:00:00+00:00           3.21           98.46  \n",
      "2025-02-12 15:00:00+00:00           2.51           98.39  \n",
      "2025-02-12 16:00:00+00:00           2.15           98.95  \n",
      "2025-02-12 17:00:00+00:00           2.13           98.51  \n",
      "\n",
      "============================================================\n",
      "--- KPIs POR TURNO ---\n",
      "\n",
      "KPIs por turno calculados: 6 turnos\n",
      "\n",
      "Primeros turnos:\n",
      "                      N_botellas  throughput_ud_h  scrap_pct  horas_RUN  \\\n",
      "fecha      turno                                                          \n",
      "2025-02-12 T1_Mañana        6206           775.75       1.06       5.17   \n",
      "           T2_Tarde        12780          1597.50       1.24       7.48   \n",
      "           T3_Noche         2676           334.50       1.46       1.76   \n",
      "2025-02-13 T1_Mañana       12318          1539.75       1.30       7.47   \n",
      "           T2_Tarde         7193           899.12       1.60       5.29   \n",
      "           T3_Noche         6976           872.00       1.26       5.81   \n",
      "\n",
      "                      energia_Wh_ud  pct_tolerancia  \n",
      "fecha      turno                                     \n",
      "2025-02-12 T1_Mañana           3.39           98.94  \n",
      "           T2_Tarde            2.29           98.76  \n",
      "           T3_Noche            2.60           98.54  \n",
      "2025-02-13 T1_Mañana           2.37           98.70  \n",
      "           T2_Tarde            2.96           98.40  \n",
      "           T3_Noche            3.20           98.74  \n",
      "\n",
      "✅ KPIs por hora y turno calculados correctamente\n"
     ]
    }
   ],
   "source": [
    "# PASO 4: KPIs por hora y por turno\n",
    "print(\"=\"*60)\n",
    "print(\"CÁLCULO DE KPIs POR HORA Y POR TURNO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE A: KPIs POR HORA\n",
    "# ============================================================================\n",
    "print(\"\\n--- KPIs POR HORA ---\")\n",
    "\n",
    "# 1. Preparar df_pz con índice temporal\n",
    "df_pz_idx = df_pz.set_index('ts_ciclo')\n",
    "\n",
    "# 2. Agregar botellas por hora\n",
    "kpis_hora_pz = df_pz_idx.resample('1h').agg({\n",
    "    'id_botella': 'count',  # N_W: Total de botellas\n",
    "    'dentro_tolerancia': ['sum', lambda x: (~x).sum()]  # OK y NG\n",
    "})\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "kpis_hora_pz.columns = ['N_botellas', 'OK', 'NG']\n",
    "\n",
    "# 3. Agregar telemetría por hora\n",
    "kpis_hora_tel = df_tel.resample('1h').agg({\n",
    "    'estado': lambda x: (x == 'RUN').sum() / 3600,  # Tiempo en RUN (horas)\n",
    "    'energia_kwh': ['first', 'last']  # Energía inicial y final\n",
    "})\n",
    "\n",
    "kpis_hora_tel.columns = ['horas_RUN', 'energia_ini', 'energia_fin']\n",
    "kpis_hora_tel['delta_energia_kWh'] = kpis_hora_tel['energia_fin'] - kpis_hora_tel['energia_ini']\n",
    "\n",
    "# 4. Combinar ambos DataFrames\n",
    "kpis_hora = pd.concat([kpis_hora_pz, kpis_hora_tel], axis=1)\n",
    "\n",
    "# 5. Calcular KPIs\n",
    "kpis_hora['throughput_ud_h'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    kpis_hora['N_botellas'] / 1.0,  # Dividir por 1 hora\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_hora['scrap_pct'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    100 * kpis_hora['NG'] / kpis_hora['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_hora['energia_Wh_ud'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    1000 * kpis_hora['delta_energia_kWh'] / kpis_hora['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_hora['pct_tolerancia'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    100 * kpis_hora['OK'] / kpis_hora['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Redondear\n",
    "kpis_hora = kpis_hora.round(2)\n",
    "\n",
    "print(f\"\\nKPIs por hora calculados: {len(kpis_hora)} horas\")\n",
    "print(f\"\\nPrimeras horas:\")\n",
    "print(kpis_hora[['N_botellas', 'throughput_ud_h', 'scrap_pct', 'horas_RUN', 'energia_Wh_ud', 'pct_tolerancia']].head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE B: KPIs POR TURNO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- KPIs POR TURNO ---\")\n",
    "\n",
    "# Definir turnos (ejemplo: 06:00-14:00, 14:00-22:00, 22:00-06:00)\n",
    "def asignar_turno(hora):\n",
    "    if 6 <= hora < 14:\n",
    "        return 'T1_Mañana'\n",
    "    elif 14 <= hora < 22:\n",
    "        return 'T2_Tarde'\n",
    "    else:\n",
    "        return 'T3_Noche'\n",
    "\n",
    "# Asignar turno a cada botella\n",
    "df_pz['turno'] = df_pz['ts_ciclo'].dt.hour.apply(asignar_turno)\n",
    "df_pz['fecha'] = df_pz['ts_ciclo'].dt.date\n",
    "\n",
    "# Asignar turno a telemetría\n",
    "df_tel['turno'] = df_tel.index.hour.map(asignar_turno)\n",
    "df_tel['fecha'] = df_tel.index.date\n",
    "\n",
    "# Agregar por fecha y turno (botellas)\n",
    "kpis_turno_pz = df_pz.groupby(['fecha', 'turno']).agg({\n",
    "    'id_botella': 'count',\n",
    "    'dentro_tolerancia': ['sum', lambda x: (~x).sum()]\n",
    "})\n",
    "\n",
    "kpis_turno_pz.columns = ['N_botellas', 'OK', 'NG']\n",
    "\n",
    "# Agregar por fecha y turno (telemetría)\n",
    "kpis_turno_tel = df_tel.groupby(['fecha', 'turno']).agg({\n",
    "    'estado': lambda x: (x == 'RUN').sum() / 3600,\n",
    "    'energia_kwh': ['first', 'last']\n",
    "})\n",
    "\n",
    "kpis_turno_tel.columns = ['horas_RUN', 'energia_ini', 'energia_fin']\n",
    "kpis_turno_tel['delta_energia_kWh'] = kpis_turno_tel['energia_fin'] - kpis_turno_tel['energia_ini']\n",
    "\n",
    "# Combinar\n",
    "kpis_turno = pd.concat([kpis_turno_pz, kpis_turno_tel], axis=1)\n",
    "\n",
    "# Calcular KPIs por turno (8 horas por turno)\n",
    "kpis_turno['throughput_ud_h'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    kpis_turno['N_botellas'] / 8.0,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_turno['scrap_pct'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    100 * kpis_turno['NG'] / kpis_turno['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_turno['energia_Wh_ud'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    1000 * kpis_turno['delta_energia_kWh'] / kpis_turno['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_turno['pct_tolerancia'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    100 * kpis_turno['OK'] / kpis_turno['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Redondear\n",
    "kpis_turno = kpis_turno.round(2)\n",
    "\n",
    "print(f\"\\nKPIs por turno calculados: {len(kpis_turno)} turnos\")\n",
    "print(f\"\\nPrimeros turnos:\")\n",
    "print(kpis_turno[['N_botellas', 'throughput_ud_h', 'scrap_pct', 'horas_RUN', 'energia_Wh_ud', 'pct_tolerancia']].head(10))\n",
    "\n",
    "print(f\"\\n✅ KPIs por hora y turno calculados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd8a5a8",
   "metadata": {},
   "source": [
    "PASO 5: Cálculo del OEE - Opción A (Por tiempos y ciclo nominal)\n",
    "\n",
    "### Fórmula del OEE\n",
    "\n",
    "$$\\text{OEE}(W) = \\text{Availability}(W) \\times \\text{Performance}(W) \\times \\text{Quality}(W)$$\n",
    "\n",
    "---\n",
    "\n",
    "### Componentes del OEE\n",
    "\n",
    "#### 1. Availability (Disponibilidad)\n",
    "\n",
    "$$\\text{Availability}(W) = \\frac{t_{\\text{RUN}}(W)}{t_{\\text{plan}}(W)}$$\n",
    "\n",
    "**Interpretación:** Proporción del tiempo planificado que la máquina estuvo en marcha.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Performance (Rendimiento)\n",
    "\n",
    "$$\\text{Performance}(W) \\approx \\frac{t_{\\text{nom}}(W)}{t_{\\text{medio\\_RUN}}(W)}$$\n",
    "\n",
    "Donde:\n",
    "- $t_{\\text{nom}}(W)$ = tiempo de ciclo nominal ponderado por formato en $W$\n",
    "- $t_{\\text{medio\\_RUN}}(W)$ = tiempo medio de ciclo durante RUN en $W$\n",
    "\n",
    "**Interpretación:** Qué tan rápido producimos vs. la velocidad teórica.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Quality (Calidad)\n",
    "\n",
    "$$\\text{Quality}(W) = \\frac{OK_W}{OK_W + NG_W}$$\n",
    "\n",
    "**Interpretación:** Proporción de piezas buenas sobre el total producido.\n",
    "\n",
    "---\n",
    "\n",
    "### Parámetros\n",
    "\n",
    "- $t_{\\text{nom}} = 1.5$ s/botella (equivale a 2400 botellas/hora)\n",
    "- $t_{\\text{plan}} = 1$ hora (para ventanas horarias) ó $8$ horas (para turnos)\n",
    "\n",
    "---\n",
    "\n",
    "### Consideraciones de implementación\n",
    "\n",
    "- Si $N_W = 0$ o $t_{\\text{RUN}}(W) = 0$ → devolver `NaN`\n",
    "- Availability ya calculada en PASO 4 como `horas_RUN / horas_planificadas`\n",
    "- Quality ya calculada en PASO 4 como `pct_tolerancia / 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "44260aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CÁLCULO DEL OEE - OPCIÓN A\n",
      "============================================================\n",
      "\n",
      "Parámetros:\n",
      "   t_nom: 1.5 s/botella\n",
      "   Horas planificadas (hora): 1.0 h\n",
      "   Horas planificadas (turno): 8.0 h\n",
      "\n",
      "============================================================\n",
      "--- OEE POR HORA ---\n",
      "\n",
      "Primeras horas con OEE:\n",
      "                           N_botellas  Availability  Performance  Quality  \\\n",
      "2025-02-12 08:00:00+00:00      1039.0          0.87     0.497605   0.9904   \n",
      "2025-02-12 09:00:00+00:00      1165.0          0.97     0.500430   0.9888   \n",
      "2025-02-12 10:00:00+00:00      1066.0          0.89     0.499064   0.9934   \n",
      "2025-02-12 11:00:00+00:00       771.0          0.64     0.501953   0.9818   \n",
      "2025-02-12 12:00:00+00:00      1036.0          0.86     0.501938   0.9932   \n",
      "2025-02-12 13:00:00+00:00      1129.0          0.94     0.500443   0.9867   \n",
      "2025-02-12 14:00:00+00:00      1169.0          0.97     0.502148   0.9846   \n",
      "2025-02-12 15:00:00+00:00      1302.0          0.78     0.695513   0.9839   \n",
      "2025-02-12 16:00:00+00:00      1720.0          0.96     0.746528   0.9895   \n",
      "2025-02-12 17:00:00+00:00      1746.0          0.97     0.750000   0.9851   \n",
      "\n",
      "                           OEE_pct  \n",
      "2025-02-12 08:00:00+00:00    42.88  \n",
      "2025-02-12 09:00:00+00:00    48.00  \n",
      "2025-02-12 10:00:00+00:00    44.12  \n",
      "2025-02-12 11:00:00+00:00    31.54  \n",
      "2025-02-12 12:00:00+00:00    42.87  \n",
      "2025-02-12 13:00:00+00:00    46.42  \n",
      "2025-02-12 14:00:00+00:00    47.96  \n",
      "2025-02-12 15:00:00+00:00    53.38  \n",
      "2025-02-12 16:00:00+00:00    70.91  \n",
      "2025-02-12 17:00:00+00:00    71.67  \n",
      "\n",
      "============================================================\n",
      "--- OEE POR TURNO ---\n",
      "\n",
      "Primeros turnos con OEE:\n",
      "                      N_botellas  Availability  Performance  Quality  OEE_pct\n",
      "fecha      turno                                                             \n",
      "2025-02-12 T1_Mañana        6206       0.64625     0.500161   0.9894    31.98\n",
      "           T2_Tarde        12780       0.93500     0.711898   0.9876    65.74\n",
      "           T3_Noche         2676       0.22000     0.633523   0.9854    13.73\n",
      "2025-02-13 T1_Mañana       12318       0.93375     0.687082   0.9870    63.32\n",
      "           T2_Tarde         7193       0.66125     0.566556   0.9840    36.86\n",
      "           T3_Noche         6976       0.72625     0.500287   0.9874    35.88\n",
      "\n",
      "✅ OEE calculado (Opción A)\n"
     ]
    }
   ],
   "source": [
    "# PASO 12: Cálculo del OEE - Opción A\n",
    "print(\"=\"*60)\n",
    "print(\"CÁLCULO DEL OEE - OPCIÓN A\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# PARÁMETROS\n",
    "# ============================================================================\n",
    "T_NOM = 1.5  # segundos/botella\n",
    "HORAS_PLANIFICADAS_HORA = 1.0  # 1 hora\n",
    "HORAS_PLANIFICADAS_TURNO = 8.0  # 8 horas por turno\n",
    "\n",
    "print(f\"\\nParámetros:\")\n",
    "print(f\"   t_nom: {T_NOM} s/botella\")\n",
    "print(f\"   Horas planificadas (hora): {HORAS_PLANIFICADAS_HORA} h\")\n",
    "print(f\"   Horas planificadas (turno): {HORAS_PLANIFICADAS_TURNO} h\")\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE A: OEE POR HORA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- OEE POR HORA ---\")\n",
    "\n",
    "# 1. Availability = horas_RUN / horas_planificadas\n",
    "kpis_hora['Availability'] = kpis_hora['horas_RUN'] / HORAS_PLANIFICADAS_HORA\n",
    "\n",
    "# 2. Performance = t_nom / t_medio_RUN\n",
    "#    t_medio_RUN = horas_RUN / N_botellas (en horas/botella)\n",
    "#    Convertir t_nom a horas: 1.5 s = 1.5/3600 horas\n",
    "kpis_hora['Performance'] = np.where(\n",
    "    (kpis_hora['N_botellas'] > 0) & (kpis_hora['horas_RUN'] > 0),\n",
    "    (T_NOM / 3600) / (kpis_hora['horas_RUN'] / kpis_hora['N_botellas']),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 3. Quality = pct_tolerancia / 100\n",
    "kpis_hora['Quality'] = kpis_hora['pct_tolerancia'] / 100\n",
    "\n",
    "# 4. OEE = Availability × Performance × Quality\n",
    "kpis_hora['OEE'] = kpis_hora['Availability'] * kpis_hora['Performance'] * kpis_hora['Quality']\n",
    "\n",
    "# Convertir a porcentaje\n",
    "kpis_hora['OEE_pct'] = (kpis_hora['OEE'] * 100).round(2)\n",
    "\n",
    "print(f\"\\nPrimeras horas con OEE:\")\n",
    "print(kpis_hora[['N_botellas', 'Availability', 'Performance', 'Quality', 'OEE_pct']].head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE B: OEE POR TURNO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- OEE POR TURNO ---\")\n",
    "\n",
    "# 1. Availability = horas_RUN / horas_planificadas\n",
    "kpis_turno['Availability'] = kpis_turno['horas_RUN'] / HORAS_PLANIFICADAS_TURNO\n",
    "\n",
    "# 2. Performance = t_nom / t_medio_RUN\n",
    "kpis_turno['Performance'] = np.where(\n",
    "    (kpis_turno['N_botellas'] > 0) & (kpis_turno['horas_RUN'] > 0),\n",
    "    (T_NOM / 3600) / (kpis_turno['horas_RUN'] / kpis_turno['N_botellas']),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 3. Quality = pct_tolerancia / 100\n",
    "kpis_turno['Quality'] = kpis_turno['pct_tolerancia'] / 100\n",
    "\n",
    "# 4. OEE = Availability × Performance × Quality\n",
    "kpis_turno['OEE'] = kpis_turno['Availability'] * kpis_turno['Performance'] * kpis_turno['Quality']\n",
    "\n",
    "# Convertir a porcentaje\n",
    "kpis_turno['OEE_pct'] = (kpis_turno['OEE'] * 100).round(2)\n",
    "\n",
    "print(f\"\\nPrimeros turnos con OEE:\")\n",
    "print(kpis_turno[['N_botellas', 'Availability', 'Performance', 'Quality', 'OEE_pct']].head(10))\n",
    "\n",
    "print(f\"\\n✅ OEE calculado (Opción A)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8061d1db",
   "metadata": {},
   "source": [
    "# FASE 3 — Análisis numérico (NumPy puro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f05b3",
   "metadata": {},
   "source": [
    "## Preparación y notación\n",
    "\n",
    "**Rejilla temporal:** Por-ciclo (cada botella alineada con telemetría más próxima)\n",
    "\n",
    "**Variables continuas:**\n",
    "- `T` = temp_prod (°C)\n",
    "- `q` = caudal (ml/s)\n",
    "- `P` = P_kW (kW)\n",
    "- `tc` = tiempo_ciclo_s (s)\n",
    "\n",
    "**Variable binaria:**\n",
    "- `RUN ∈ {0,1}` (1 si en marcha)\n",
    "\n",
    "**Error de llenado:**\n",
    "- `e = peso_lleno_g - m_obj(f)` donde `m_obj(250)=250g`, `m_obj(500)=500g`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8f670544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "FASE 3 - ANÁLISIS NUMÉRICO (NumPy puro)\n",
      "============================================================\n",
      "\n",
      "PASO 1.1: Cálculo del error de llenado\n",
      "\n",
      "Error de llenado calculado:\n",
      "   Media: -0.046 g\n",
      "   Std: 3.123 g\n",
      "   Min: -16.770 g\n",
      "   Max: 18.470 g\n",
      "\n",
      "✅ Error de llenado calculado\n",
      "\n",
      "============================================================\n",
      "PASO 1.2: Cálculo del tiempo de ciclo\n",
      "\n",
      "Tiempo de ciclo calculado:\n",
      "   Media: 2.682 s\n",
      "   Mediana: 2.000 s\n",
      "   Std: 11.772 s\n",
      "   Min: 2.000 s\n",
      "   Max: 1624.000 s\n",
      "\n",
      "✅ Tiempo de ciclo calculado\n",
      "\n",
      "============================================================\n",
      "PASO 1.3: Alineación telemetría con botellas (merge_asof)\n",
      "\n",
      "Alineación completada:\n",
      "   Total de botellas: 48,149\n",
      "   Botellas con telemetría válida: 48,149\n",
      "\n",
      "Primeros registros alineados:\n",
      "                   ts_ciclo  temp_prod  caudal    P_kW  tiempo_ciclo_s  \\\n",
      "0 2025-02-12 08:08:03+00:00  25.805000   9.529  3.5784             NaN   \n",
      "1 2025-02-12 08:08:06+00:00  25.577999   9.577  3.1104             3.0   \n",
      "2 2025-02-12 08:08:09+00:00  25.697001  10.114  3.9024             3.0   \n",
      "3 2025-02-12 08:08:12+00:00  25.820000   9.653  3.9276             3.0   \n",
      "4 2025-02-12 08:08:15+00:00  25.915001   8.964  4.2948             3.0   \n",
      "5 2025-02-12 08:08:18+00:00  25.746000   8.310  4.5108             3.0   \n",
      "6 2025-02-12 08:08:21+00:00  25.862000   8.833  3.6144             3.0   \n",
      "7 2025-02-12 08:08:24+00:00  25.742001   9.526  4.2408             3.0   \n",
      "8 2025-02-12 08:08:27+00:00  25.586000   7.994  3.3516             3.0   \n",
      "9 2025-02-12 08:08:30+00:00  25.545000   8.666  3.9636             3.0   \n",
      "\n",
      "   error_llenado  RUN  \n",
      "0          -0.31    1  \n",
      "1          -1.29    1  \n",
      "2           1.08    1  \n",
      "3           3.04    1  \n",
      "4          -1.16    1  \n",
      "5          -4.11    1  \n",
      "6          -0.83    1  \n",
      "7           2.65    1  \n",
      "8           3.23    1  \n",
      "9          -2.57    1  \n",
      "\n",
      "✅ Datos alineados\n",
      "\n",
      "============================================================\n",
      "PASO 1.4: Extracción a NumPy y máscara de validez\n",
      "\n",
      "Máscara de datos válidos:\n",
      "   Total de registros: 48,149\n",
      "   Registros válidos (sin NaN): 48,148 (100.00%)\n",
      "   Registros con NaN: 1\n",
      "\n",
      "✅ Arrays NumPy preparados: T, q, P, tc, e, RUN\n"
     ]
    }
   ],
   "source": [
    "# PASO 1.1: Calcular error de llenado\n",
    "print(\"=\"*60)\n",
    "print(\"FASE 3 - ANÁLISIS NUMÉRICO (NumPy puro)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPASO 1.1: Cálculo del error de llenado\")\n",
    "\n",
    "# e = peso_lleno_g - m_obj(f)\n",
    "df_pz['error_llenado'] = df_pz['peso_lleno_g'] - df_pz['masa_objetivo']\n",
    "\n",
    "print(f\"\\nError de llenado calculado:\")\n",
    "print(f\"   Media: {df_pz['error_llenado'].mean():.3f} g\")\n",
    "print(f\"   Std: {df_pz['error_llenado'].std():.3f} g\")\n",
    "print(f\"   Min: {df_pz['error_llenado'].min():.3f} g\")\n",
    "print(f\"   Max: {df_pz['error_llenado'].max():.3f} g\")\n",
    "\n",
    "print(f\"\\n✅ Error de llenado calculado\")\n",
    "\n",
    "# PASO 1.2: Calcular tiempo de ciclo\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 1.2: Cálculo del tiempo de ciclo\")\n",
    "\n",
    "# tc = diferencia temporal entre botellas consecutivas (en segundos)\n",
    "df_pz['tiempo_ciclo_s'] = df_pz['ts_ciclo'].diff().dt.total_seconds()\n",
    "\n",
    "# Estadísticas (ignorar primer valor NaN)\n",
    "tc_validos = df_pz['tiempo_ciclo_s'].dropna()\n",
    "\n",
    "print(f\"\\nTiempo de ciclo calculado:\")\n",
    "print(f\"   Media: {tc_validos.mean():.3f} s\")\n",
    "print(f\"   Mediana: {tc_validos.median():.3f} s\")\n",
    "print(f\"   Std: {tc_validos.std():.3f} s\")\n",
    "print(f\"   Min: {tc_validos.min():.3f} s\")\n",
    "print(f\"   Max: {tc_validos.max():.3f} s\")\n",
    "\n",
    "print(f\"\\n✅ Tiempo de ciclo calculado\")\n",
    "\n",
    "\n",
    "# PASO 1.3: Alinear telemetría con botellas\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 1.3: Alineación telemetría con botellas (merge_asof)\")\n",
    "\n",
    "# Preparar df_tel: asegurar que el índice se llame 'ts' y reset_index\n",
    "df_tel.index.name = 'ts'  # Asegurar nombre del índice\n",
    "df_tel_temp = df_tel[['temp_prod', 'caudal', 'P_kW', 'estado']].reset_index()\n",
    "\n",
    "# Alinear cada botella con la muestra de telemetría más cercana ANTES del ciclo\n",
    "df_merge = pd.merge_asof(\n",
    "    df_pz.sort_values('ts_ciclo'),\n",
    "    df_tel_temp.sort_values('ts'),\n",
    "    left_on='ts_ciclo',\n",
    "    right_on='ts',\n",
    "    direction='backward',\n",
    "    tolerance=pd.Timedelta(seconds=5)  # Máximo 5 segundos de diferencia\n",
    ")\n",
    "\n",
    "# Convertir estado a binario: RUN=1, STOP=0\n",
    "df_merge['RUN'] = (df_merge['estado'] == 'RUN').astype(int)\n",
    "\n",
    "print(f\"\\nAlineación completada:\")\n",
    "print(f\"   Total de botellas: {len(df_merge):,}\")\n",
    "print(f\"   Botellas con telemetría válida: {df_merge['temp_prod'].notna().sum():,}\")\n",
    "\n",
    "print(f\"\\nPrimeros registros alineados:\")\n",
    "print(df_merge[['ts_ciclo', 'temp_prod', 'caudal', 'P_kW', 'tiempo_ciclo_s', 'error_llenado', 'RUN']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Datos alineados\")\n",
    "\n",
    "\n",
    "# PASO 1.4: Extraer arrays NumPy y crear máscara de datos válidos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 1.4: Extracción a NumPy y máscara de validez\")\n",
    "\n",
    "# Extraer arrays NumPy (a partir de aquí solo NumPy)\n",
    "T = df_merge['temp_prod'].values\n",
    "q = df_merge['caudal'].values\n",
    "P = df_merge['P_kW'].values\n",
    "tc = df_merge['tiempo_ciclo_s'].values\n",
    "e = df_merge['error_llenado'].values\n",
    "RUN = df_merge['RUN'].values\n",
    "\n",
    "# Crear máscara de datos válidos (sin NaN en ninguna variable)\n",
    "mask_validos = ~(np.isnan(T) | np.isnan(q) | np.isnan(P) | np.isnan(tc) | np.isnan(e))\n",
    "\n",
    "# Filtrar arrays con la máscara\n",
    "T_clean = T[mask_validos]\n",
    "q_clean = q[mask_validos]\n",
    "P_clean = P[mask_validos]\n",
    "tc_clean = tc[mask_validos]\n",
    "e_clean = e[mask_validos]\n",
    "RUN_clean = RUN[mask_validos]\n",
    "\n",
    "n_total = len(T)\n",
    "n_validos = len(T_clean)\n",
    "\n",
    "print(f\"\\nMáscara de datos válidos:\")\n",
    "print(f\"   Total de registros: {n_total:,}\")\n",
    "print(f\"   Registros válidos (sin NaN): {n_validos:,} ({n_validos/n_total*100:.2f}%)\")\n",
    "print(f\"   Registros con NaN: {n_total - n_validos:,}\")\n",
    "\n",
    "print(f\"\\n✅ Arrays NumPy preparados: T, q, P, tc, e, RUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b61974",
   "metadata": {},
   "source": [
    "## PASO 2: Correlaciones de Pearson\n",
    "\n",
    "### Fórmula de correlación de Pearson\n",
    "\n",
    "$$r_{xy} = \\frac{\\text{cov}(x,y)}{\\sigma_x \\sigma_y} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2} \\sqrt{\\sum(y_i-\\bar{y})^2}}$$\n",
    "\n",
    "**Implementación con estandarización:**\n",
    "\n",
    "1. Estandarizar: $z = \\frac{x - \\bar{x}}{\\sigma_x}$\n",
    "2. Matriz de correlación: $\\mathbf{R} = \\frac{\\mathbf{X}_{\\text{std}}^T \\mathbf{X}_{\\text{std}}}{n-1}$\n",
    "\n",
    "donde $\\mathbf{X}_{\\text{std}}$ es la matriz de datos estandarizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "1daffe0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PASO 2: CORRELACIONES DE PEARSON\n",
      "============================================================\n",
      "\n",
      "Matriz de correlación de Pearson (48,148 muestras):\n",
      "\n",
      "               T       q       P      tc       e\n",
      "------------------------------------------------\n",
      "       T   1.000   0.314   0.109   0.001   0.032\n",
      "       q   0.314   1.000   0.049   0.039   0.023\n",
      "       P   0.109   0.049   1.000   0.003   0.011\n",
      "      tc   0.001   0.039   0.003   1.000  -0.003\n",
      "       e   0.032   0.023   0.011  -0.003   1.000\n",
      "\n",
      "Correlaciones con el error de llenado (e):\n",
      "   T vs e:   0.032\n",
      "   q vs e:   0.023\n",
      "   P vs e:   0.011\n",
      "   tc vs e:  -0.003\n",
      "\n",
      "✅ Correlaciones calculadas con NumPy puro\n"
     ]
    }
   ],
   "source": [
    "# PASO 2: Correlaciones de Pearson (NumPy puro)\n",
    "print(\"=\"*60)\n",
    "print(\"PASO 2: CORRELACIONES DE PEARSON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Función para estandarizar (z-score)\n",
    "def estandarizar(x):\n",
    "    \"\"\"Estandariza un array: (x - media) / std\"\"\"\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "# Estandarizar todas las variables\n",
    "T_std = estandarizar(T_clean)\n",
    "q_std = estandarizar(q_clean)\n",
    "P_std = estandarizar(P_clean)\n",
    "tc_std = estandarizar(tc_clean)\n",
    "e_std = estandarizar(e_clean)\n",
    "\n",
    "# Construir matriz de datos estandarizados [T, q, P, tc, e]\n",
    "X_std = np.column_stack([T_std, q_std, P_std, tc_std, e_std])\n",
    "\n",
    "# Calcular matriz de correlación: R = (X'X) / (n-1)\n",
    "n = len(T_clean)\n",
    "corr_matrix = (X_std.T @ X_std) / (n - 1)\n",
    "\n",
    "# Nombres de variables\n",
    "var_names = ['T', 'q', 'P', 'tc', 'e']\n",
    "\n",
    "print(f\"\\nMatriz de correlación de Pearson ({n:,} muestras):\")\n",
    "print(\"\\n\" + \" \"*8 + \"\".join(f\"{v:>8}\" for v in var_names))\n",
    "print(\"-\" * 48)\n",
    "for i, nombre in enumerate(var_names):\n",
    "    fila = \"\".join(f\"{corr_matrix[i,j]:>8.3f}\" for j in range(len(var_names)))\n",
    "    print(f\"{nombre:>8}{fila}\")\n",
    "\n",
    "# Identificar correlaciones más fuertes con el error (e)\n",
    "print(f\"\\nCorrelaciones con el error de llenado (e):\")\n",
    "idx_e = 4  # Índice de 'e' en var_names\n",
    "for i, var in enumerate(var_names[:-1]):  # Excluir 'e' mismo\n",
    "    print(f\"   {var} vs e: {corr_matrix[i, idx_e]:>7.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Correlaciones calculadas con NumPy puro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4882c805",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
