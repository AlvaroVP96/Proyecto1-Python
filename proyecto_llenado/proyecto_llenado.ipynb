{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a58ce4",
   "metadata": {},
   "source": [
    "# Proyecto 1 — Estación de llenado y taponado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3bd33",
   "metadata": {},
   "source": [
    "Importación de las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f4a8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d78916",
   "metadata": {},
   "source": [
    "Definir las rutas de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49beaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "\n",
    "telemetria_file = data_path / \"telemetria.csv\"\n",
    "eventos_file = data_path / \"eventos.csv\"\n",
    "botellas_file = data_path / \"botellas.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba8245",
   "metadata": {},
   "source": [
    "# FASE 1 --->Ingesta y validación (Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c0a79",
   "metadata": {},
   "source": [
    "\n",
    "PASO 1: Carga y tipado de datos\n",
    "\n",
    "    1.1 Definir tipos de datos explícitos para cada CSV utilizando un diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faa031ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_tel = {\n",
    "    'temp_prod': 'float32',\n",
    "    'vel_cinta': 'float32',\n",
    "    'caudal': 'float32',\n",
    "    'energia_kwh': 'float64'\n",
    "}\n",
    "\n",
    "dtype_evt = {\n",
    "    'tipo': 'category',\n",
    "    'id_botella': 'Int64'\n",
    "}\n",
    "\n",
    "dtype_pz = {\n",
    "    'id_botella': 'int64',\n",
    "    'peso_neto': 'float32',\n",
    "    'formato': 'category'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db836bc4",
   "metadata": {},
   "source": [
    "    1.2 Cargar los csv en los dataFrames parseando el tiempo a datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f12c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar telemetría con parseo de fecha\n",
    "df_tel = pd.read_csv(\n",
    "    telemetria_file,\n",
    "    dtype=dtype_tel,\n",
    "    parse_dates=['ts'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "# Convertir ts a UTC y establecer como índice\n",
    "df_tel['ts'] = pd.to_datetime(df_tel['ts'], utc=True) # Convierte a datetime con zona horaria UTC\n",
    "df_tel = df_tel.set_index('ts').sort_index() # Establece la columna de tiempo como índice del DataFrame\n",
    "\n",
    "# Cargar eventos\n",
    "df_evt = pd.read_csv(\n",
    "    eventos_file,\n",
    "    dtype=dtype_evt,\n",
    "    parse_dates=['ts_ini', 'ts_fin'],\n",
    "    date_format='ISO8601'\n",
    ") # Lee el CSV y convierte automáticamente las columnas de fecha\n",
    "df_evt['ts_ini'] = pd.to_datetime(df_evt['ts_ini'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt['ts_fin'] = pd.to_datetime(df_evt['ts_fin'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt = df_evt.sort_values('ts_ini').reset_index(drop=True)\n",
    "\n",
    "# Cargar botellas\n",
    "df_pz = pd.read_csv(\n",
    "    botellas_file,\n",
    "    dtype=dtype_pz,\n",
    "    parse_dates=['ts_ciclo'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "df_pz['ts_ciclo'] = pd.to_datetime(df_pz['ts_ciclo'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef66b8",
   "metadata": {},
   "source": [
    "PASO 2. Orden y duplicados\n",
    "\n",
    "    2.1 Telemetría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84130e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemetria:\n",
      "Duplicados eliminados: 0\n",
      "Índice monótono: True\n",
      "No hay timestamps duplicados\n"
     ]
    }
   ],
   "source": [
    "print(\"Telemetria:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "duplicados_antes_tel = df_tel.duplicated().sum()\n",
    "df_tel = df_tel[~df_tel.duplicated(keep='first')]\n",
    "\n",
    "#df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Verificar monotonía del índice\n",
    "es_monotono_tel = df_tel.index.is_monotonic_increasing #Comprobacion de la monotonia: Los indices temporales avanzan correctamente de menor a mayor\n",
    "\n",
    "print(f\"Duplicados eliminados: {duplicados_antes_tel}\")\n",
    "print(f\"Índice monótono: {es_monotono_tel}\")\n",
    "\n",
    "# Verificar si hay duplicados en el índice temporal\n",
    "duplicados_index = df_tel.index.duplicated().sum()\n",
    "if duplicados_index > 0:\n",
    "    print(f\"Hay {duplicados_index} timestamps duplicados en el índice\")\n",
    "    df_tel = df_tel[~df_tel.index.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\"No hay timestamps duplicados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858598a8",
   "metadata": {},
   "source": [
    "    2.2 Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e0c877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventos:\n",
      "Duplicados eliminados: 0\n",
      "Orden por ts_ini monótono: True\n",
      "Eventos con ts_fin < ts_ini: 0\n",
      "Timestamps ts_ini duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Eventos:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "dup_evt = df_evt.duplicated().sum()\n",
    "df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por tiempo de inicio (y fin como desempate)\n",
    "df_evt = df_evt.sort_values(['ts_ini', 'ts_fin']).reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_evt = df_evt['ts_ini'].is_monotonic_increasing\n",
    "neg_dur = (df_evt['ts_fin'] < df_evt['ts_ini']).sum()\n",
    "dup_ts_ini = df_evt['ts_ini'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_evt}\")\n",
    "print(f\"Orden por ts_ini monótono: {es_monotono_evt}\")\n",
    "print(f\"Eventos con ts_fin < ts_ini: {neg_dur}\")\n",
    "print(f\"Timestamps ts_ini duplicados: {dup_ts_ini}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28764a4",
   "metadata": {},
   "source": [
    "    2.3 Botellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9fc0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Botellas:\n",
      "Duplicados eliminados: 0\n",
      "Orden por ts_ciclo monótono: True\n",
      "Timestamps ts_ciclo duplicados: 0\n",
      "id_botella duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Botellas:\")\n",
    "dup_pz = df_pz.duplicated().sum()\n",
    "df_pz = df_pz[~df_pz.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por ts_ciclo\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_pz = df_pz['ts_ciclo'].is_monotonic_increasing\n",
    "dup_ts_ciclo = df_pz['ts_ciclo'].duplicated().sum()\n",
    "dup_id_botella = df_pz['id_botella'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_pz}\")\n",
    "print(f\"Orden por ts_ciclo monótono: {es_monotono_pz}\")\n",
    "print(f\"Timestamps ts_ciclo duplicados: {dup_ts_ciclo}\")\n",
    "print(f\"id_botella duplicados: {dup_id_botella}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0f7dd",
   "metadata": {},
   "source": [
    "PASO 3: Validaciones de rango\n",
    "\n",
    "    3.1 Marcar valores fuera de rango (sin eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c35d8d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDACIÓN DE RANGOS\n",
      "============================================================\n",
      "temp_prod fuera de [18.0, 35.0] °C: 0 (0.00%)\n",
      "vel_cinta fuera de [0.0, 0.5] m/s: 0 (0.00%)\n",
      "caudal fuera de [0.0, 12.0] ml/s: 0 (0.00%)\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "           temp_prod      vel_cinta         caudal    energia_kwh\n",
      "count  129601.000000  129601.000000  129601.000000  129601.000000\n",
      "mean       25.646635       0.269995       7.735915      64.876601\n",
      "std         2.545803       0.092667       2.532649      37.845824\n",
      "min        18.000000       0.000000       0.000000       0.000000\n",
      "25%        23.802999       0.246000       7.443000      31.746546\n",
      "50%        25.648001       0.284000       8.321000      64.762093\n",
      "75%        27.365999       0.330000       9.101000      97.557688\n",
      "max        33.855000       0.380000      11.723000     130.067508\n"
     ]
    }
   ],
   "source": [
    "RANGO_TEMP = (18.0,35.0)\n",
    "RANGO_VEL = (0.0,0.5)\n",
    "RANGO_CAUDAL = (0.0,12.0)\n",
    "\n",
    "df_tel['fuera_RANGO_TEMP'] = (df_tel['temp_prod'] < RANGO_TEMP[0]) | (df_tel['temp_prod'] > RANGO_TEMP[1])\n",
    "df_tel['fuera_RANGO_VEL'] = (df_tel['vel_cinta'] < RANGO_VEL[0]) | (df_tel['vel_cinta'] > RANGO_VEL[1])\n",
    "df_tel['fuera_RANGO_CAUDAL'] = (df_tel['caudal'] < RANGO_CAUDAL[0]) | (df_tel['caudal'] > RANGO_CAUDAL[1])\n",
    "\n",
    "n_temp_fuera = df_tel['fuera_RANGO_TEMP'].sum()\n",
    "n_vel_fuera = df_tel['fuera_RANGO_VEL'].sum()\n",
    "n_caudal_fuera = df_tel['fuera_RANGO_CAUDAL'].sum()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE RANGOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"temp_prod fuera de [{RANGO_TEMP[0]}, {RANGO_TEMP[1]}] °C: {n_temp_fuera} ({n_temp_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"vel_cinta fuera de [{RANGO_VEL[0]}, {RANGO_VEL[1]}] m/s: {n_vel_fuera} ({n_vel_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"caudal fuera de [{RANGO_CAUDAL[0]}, {RANGO_CAUDAL[1]}] ml/s: {n_caudal_fuera} ({n_caudal_fuera/len(df_tel)*100:.2f}%)\")\n",
    "\n",
    "# Mostrar estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df_tel[['temp_prod', 'vel_cinta', 'caudal', 'energia_kwh']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3eeaf",
   "metadata": {},
   "source": [
    "    3.2 Validar que energia_kwh no decrece (salvo cuantización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3a121c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDACIÓN DE ENERGÍA NO DECRECIENTE\n",
      "============================================================\n",
      "Total de cambios: 129,600\n",
      "Decrementos detectados: 0 (0.000%)\n",
      "\n",
      " No se detectaron decrementos en energia_kwh\n"
     ]
    }
   ],
   "source": [
    "# Calcular diferencias entre valores consecutivos de energía\n",
    "df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "\n",
    "# Contar cuántas veces la energía DECRECE (delta < 0)\n",
    "# Nota: diff() genera NaN en la primera fila, lo ignoramos\n",
    "decrementos = (df_tel['delta_energia'] < 0).sum() \n",
    "total_cambios = df_tel['delta_energia'].notna().sum() #Va a contar cuantas veces decrece\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE ENERGÍA NO DECRECIENTE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de cambios: {total_cambios:,}\")\n",
    "print(f\"Decrementos detectados: {decrementos} ({decrementos/total_cambios*100:.3f}%)\")\n",
    "\n",
    "# Mostrar algunos ejemplos de decrementos (si existen)\n",
    "if decrementos > 0:\n",
    "    print(\"\\n Ejemplos de energía que decrece:\")\n",
    "    ejemplos_decremento = df_tel[df_tel['delta_energia'] < 0][['energia_kwh', 'delta_energia']].head(10)\n",
    "    print(ejemplos_decremento)\n",
    "    \n",
    "    # Estadísticas de los decrementos\n",
    "    print(\"\\n Estadísticas de los decrementos:\")\n",
    "    print(df_tel[df_tel['delta_energia'] < 0]['delta_energia'].describe())\n",
    "else:\n",
    "    print(\"\\n No se detectaron decrementos en energia_kwh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01bab0",
   "metadata": {},
   "source": [
    "PASO 4: Monotonicidad de energía (corrección de decrementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23534c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se requieren correcciones en energia_kwh\n",
      "La señal es naturalmente monótona creciente\n",
      "\n",
      "Verificación final: 0 decrementos después de corrección\n"
     ]
    }
   ],
   "source": [
    "# PASO 4: Corregir decrementos de energía (si los hubiera)\n",
    "# Guardamos la columna original para comparación\n",
    "df_tel['energia_kwh_original'] = df_tel['energia_kwh'].copy()\n",
    "\n",
    "# Identificar decrementos\n",
    "decrementos_mask = df_tel['delta_energia'] < 0\n",
    "n_correcciones = decrementos_mask.sum()\n",
    "\n",
    "if n_correcciones > 0:\n",
    "    print(f\"Se encontraron {n_correcciones} decrementos. Corrigiendo...\")\n",
    "    \n",
    "    # Hacer clip de deltas negativos a 0\n",
    "    df_tel['delta_energia_corregida'] = df_tel['delta_energia'].clip(lower=0)\n",
    "    \n",
    "    # Reconstruir energía acumulada desde el primer valor\n",
    "    energia_inicial = df_tel['energia_kwh'].iloc[0]\n",
    "    df_tel['energia_kwh'] = energia_inicial + df_tel['delta_energia_corregida'].fillna(0).cumsum()\n",
    "    \n",
    "    # Recalcular delta_energia con valores corregidos\n",
    "    df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "    \n",
    "    print(f\"{n_correcciones} correcciones aplicadas\")\n",
    "else:\n",
    "    print(\"No se requieren correcciones en energia_kwh\")\n",
    "    print(\"La señal es naturalmente monótona creciente\")\n",
    "\n",
    "# Verificación final\n",
    "decrementos_final = (df_tel['delta_energia'] < 0).sum()\n",
    "print(f\"\\nVerificación final: {decrementos_final} decrementos después de corrección\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2d090",
   "metadata": {},
   "source": [
    "PASO 5: Frecuencia y huecos temporales\n",
    "\n",
    "    5.1 Confirmar frecuencia nominal de 1 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "873af9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISIS DE FRECUENCIA DE MUESTREO\n",
      "============================================================\n",
      "\n",
      "Muestras con intervalo de 1s: 129600/129600\n",
      "\n",
      "Huecos detectados (intervalos > 1s): 0\n",
      "El numero de huecos es: 0\n",
      "La frecuencia nominal es de 1 Hz. Todos los saltos son de un segundo\n",
      "No es necesario interpolar ni marcar segmentos invalidos\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Analizar la frecuencia de muestreo\n",
    "print(\"=\"*60)\n",
    "print(\"ANÁLISIS DE FRECUENCIA DE MUESTREO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular diferencias de tiempo entre muestras consecutivas\n",
    "time_diffs = df_tel.index.to_series().diff()\n",
    "\n",
    "# Contar muestras con intervalo de 1 segundo\n",
    "intervalo_1s = time_diffs == pd.Timedelta(seconds=1)\n",
    "n_1s = intervalo_1s.sum()\n",
    "total = len(time_diffs) - 1  # -1 porque el primer valor es NaN\n",
    "\n",
    "print(f\"\\nMuestras con intervalo de 1s: {n_1s}/{total}\")\n",
    "\n",
    "# Identificar huecos (intervalos > 1s)\n",
    "huecos = time_diffs[time_diffs > pd.Timedelta(seconds=1)]\n",
    "n_huecos = len(huecos)\n",
    "\n",
    "print(f\"\\nHuecos detectados (intervalos > 1s): {n_huecos}\")\n",
    "\n",
    "if n_huecos > 0:\n",
    "    print(f\"\\nEstadísticas de los huecos:\")\n",
    "    print(huecos.describe())\n",
    "    \n",
    "    # Clasificar huecos\n",
    "    huecos_pequenos = huecos[huecos <= pd.Timedelta(seconds=10)]\n",
    "    huecos_grandes = huecos[huecos > pd.Timedelta(seconds=10)]\n",
    "    \n",
    "    print(f\"\\nHuecos pequeños (≤10s): {len(huecos_pequenos)}\")\n",
    "    print(f\"Huecos grandes (>10s): {len(huecos_grandes)}\")\n",
    "else:\n",
    "    print(f\"El numero de huecos es: {n_huecos}\")\n",
    "    print(\"La frecuencia nominal es de 1 Hz. Todos los saltos son de un segundo\")\n",
    "    print(\"No es necesario interpolar ni marcar segmentos invalidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e235834",
   "metadata": {},
   "source": [
    "    5.2 Reindexar a rejilla de 1 segundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01a14063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REINDEXACIÓN A REJILLA DE 1 SEGUNDO\n",
      "============================================================\n",
      "\n",
      "Rango temporal:\n",
      "   Inicio: 2025-02-12 08:00:00+00:00\n",
      "   Fin: 2025-02-13 20:00:00+00:00\n",
      "   Duración: 1 days 12:00:00\n",
      "\n",
      "Tamaño de los datos:\n",
      "   Muestras originales: 129,601\n",
      "   Rejilla de 1s: 129,601\n",
      "   Diferencia (huecos): 0\n",
      "\n",
      "DataFrame reindexado\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Reindexar a rejilla regular de 1 segundo\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REINDEXACIÓN A REJILLA DE 1 SEGUNDO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear rejilla temporal de 1s desde el primer al último timestamp\n",
    "ts_inicio = df_tel.index.min()\n",
    "ts_fin = df_tel.index.max()\n",
    "rejilla_1s = pd.date_range(start=ts_inicio, end=ts_fin, freq='1s')\n",
    "\n",
    "print(f\"\\nRango temporal:\")\n",
    "print(f\"   Inicio: {ts_inicio}\")\n",
    "print(f\"   Fin: {ts_fin}\")\n",
    "print(f\"   Duración: {ts_fin - ts_inicio}\")\n",
    "\n",
    "print(f\"\\nTamaño de los datos:\")\n",
    "print(f\"   Muestras originales: {len(df_tel):,}\")\n",
    "print(f\"   Rejilla de 1s: {len(rejilla_1s):,}\")\n",
    "print(f\"   Diferencia (huecos): {len(rejilla_1s) - len(df_tel):,}\")\n",
    "\n",
    "# Reindexar el DataFrame a la rejilla de 1s\n",
    "df_tel = df_tel.reindex(rejilla_1s)\n",
    "\n",
    "print(f\"\\nDataFrame reindexado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3405109",
   "metadata": {},
   "source": [
    "5.3 Rellenar huecos pequeños (≤10s) con interpolación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "359c9c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RELLENADO DE HUECOS PEQUEÑOS (≤10s)\n",
      "============================================================\n",
      "\n",
      "Bloques de NaN detectados:\n",
      "   Total de bloques: 0\n",
      "   Bloques ≤10s: 0 (se interpolarán)\n",
      "   Bloques >10s: 0 (se marcarán como inválidos)\n",
      "\n",
      "Interpolando temp_prod y caudal...\n",
      "Forward-fill en vel_cinta...\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Rellenar huecos ≤ 10s\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELLENADO DE HUECOS PEQUEÑOS (≤10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identificar bloques de NaN consecutivos\n",
    "df_tel['es_nan'] = df_tel['temp_prod'].isna()\n",
    "df_tel['bloque_nan'] = (df_tel['es_nan'] != df_tel['es_nan'].shift()).cumsum()\n",
    "\n",
    "# Calcular tamaño de cada bloque de NaN\n",
    "tamano_bloques = df_tel[df_tel['es_nan']].groupby('bloque_nan').size()\n",
    "\n",
    "# Clasificar bloques\n",
    "bloques_pequenos = tamano_bloques[tamano_bloques <= 10]\n",
    "bloques_grandes = tamano_bloques[tamano_bloques > 10]\n",
    "\n",
    "print(f\"\\nBloques de NaN detectados:\")\n",
    "print(f\"   Total de bloques: {len(tamano_bloques)}\")\n",
    "print(f\"   Bloques ≤10s: {len(bloques_pequenos)} (se interpolarán)\")\n",
    "print(f\"   Bloques >10s: {len(bloques_grandes)} (se marcarán como inválidos)\")\n",
    "\n",
    "# Crear máscara para huecos pequeños (≤10s)\n",
    "mask_huecos_pequenos = df_tel['bloque_nan'].isin(bloques_pequenos.index) & df_tel['es_nan']\n",
    "\n",
    "# Interpolación lineal para temp_prod y caudal en huecos pequeños\n",
    "print(f\"\\nInterpolando temp_prod y caudal...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'temp_prod'] = df_tel['temp_prod'].interpolate(method='linear', limit=10)\n",
    "df_tel.loc[mask_huecos_pequenos, 'caudal'] = df_tel['caudal'].interpolate(method='linear', limit=10)\n",
    "\n",
    "# Forward-fill para vel_cinta (propagar último valor válido)\n",
    "print(f\"Forward-fill en vel_cinta...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'vel_cinta'] = df_tel['vel_cinta'].ffill(limit=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c32aca",
   "metadata": {},
   "source": [
    "    5.4 Marcar huecos grandes (>10s) como inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06242975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARCADO DE HUECOS GRANDES (>10s)\n",
      "============================================================\n",
      "\n",
      "Segmentos marcados como inválidos:\n",
      "   Total de segundos inválidos: 0\n",
      "   Porcentaje: 0.00%\n",
      "\n",
      "✅ Proceso de huecos completado\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Marcar huecos grandes como inválidos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MARCADO DE HUECOS GRANDES (>10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna para marcar segmentos inválidos\n",
    "mask_huecos_grandes = df_tel['bloque_nan'].isin(bloques_grandes.index) & df_tel['es_nan']\n",
    "df_tel['segmento_invalido'] = mask_huecos_grandes\n",
    "\n",
    "# Contar segundos marcados como inválidos\n",
    "n_invalidos = df_tel['segmento_invalido'].sum()\n",
    "total_segundos = len(df_tel)\n",
    "\n",
    "print(f\"\\nSegmentos marcados como inválidos:\")\n",
    "print(f\"   Total de segundos inválidos: {n_invalidos:,}\")\n",
    "print(f\"   Porcentaje: {n_invalidos/total_segundos*100:.2f}%\")\n",
    "\n",
    "if len(bloques_grandes) > 0:\n",
    "    print(f\"\\nDetalle de huecos grandes:\")\n",
    "    for i, (bloque_id, tamano) in enumerate(bloques_grandes.items(), 1):\n",
    "        inicio_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.min()\n",
    "        fin_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.max()\n",
    "        print(f\"   Hueco {i}: {tamano}s desde {inicio_hueco} hasta {fin_hueco}\")\n",
    "        if i >= 5:\n",
    "            print(f\"   ... y {len(bloques_grandes)-5} huecos más\")\n",
    "            break\n",
    "\n",
    "# Limpiar columnas auxiliares\n",
    "df_tel = df_tel.drop(columns=['es_nan', 'bloque_nan'])\n",
    "\n",
    "print(f\"\\n✅ Proceso de huecos completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e50ca",
   "metadata": {},
   "source": [
    "PASO 6: Detección de atípicos\n",
    "\n",
    "    6.1 Detección por z-score (umbral ±3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee0c9b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DETECCIÓN DE ATÍPICOS POR Z-SCORE\n",
      "============================================================\n",
      "\n",
      "Atípicos detectados (|z-score| > 3):\n",
      "   temp_prod: 43 (0.033%)\n",
      "   vel_cinta: 0 (0.000%)\n",
      "   caudal: 10833 (8.359%)\n",
      "\n",
      "Ejemplos de atípicos en temp_prod:\n",
      "                           temp_prod    z_temp\n",
      "2025-02-13 03:59:56+00:00       18.0 -3.003624\n",
      "2025-02-13 03:59:57+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:03+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:04+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:05+00:00       18.0 -3.003624\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Detección de atípicos por z-score\n",
    "print(\"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR Z-SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral estándar: valores con |z-score| > 3 son atípicos\n",
    "UMBRAL_Z = 3\n",
    "\n",
    "# Calcular z-score para cada variable\n",
    "# z-score = (valor - media) / desviación estándar\n",
    "df_tel['z_temp'] = (df_tel['temp_prod'] - df_tel['temp_prod'].mean()) / df_tel['temp_prod'].std()\n",
    "df_tel['z_vel'] = (df_tel['vel_cinta'] - df_tel['vel_cinta'].mean()) / df_tel['vel_cinta'].std()\n",
    "df_tel['z_caudal'] = (df_tel['caudal'] - df_tel['caudal'].mean()) / df_tel['caudal'].std()\n",
    "\n",
    "# Marcar atípicos (|z| > 3)\n",
    "df_tel['atipico_z_temp'] = df_tel['z_temp'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_vel'] = df_tel['z_vel'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_caudal'] = df_tel['z_caudal'].abs() > UMBRAL_Z\n",
    "\n",
    "# Contar atípicos detectados\n",
    "n_atip_temp = df_tel['atipico_z_temp'].sum()\n",
    "n_atip_vel = df_tel['atipico_z_vel'].sum()\n",
    "n_atip_caudal = df_tel['atipico_z_caudal'].sum()\n",
    "\n",
    "print(f\"\\nAtípicos detectados (|z-score| > {UMBRAL_Z}):\")\n",
    "print(f\"   temp_prod: {n_atip_temp} ({n_atip_temp/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   vel_cinta: {n_atip_vel} ({n_atip_vel/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   caudal: {n_atip_caudal} ({n_atip_caudal/len(df_tel)*100:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplos si existen\n",
    "if n_atip_temp > 0:\n",
    "    print(\"\\nEjemplos de atípicos en temp_prod:\")\n",
    "    print(df_tel[df_tel['atipico_z_temp']][['temp_prod', 'z_temp']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b40235",
   "metadata": {},
   "source": [
    "    6.2 Detección por IQR (rango intercuartílico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b2d62e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETECCIÓN DE ATÍPICOS POR IQR\n",
      "============================================================\n",
      "\n",
      "temp_prod:\n",
      "   Q1: 23.803\n",
      "   Q3: 27.366\n",
      "   IQR: 3.563\n",
      "   Límites: [18.458, 32.710]\n",
      "   Atípicos: 125 (0.096%)\n",
      "\n",
      "vel_cinta:\n",
      "   Q1: 0.246\n",
      "   Q3: 0.330\n",
      "   IQR: 0.084\n",
      "   Límites: [0.120, 0.456]\n",
      "   Atípicos: 10833 (8.359%)\n",
      "\n",
      "caudal:\n",
      "   Q1: 7.443\n",
      "   Q3: 9.101\n",
      "   IQR: 1.658\n",
      "   Límites: [4.956, 11.588]\n",
      "   Atípicos: 10834 (8.360%)\n"
     ]
    }
   ],
   "source": [
    "# 6.2 Detección de atípicos por IQR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR IQR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular cuartiles y rango intercuartílico (IQR)\n",
    "# IQR = Q3 - Q1\n",
    "# Límites: [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
    "\n",
    "for var in ['temp_prod', 'vel_cinta', 'caudal']:\n",
    "    Q1 = df_tel[var].quantile(0.25)\n",
    "    Q3 = df_tel[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Marcar atípicos\n",
    "    col_name = f'atipico_iqr_{var.split(\"_\")[0]}'  # atipico_iqr_temp, atipico_iqr_vel, atipico_iqr_caudal\n",
    "    df_tel[col_name] = (df_tel[var] < limite_inferior) | (df_tel[var] > limite_superior)\n",
    "    \n",
    "    n_atipicos = df_tel[col_name].sum()\n",
    "    \n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"   Q1: {Q1:.3f}\")\n",
    "    print(f\"   Q3: {Q3:.3f}\")\n",
    "    print(f\"   IQR: {IQR:.3f}\")\n",
    "    print(f\"   Límites: [{limite_inferior:.3f}, {limite_superior:.3f}]\")\n",
    "    print(f\"   Atípicos: {n_atipicos} ({n_atipicos/len(df_tel)*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad4f3e3",
   "metadata": {},
   "source": [
    "    6.3 Consolidar marcas de atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362cd0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONSOLIDACIÓN DE ATÍPICOS\n",
      "============================================================\n",
      "\n",
      "Registros con al menos un valor atípico:\n",
      "   Total: 10,959\n",
      "   Porcentaje: 8.46%\n",
      "\n",
      "Comparación de métodos:\n",
      "   Z-score: 10,876\n",
      "   IQR: 10,959\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Consolidar detección de atípicos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONSOLIDACIÓN DE ATÍPICOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna que marca si hay algún atípico (OR lógico)\n",
    "# Un registro es atípico si al menos una variable lo es (por cualquier método)\n",
    "df_tel['es_atipico'] = (\n",
    "    df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal'] |\n",
    "    df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']\n",
    ")\n",
    "\n",
    "total_atipicos = df_tel['es_atipico'].sum()\n",
    "porcentaje = total_atipicos / len(df_tel) * 100\n",
    "\n",
    "print(f\"\\nRegistros con al menos un valor atípico:\")\n",
    "print(f\"   Total: {total_atipicos:,}\")\n",
    "print(f\"   Porcentaje: {porcentaje:.2f}%\")\n",
    "\n",
    "# Resumen por método\n",
    "print(f\"\\nComparación de métodos:\")\n",
    "print(f\"   Z-score: {(df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal']).sum():,}\")\n",
    "print(f\"   IQR: {(df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a92c2f",
   "metadata": {},
   "source": [
    "PASO 7: Etiqueta RUN/STOP por segundo\n",
    "\n",
    "    7.1 Construir máscara de paradas desde eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9bb9b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONSTRUCCIÓN DE MÁSCARA RUN/STOP\n",
      "============================================================\n",
      "\n",
      "Eventos de parada encontrados:\n",
      "   Total: 78\n",
      "   micro_parada: 71\n",
      "   cambio_formato: 5\n",
      "   limpieza: 2\n",
      "\n",
      "Segundos marcados como STOP por eventos: 10,755 (8.30%)\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Construir máscara STOP_evt desde eventos.csv\n",
    "print(\"=\"*60)\n",
    "print(\"CONSTRUCCIÓN DE MÁSCARA RUN/STOP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filtrar eventos que implican parada\n",
    "eventos_parada = df_evt[df_evt['tipo'].isin(['micro_parada', 'cambio_formato', 'limpieza'])].copy()\n",
    "\n",
    "print(f\"\\nEventos de parada encontrados:\")\n",
    "print(f\"   Total: {len(eventos_parada)}\")\n",
    "print(f\"   micro_parada: {(eventos_parada['tipo'] == 'micro_parada').sum()}\")\n",
    "print(f\"   cambio_formato: {(eventos_parada['tipo'] == 'cambio_formato').sum()}\")\n",
    "print(f\"   limpieza: {(eventos_parada['tipo'] == 'limpieza').sum()}\")\n",
    "\n",
    "# Inicializar columna STOP_evt en False (por defecto está en marcha)\n",
    "df_tel['STOP_evt'] = False\n",
    "\n",
    "# Marcar como True los segundos que caen en intervalos [ts_ini, ts_fin)\n",
    "for idx, evento in eventos_parada.iterrows():\n",
    "    mascara_tiempo = (df_tel.index >= evento['ts_ini']) & (df_tel.index < evento['ts_fin'])\n",
    "    df_tel.loc[mascara_tiempo, 'STOP_evt'] = True\n",
    "\n",
    "n_stop_evt = df_tel['STOP_evt'].sum()\n",
    "print(f\"\\nSegundos marcados como STOP por eventos: {n_stop_evt:,} ({n_stop_evt/len(df_tel)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9425947",
   "metadata": {},
   "source": [
    "7.2 Definir RUN basado en velocidad de cinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "119ee02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEFINICIÓN DE RUN_vel\n",
      "============================================================\n",
      "\n",
      "Umbral de velocidad: 0.05 m/s\n",
      "Segundos con RUN_vel=True: 118,768\n",
      "Segundos con RUN_vel=False: 10,833\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Definir RUN_vel basado en velocidad de cinta\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEFINICIÓN DE RUN_vel\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral de velocidad para considerar que la máquina está en marcha\n",
    "UMBRAL_VEL_RUN = 0.05  # m/s\n",
    "\n",
    "# RUN_vel = True si vel_cinta >= 0.05 m/s\n",
    "df_tel['RUN_vel'] = df_tel['vel_cinta'] >= UMBRAL_VEL_RUN\n",
    "\n",
    "n_run_vel = df_tel['RUN_vel'].sum()\n",
    "print(f\"\\nUmbral de velocidad: {UMBRAL_VEL_RUN} m/s\")\n",
    "print(f\"Segundos con RUN_vel=True: {n_run_vel:,}\")\n",
    "print(f\"Segundos con RUN_vel=False: {len(df_tel)-n_run_vel:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252d970",
   "metadata": {},
   "source": [
    "7.3 Combinar en estado final (RUN/STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5def909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMBINACIÓN DE CONDICIONES\n",
      "============================================================\n",
      "\n",
      "Distribución de estados:\n",
      "   RUN: 118,768\n",
      "   STOP: 10,833\n",
      "\n",
      "Transiciones de estado detectadas: 151\n"
     ]
    }
   ],
   "source": [
    "# 7.3 Definir estado final: RUN si RUN_vel=True Y STOP_evt=False\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINACIÓN DE CONDICIONES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# estado = RUN si (RUN_vel AND NOT STOP_evt), STOP en otro caso\n",
    "df_tel['estado'] = 'STOP'\n",
    "df_tel.loc[df_tel['RUN_vel'] & ~df_tel['STOP_evt'], 'estado'] = 'RUN'\n",
    "\n",
    "# Convertir a tipo category para ahorrar memoria\n",
    "df_tel['estado'] = df_tel['estado'].astype('category')\n",
    "\n",
    "# Contar estados\n",
    "n_run = (df_tel['estado'] == 'RUN').sum()\n",
    "n_stop = (df_tel['estado'] == 'STOP').sum()\n",
    "\n",
    "print(f\"\\nDistribución de estados:\")\n",
    "print(f\"   RUN: {n_run:,}\")\n",
    "print(f\"   STOP: {n_stop:,}\")\n",
    "\n",
    "# Análisis de transiciones\n",
    "df_tel['cambio_estado'] = df_tel['estado'] != df_tel['estado'].shift()\n",
    "n_transiciones = df_tel['cambio_estado'].sum() - 1  # -1 para excluir el primer valor\n",
    "\n",
    "print(f\"\\nTransiciones de estado detectadas: {n_transiciones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c44588",
   "metadata": {},
   "source": [
    "PASO 8: Agregación a 1 minuto (diagnóstico temprano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ea154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGREGACIÓN A 1 MINUTO\n",
      "============================================================\n",
      "\n",
      "DataFrame agregado:\n",
      "   Registros originales (1s): 129,601\n",
      "   Registros agregados (1min): 2,161\n",
      "   Rango temporal: 2025-02-12 08:00:00+00:00 a 2025-02-13 20:00:00+00:00\n",
      "\n",
      "Columnas creadas:\n",
      "   - temp_mean\n",
      "   - temp_p95\n",
      "   - caudal_mean\n",
      "   - vel_cinta_mean\n",
      "   - energia_kwh\n",
      "   - segundos_stop\n",
      "   - pct_stop\n",
      "   - segundos_run\n",
      "   - pct_run\n",
      "   - delta_energia_min\n",
      "\n",
      "Estadísticas de disponibilidad:\n",
      "   Media % RUN por minuto: 91.65%\n",
      "   Media % STOP por minuto: 8.35%\n",
      "   Minutos con 100% RUN: 1910\n",
      "   Minutos con 100% STOP: 120\n",
      "\n",
      "Primeros registros:\n",
      "                           temp_mean  temp_p95  caudal_mean  vel_cinta_mean  \\\n",
      "2025-02-12 08:00:00+00:00  24.997999    25.672          0.0             0.0   \n",
      "2025-02-12 08:01:00+00:00  24.575001    24.756          0.0             0.0   \n",
      "2025-02-12 08:02:00+00:00  24.604000    24.876          0.0             0.0   \n",
      "2025-02-12 08:03:00+00:00  25.184000    25.523          0.0             0.0   \n",
      "2025-02-12 08:04:00+00:00  25.219000    25.513          0.0             0.0   \n",
      "\n",
      "                           energia_kwh  segundos_stop  pct_stop  segundos_run  \\\n",
      "2025-02-12 08:00:00+00:00        0.018             60     100.0             0   \n",
      "2025-02-12 08:01:00+00:00        0.038             60     100.0             0   \n",
      "2025-02-12 08:02:00+00:00        0.057             60     100.0             0   \n",
      "2025-02-12 08:03:00+00:00        0.076             60     100.0             0   \n",
      "2025-02-12 08:04:00+00:00        0.096             60     100.0             0   \n",
      "\n",
      "                           pct_run  delta_energia_min  \n",
      "2025-02-12 08:00:00+00:00      0.0                NaN  \n",
      "2025-02-12 08:01:00+00:00      0.0              0.020  \n",
      "2025-02-12 08:02:00+00:00      0.0              0.019  \n",
      "2025-02-12 08:03:00+00:00      0.0              0.019  \n",
      "2025-02-12 08:04:00+00:00      0.0              0.020  \n"
     ]
    }
   ],
   "source": [
    "# PASO 8: Agregación temporal a 1 minuto\n",
    "print(\"=\"*60)\n",
    "print(\"AGREGACIÓN A 1 MINUTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear agregaciones por minuto\n",
    "df_1min = df_tel.resample('1min').agg({\n",
    "    'temp_prod': ['mean', lambda x: x.quantile(0.95)],\n",
    "    'caudal': 'mean',\n",
    "    'vel_cinta': 'mean',\n",
    "    'energia_kwh': 'last',  # Último valor del minuto (acumulado)\n",
    "    'estado': lambda x: (x == 'STOP').sum()  # Contar segundos en STOP\n",
    "}).round(3)\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_1min.columns = ['temp_mean', 'temp_p95', 'caudal_mean', 'vel_cinta_mean', 'energia_kwh', 'segundos_stop']\n",
    "\n",
    "# Calcular métricas derivadas\n",
    "df_1min['pct_stop'] = (df_1min['segundos_stop'] / 60 * 100).round(2)\n",
    "df_1min['segundos_run'] = 60 - df_1min['segundos_stop']\n",
    "df_1min['pct_run'] = (df_1min['segundos_run'] / 60 * 100).round(2)\n",
    "\n",
    "# Calcular delta de energía por minuto\n",
    "df_1min['delta_energia_min'] = df_1min['energia_kwh'].diff()\n",
    "\n",
    "# Información del resultado\n",
    "print(f\"\\nDataFrame agregado:\")\n",
    "print(f\"   Registros originales (1s): {len(df_tel):,}\")\n",
    "print(f\"   Registros agregados (1min): {len(df_1min):,}\")\n",
    "print(f\"   Rango temporal: {df_1min.index.min()} a {df_1min.index.max()}\")\n",
    "\n",
    "print(f\"\\nColumnas creadas:\")\n",
    "for col in df_1min.columns:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(f\"\\nEstadísticas de disponibilidad:\")\n",
    "print(f\"   Media % RUN por minuto: {df_1min['pct_run'].mean():.2f}%\")\n",
    "print(f\"   Media % STOP por minuto: {df_1min['pct_stop'].mean():.2f}%\")\n",
    "print(f\"   Minutos con 100% RUN: {(df_1min['pct_run'] == 100).sum()} ({(df_1min['pct_run'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "print(f\"   Minutos con 100% STOP: {(df_1min['pct_stop'] == 100).sum()} ({(df_1min['pct_stop'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "print(df_1min.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
