{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Proyecto 1 — Estación de llenado y taponado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Importación de las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Definir las rutas de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "\n",
    "telemetria_file = data_path / \"telemetria.csv\"\n",
    "eventos_file = data_path / \"eventos.csv\"\n",
    "botellas_file = data_path / \"botellas.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# FASE 1 --->Ingesta y validación (Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "\n",
    "PASO 1: Carga y tipado de datos\n",
    "\n",
    "    1.1 Definir tipos de datos explícitos para cada CSV utilizando un diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_tel = {\n",
    "    'temp_prod': 'float32',\n",
    "    'vel_cinta': 'float32',\n",
    "    'caudal': 'float32',\n",
    "    'energia_kwh': 'float64'\n",
    "}\n",
    "\n",
    "dtype_evt = {\n",
    "    'tipo': 'category',\n",
    "    'id_botella': 'Int64'\n",
    "}\n",
    "\n",
    "dtype_pz = {\n",
    "    'id_botella': 'int64',\n",
    "    'peso_neto': 'float32',\n",
    "    'formato': 'category'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "    1.2 Cargar los csv en los dataFrames parseando el tiempo a datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar telemetría con parseo de fecha\n",
    "df_tel = pd.read_csv(\n",
    "    telemetria_file,\n",
    "    dtype=dtype_tel,\n",
    "    parse_dates=['ts'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "# Convertir ts a UTC y establecer como índice\n",
    "df_tel['ts'] = pd.to_datetime(df_tel['ts'], utc=True) # Convierte a datetime con zona horaria UTC\n",
    "df_tel = df_tel.set_index('ts').sort_index() # Establece la columna de tiempo como índice del DataFrame\n",
    "\n",
    "# Cargar eventos\n",
    "df_evt = pd.read_csv(\n",
    "    eventos_file,\n",
    "    dtype=dtype_evt,\n",
    "    parse_dates=['ts_ini', 'ts_fin'],\n",
    "    date_format='ISO8601'\n",
    ") # Lee el CSV y convierte automáticamente las columnas de fecha\n",
    "df_evt['ts_ini'] = pd.to_datetime(df_evt['ts_ini'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt['ts_fin'] = pd.to_datetime(df_evt['ts_fin'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt = df_evt.sort_values('ts_ini').reset_index(drop=True)\n",
    "\n",
    "# Cargar botellas\n",
    "df_pz = pd.read_csv(\n",
    "    botellas_file,\n",
    "    dtype=dtype_pz,\n",
    "    parse_dates=['ts_ciclo'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "df_pz['ts_ciclo'] = pd.to_datetime(df_pz['ts_ciclo'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "PASO 2. Orden y duplicados\n",
    "\n",
    "    2.1 Telemetría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Telemetria:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "duplicados_antes_tel = df_tel.duplicated().sum()\n",
    "df_tel = df_tel[~df_tel.duplicated(keep='first')]\n",
    "\n",
    "#df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Verificar monotonía del índice\n",
    "es_monotono_tel = df_tel.index.is_monotonic_increasing #Comprobacion de la monotonia: Los indices temporales avanzan correctamente de menor a mayor\n",
    "\n",
    "print(f\"Duplicados eliminados: {duplicados_antes_tel}\")\n",
    "print(f\"Índice monótono: {es_monotono_tel}\")\n",
    "\n",
    "# Verificar si hay duplicados en el índice temporal\n",
    "duplicados_index = df_tel.index.duplicated().sum()\n",
    "if duplicados_index > 0:\n",
    "    print(f\"Hay {duplicados_index} timestamps duplicados en el índice\")\n",
    "    df_tel = df_tel[~df_tel.index.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\"No hay timestamps duplicados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "    2.2 Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Eventos:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "dup_evt = df_evt.duplicated().sum()\n",
    "df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por tiempo de inicio (y fin como desempate)\n",
    "df_evt = df_evt.sort_values(['ts_ini', 'ts_fin']).reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_evt = df_evt['ts_ini'].is_monotonic_increasing\n",
    "neg_dur = (df_evt['ts_fin'] < df_evt['ts_ini']).sum()\n",
    "dup_ts_ini = df_evt['ts_ini'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_evt}\")\n",
    "print(f\"Orden por ts_ini monótono: {es_monotono_evt}\")\n",
    "print(f\"Eventos con ts_fin < ts_ini: {neg_dur}\")\n",
    "print(f\"Timestamps ts_ini duplicados: {dup_ts_ini}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "    2.3 Botellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Botellas:\")\n",
    "dup_pz = df_pz.duplicated().sum()\n",
    "df_pz = df_pz[~df_pz.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por ts_ciclo\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_pz = df_pz['ts_ciclo'].is_monotonic_increasing\n",
    "dup_ts_ciclo = df_pz['ts_ciclo'].duplicated().sum()\n",
    "dup_id_botella = df_pz['id_botella'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_pz}\")\n",
    "print(f\"Orden por ts_ciclo monótono: {es_monotono_pz}\")\n",
    "print(f\"Timestamps ts_ciclo duplicados: {dup_ts_ciclo}\")\n",
    "print(f\"id_botella duplicados: {dup_id_botella}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "PASO 3: Validaciones de rango\n",
    "\n",
    "    3.1 Marcar valores fuera de rango (sin eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANGO_TEMP = (18.0,35.0)\n",
    "RANGO_VEL = (0.0,0.5)\n",
    "RANGO_CAUDAL = (0.0,12.0)\n",
    "\n",
    "df_tel['fuera_RANGO_TEMP'] = (df_tel['temp_prod'] < RANGO_TEMP[0]) | (df_tel['temp_prod'] > RANGO_TEMP[1])\n",
    "df_tel['fuera_RANGO_VEL'] = (df_tel['vel_cinta'] < RANGO_VEL[0]) | (df_tel['vel_cinta'] > RANGO_VEL[1])\n",
    "df_tel['fuera_RANGO_CAUDAL'] = (df_tel['caudal'] < RANGO_CAUDAL[0]) | (df_tel['caudal'] > RANGO_CAUDAL[1])\n",
    "\n",
    "n_temp_fuera = df_tel['fuera_RANGO_TEMP'].sum()\n",
    "n_vel_fuera = df_tel['fuera_RANGO_VEL'].sum()\n",
    "n_caudal_fuera = df_tel['fuera_RANGO_CAUDAL'].sum()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE RANGOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"temp_prod fuera de [{RANGO_TEMP[0]}, {RANGO_TEMP[1]}] °C: {n_temp_fuera} ({n_temp_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"vel_cinta fuera de [{RANGO_VEL[0]}, {RANGO_VEL[1]}] m/s: {n_vel_fuera} ({n_vel_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"caudal fuera de [{RANGO_CAUDAL[0]}, {RANGO_CAUDAL[1]}] ml/s: {n_caudal_fuera} ({n_caudal_fuera/len(df_tel)*100:.2f}%)\")\n",
    "\n",
    "# Mostrar estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df_tel[['temp_prod', 'vel_cinta', 'caudal', 'energia_kwh']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "    3.2 Validar que energia_kwh no decrece (salvo cuantización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular diferencias entre valores consecutivos de energía\n",
    "df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "\n",
    "# Contar cuántas veces la energía DECRECE (delta < 0)\n",
    "# Nota: diff() genera NaN en la primera fila, lo ignoramos\n",
    "decrementos = (df_tel['delta_energia'] < 0).sum() \n",
    "total_cambios = df_tel['delta_energia'].notna().sum() #Va a contar cuantas veces decrece\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE ENERGÍA NO DECRECIENTE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de cambios: {total_cambios:,}\")\n",
    "print(f\"Decrementos detectados: {decrementos} ({decrementos/total_cambios*100:.3f}%)\")\n",
    "\n",
    "# Mostrar algunos ejemplos de decrementos (si existen)\n",
    "if decrementos > 0:\n",
    "    print(\"\\n Ejemplos de energía que decrece:\")\n",
    "    ejemplos_decremento = df_tel[df_tel['delta_energia'] < 0][['energia_kwh', 'delta_energia']].head(10)\n",
    "    print(ejemplos_decremento)\n",
    "    \n",
    "    # Estadísticas de los decrementos\n",
    "    print(\"\\n Estadísticas de los decrementos:\")\n",
    "    print(df_tel[df_tel['delta_energia'] < 0]['delta_energia'].describe())\n",
    "else:\n",
    "    print(\"\\n No se detectaron decrementos en energia_kwh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "PASO 4: Monotonicidad de energía (corrección de decrementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 4: Corregir decrementos de energía (si los hubiera)\n",
    "# Guardamos la columna original para comparación\n",
    "df_tel['energia_kwh_original'] = df_tel['energia_kwh'].copy()\n",
    "\n",
    "# Identificar decrementos\n",
    "decrementos_mask = df_tel['delta_energia'] < 0\n",
    "n_correcciones = decrementos_mask.sum()\n",
    "\n",
    "if n_correcciones > 0:\n",
    "    print(f\"Se encontraron {n_correcciones} decrementos. Corrigiendo...\")\n",
    "    \n",
    "    # Hacer clip de deltas negativos a 0\n",
    "    df_tel['delta_energia_corregida'] = df_tel['delta_energia'].clip(lower=0)\n",
    "    \n",
    "    # Reconstruir energía acumulada desde el primer valor\n",
    "    energia_inicial = df_tel['energia_kwh'].iloc[0]\n",
    "    df_tel['energia_kwh'] = energia_inicial + df_tel['delta_energia_corregida'].fillna(0).cumsum()\n",
    "    \n",
    "    # Recalcular delta_energia con valores corregidos\n",
    "    df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "    \n",
    "    print(f\"{n_correcciones} correcciones aplicadas\")\n",
    "else:\n",
    "    print(\"No se requieren correcciones en energia_kwh\")\n",
    "    print(\"La señal es naturalmente monótona creciente\")\n",
    "\n",
    "# Verificación final\n",
    "decrementos_final = (df_tel['delta_energia'] < 0).sum()\n",
    "print(f\"\\nVerificación final: {decrementos_final} decrementos después de corrección\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "PASO 5: Frecuencia y huecos temporales\n",
    "\n",
    "    5.1 Confirmar frecuencia nominal de 1 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Analizar la frecuencia de muestreo\n",
    "print(\"=\"*60)\n",
    "print(\"ANÁLISIS DE FRECUENCIA DE MUESTREO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular diferencias de tiempo entre muestras consecutivas\n",
    "time_diffs = df_tel.index.to_series().diff()\n",
    "\n",
    "# Contar muestras con intervalo de 1 segundo\n",
    "intervalo_1s = time_diffs == pd.Timedelta(seconds=1)\n",
    "n_1s = intervalo_1s.sum()\n",
    "total = len(time_diffs) - 1  # -1 porque el primer valor es NaN\n",
    "\n",
    "print(f\"\\nMuestras con intervalo de 1s: {n_1s}/{total}\")\n",
    "\n",
    "# Identificar huecos (intervalos > 1s)\n",
    "huecos = time_diffs[time_diffs > pd.Timedelta(seconds=1)]\n",
    "n_huecos = len(huecos)\n",
    "\n",
    "print(f\"\\nHuecos detectados (intervalos > 1s): {n_huecos}\")\n",
    "\n",
    "if n_huecos > 0:\n",
    "    print(f\"\\nEstadísticas de los huecos:\")\n",
    "    print(huecos.describe())\n",
    "    \n",
    "    # Clasificar huecos\n",
    "    huecos_pequenos = huecos[huecos <= pd.Timedelta(seconds=10)]\n",
    "    huecos_grandes = huecos[huecos > pd.Timedelta(seconds=10)]\n",
    "    \n",
    "    print(f\"\\nHuecos pequeños (≤10s): {len(huecos_pequenos)}\")\n",
    "    print(f\"Huecos grandes (>10s): {len(huecos_grandes)}\")\n",
    "else:\n",
    "    print(f\"El numero de huecos es: {n_huecos}\")\n",
    "    print(\"La frecuencia nominal es de 1 Hz. Todos los saltos son de un segundo\")\n",
    "    print(\"No es necesario interpolar ni marcar segmentos invalidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "    5.2 Reindexar a rejilla de 1 segundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Reindexar a rejilla regular de 1 segundo\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REINDEXACIÓN A REJILLA DE 1 SEGUNDO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear rejilla temporal de 1s desde el primer al último timestamp\n",
    "ts_inicio = df_tel.index.min()\n",
    "ts_fin = df_tel.index.max()\n",
    "rejilla_1s = pd.date_range(start=ts_inicio, end=ts_fin, freq='1s')\n",
    "\n",
    "print(f\"\\nRango temporal:\")\n",
    "print(f\"   Inicio: {ts_inicio}\")\n",
    "print(f\"   Fin: {ts_fin}\")\n",
    "print(f\"   Duración: {ts_fin - ts_inicio}\")\n",
    "\n",
    "print(f\"\\nTamaño de los datos:\")\n",
    "print(f\"   Muestras originales: {len(df_tel):,}\")\n",
    "print(f\"   Rejilla de 1s: {len(rejilla_1s):,}\")\n",
    "print(f\"   Diferencia (huecos): {len(rejilla_1s) - len(df_tel):,}\")\n",
    "\n",
    "# Reindexar el DataFrame a la rejilla de 1s\n",
    "df_tel = df_tel.reindex(rejilla_1s)\n",
    "\n",
    "print(f\"\\nDataFrame reindexado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "5.3 Rellenar huecos pequeños (≤10s) con interpolación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Rellenar huecos ≤ 10s\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELLENADO DE HUECOS PEQUEÑOS (≤10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identificar bloques de NaN consecutivos\n",
    "df_tel['es_nan'] = df_tel['temp_prod'].isna()\n",
    "df_tel['bloque_nan'] = (df_tel['es_nan'] != df_tel['es_nan'].shift()).cumsum()\n",
    "\n",
    "# Calcular tamaño de cada bloque de NaN\n",
    "tamano_bloques = df_tel[df_tel['es_nan']].groupby('bloque_nan').size()\n",
    "\n",
    "# Clasificar bloques\n",
    "bloques_pequenos = tamano_bloques[tamano_bloques <= 10]\n",
    "bloques_grandes = tamano_bloques[tamano_bloques > 10]\n",
    "\n",
    "print(f\"\\nBloques de NaN detectados:\")\n",
    "print(f\"   Total de bloques: {len(tamano_bloques)}\")\n",
    "print(f\"   Bloques ≤10s: {len(bloques_pequenos)} (se interpolarán)\")\n",
    "print(f\"   Bloques >10s: {len(bloques_grandes)} (se marcarán como inválidos)\")\n",
    "\n",
    "# Crear máscara para huecos pequeños (≤10s)\n",
    "mask_huecos_pequenos = df_tel['bloque_nan'].isin(bloques_pequenos.index) & df_tel['es_nan']\n",
    "\n",
    "# Interpolación lineal para temp_prod y caudal en huecos pequeños\n",
    "print(f\"\\nInterpolando temp_prod y caudal...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'temp_prod'] = df_tel['temp_prod'].interpolate(method='linear', limit=10)\n",
    "df_tel.loc[mask_huecos_pequenos, 'caudal'] = df_tel['caudal'].interpolate(method='linear', limit=10)\n",
    "\n",
    "# Forward-fill para vel_cinta (propagar último valor válido)\n",
    "print(f\"Forward-fill en vel_cinta...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'vel_cinta'] = df_tel['vel_cinta'].ffill(limit=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "    5.4 Marcar huecos grandes (>10s) como inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Marcar huecos grandes como inválidos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MARCADO DE HUECOS GRANDES (>10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna para marcar segmentos inválidos\n",
    "mask_huecos_grandes = df_tel['bloque_nan'].isin(bloques_grandes.index) & df_tel['es_nan']\n",
    "df_tel['segmento_invalido'] = mask_huecos_grandes\n",
    "\n",
    "# Contar segundos marcados como inválidos\n",
    "n_invalidos = df_tel['segmento_invalido'].sum()\n",
    "total_segundos = len(df_tel)\n",
    "\n",
    "print(f\"\\nSegmentos marcados como inválidos:\")\n",
    "print(f\"   Total de segundos inválidos: {n_invalidos:,}\")\n",
    "print(f\"   Porcentaje: {n_invalidos/total_segundos*100:.2f}%\")\n",
    "\n",
    "if len(bloques_grandes) > 0:\n",
    "    print(f\"\\nDetalle de huecos grandes:\")\n",
    "    for i, (bloque_id, tamano) in enumerate(bloques_grandes.items(), 1):\n",
    "        inicio_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.min()\n",
    "        fin_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.max()\n",
    "        print(f\"   Hueco {i}: {tamano}s desde {inicio_hueco} hasta {fin_hueco}\")\n",
    "        if i >= 5:\n",
    "            print(f\"   ... y {len(bloques_grandes)-5} huecos más\")\n",
    "            break\n",
    "\n",
    "# Limpiar columnas auxiliares\n",
    "df_tel = df_tel.drop(columns=['es_nan', 'bloque_nan'])\n",
    "\n",
    "print(f\"\\n✅ Proceso de huecos completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "PASO 6: Detección de atípicos\n",
    "\n",
    "    6.1 Detección por z-score (umbral ±3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Detección de atípicos por z-score\n",
    "print(\"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR Z-SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral estándar: valores con |z-score| > 3 son atípicos\n",
    "UMBRAL_Z = 3\n",
    "\n",
    "# Calcular z-score para cada variable\n",
    "# z-score = (valor - media) / desviación estándar\n",
    "df_tel['z_temp'] = (df_tel['temp_prod'] - df_tel['temp_prod'].mean()) / df_tel['temp_prod'].std()\n",
    "df_tel['z_vel'] = (df_tel['vel_cinta'] - df_tel['vel_cinta'].mean()) / df_tel['vel_cinta'].std()\n",
    "df_tel['z_caudal'] = (df_tel['caudal'] - df_tel['caudal'].mean()) / df_tel['caudal'].std()\n",
    "\n",
    "# Marcar atípicos (|z| > 3)\n",
    "df_tel['atipico_z_temp'] = df_tel['z_temp'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_vel'] = df_tel['z_vel'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_caudal'] = df_tel['z_caudal'].abs() > UMBRAL_Z\n",
    "\n",
    "# Contar atípicos detectados\n",
    "n_atip_temp = df_tel['atipico_z_temp'].sum()\n",
    "n_atip_vel = df_tel['atipico_z_vel'].sum()\n",
    "n_atip_caudal = df_tel['atipico_z_caudal'].sum()\n",
    "\n",
    "print(f\"\\nAtípicos detectados (|z-score| > {UMBRAL_Z}):\")\n",
    "print(f\"   temp_prod: {n_atip_temp} ({n_atip_temp/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   vel_cinta: {n_atip_vel} ({n_atip_vel/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   caudal: {n_atip_caudal} ({n_atip_caudal/len(df_tel)*100:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplos si existen\n",
    "if n_atip_temp > 0:\n",
    "    print(\"\\nEjemplos de atípicos en temp_prod:\")\n",
    "    print(df_tel[df_tel['atipico_z_temp']][['temp_prod', 'z_temp']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "    6.2 Detección por IQR (rango intercuartílico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Detección de atípicos por IQR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR IQR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular cuartiles y rango intercuartílico (IQR)\n",
    "# IQR = Q3 - Q1\n",
    "# Límites: [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
    "\n",
    "for var in ['temp_prod', 'vel_cinta', 'caudal']:\n",
    "    Q1 = df_tel[var].quantile(0.25)\n",
    "    Q3 = df_tel[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Marcar atípicos\n",
    "    col_name = f'atipico_iqr_{var.split(\"_\")[0]}'  # atipico_iqr_temp, atipico_iqr_vel, atipico_iqr_caudal\n",
    "    df_tel[col_name] = (df_tel[var] < limite_inferior) | (df_tel[var] > limite_superior)\n",
    "    \n",
    "    n_atipicos = df_tel[col_name].sum()\n",
    "    \n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"   Q1: {Q1:.3f}\")\n",
    "    print(f\"   Q3: {Q3:.3f}\")\n",
    "    print(f\"   IQR: {IQR:.3f}\")\n",
    "    print(f\"   Límites: [{limite_inferior:.3f}, {limite_superior:.3f}]\")\n",
    "    print(f\"   Atípicos: {n_atipicos} ({n_atipicos/len(df_tel)*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "    6.3 Consolidar marcas de atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Consolidar detección de atípicos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONSOLIDACIÓN DE ATÍPICOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna que marca si hay algún atípico (OR lógico)\n",
    "# Un registro es atípico si al menos una variable lo es (por cualquier método)\n",
    "df_tel['es_atipico'] = (\n",
    "    df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal'] |\n",
    "    df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']\n",
    ")\n",
    "\n",
    "total_atipicos = df_tel['es_atipico'].sum()\n",
    "porcentaje = total_atipicos / len(df_tel) * 100\n",
    "\n",
    "print(f\"\\nRegistros con al menos un valor atípico:\")\n",
    "print(f\"   Total: {total_atipicos:,}\")\n",
    "print(f\"   Porcentaje: {porcentaje:.2f}%\")\n",
    "\n",
    "# Resumen por método\n",
    "print(f\"\\nComparación de métodos:\")\n",
    "print(f\"   Z-score: {(df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal']).sum():,}\")\n",
    "print(f\"   IQR: {(df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "PASO 7: Etiqueta RUN/STOP por segundo\n",
    "\n",
    "    7.1 Construir máscara de paradas desde eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Construir máscara STOP_evt desde eventos.csv\n",
    "print(\"=\"*60)\n",
    "print(\"CONSTRUCCIÓN DE MÁSCARA RUN/STOP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filtrar eventos que implican parada\n",
    "eventos_parada = df_evt[df_evt['tipo'].isin(['micro_parada', 'cambio_formato', 'limpieza'])].copy()\n",
    "\n",
    "print(f\"\\nEventos de parada encontrados:\")\n",
    "print(f\"   Total: {len(eventos_parada)}\")\n",
    "print(f\"   micro_parada: {(eventos_parada['tipo'] == 'micro_parada').sum()}\")\n",
    "print(f\"   cambio_formato: {(eventos_parada['tipo'] == 'cambio_formato').sum()}\")\n",
    "print(f\"   limpieza: {(eventos_parada['tipo'] == 'limpieza').sum()}\")\n",
    "\n",
    "# Inicializar columna STOP_evt en False (por defecto está en marcha)\n",
    "df_tel['STOP_evt'] = False\n",
    "\n",
    "# Marcar como True los segundos que caen en intervalos [ts_ini, ts_fin)\n",
    "for idx, evento in eventos_parada.iterrows():\n",
    "    mascara_tiempo = (df_tel.index >= evento['ts_ini']) & (df_tel.index < evento['ts_fin'])\n",
    "    df_tel.loc[mascara_tiempo, 'STOP_evt'] = True\n",
    "\n",
    "n_stop_evt = df_tel['STOP_evt'].sum()\n",
    "print(f\"\\nSegundos marcados como STOP por eventos: {n_stop_evt:,} ({n_stop_evt/len(df_tel)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "7.2 Definir RUN basado en velocidad de cinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Definir RUN_vel basado en velocidad de cinta\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEFINICIÓN DE RUN_vel\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral de velocidad para considerar que la máquina está en marcha\n",
    "UMBRAL_VEL_RUN = 0.05  # m/s\n",
    "\n",
    "# RUN_vel = True si vel_cinta >= 0.05 m/s\n",
    "df_tel['RUN_vel'] = df_tel['vel_cinta'] >= UMBRAL_VEL_RUN\n",
    "\n",
    "n_run_vel = df_tel['RUN_vel'].sum()\n",
    "print(f\"\\nUmbral de velocidad: {UMBRAL_VEL_RUN} m/s\")\n",
    "print(f\"Segundos con RUN_vel=True: {n_run_vel:,}\")\n",
    "print(f\"Segundos con RUN_vel=False: {len(df_tel)-n_run_vel:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40",
   "metadata": {},
   "source": [
    "7.3 Combinar en estado final (RUN/STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Definir estado final: RUN si RUN_vel=True Y STOP_evt=False\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINACIÓN DE CONDICIONES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# estado = RUN si (RUN_vel AND NOT STOP_evt), STOP en otro caso\n",
    "df_tel['estado'] = 'STOP'\n",
    "df_tel.loc[df_tel['RUN_vel'] & ~df_tel['STOP_evt'], 'estado'] = 'RUN'\n",
    "\n",
    "# Convertir a tipo category para ahorrar memoria\n",
    "df_tel['estado'] = df_tel['estado'].astype('category')\n",
    "\n",
    "# Contar estados\n",
    "n_run = (df_tel['estado'] == 'RUN').sum()\n",
    "n_stop = (df_tel['estado'] == 'STOP').sum()\n",
    "\n",
    "print(f\"\\nDistribución de estados:\")\n",
    "print(f\"   RUN: {n_run:,}\")\n",
    "print(f\"   STOP: {n_stop:,}\")\n",
    "\n",
    "# Análisis de transiciones\n",
    "df_tel['cambio_estado'] = df_tel['estado'] != df_tel['estado'].shift()\n",
    "n_transiciones = df_tel['cambio_estado'].sum() - 1  # -1 para excluir el primer valor\n",
    "\n",
    "print(f\"\\nTransiciones de estado detectadas: {n_transiciones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "PASO 8: Agregación a 1 minuto (diagnóstico temprano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"AGREGACIÓN A 1 MINUTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear agregaciones por minuto\n",
    "df_1min = df_tel.resample('1min').agg({\n",
    "    'temp_prod': ['mean', lambda x: x.quantile(0.95)],\n",
    "    'caudal': 'mean',\n",
    "    'vel_cinta': 'mean',\n",
    "    'energia_kwh': 'last',  # Último valor del minuto (acumulado)\n",
    "    'estado': lambda x: (x == 'STOP').sum()  # Contar segundos en STOP\n",
    "}).round(3)\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_1min.columns = ['temp_mean', 'temp_p95', 'caudal_mean', 'vel_cinta_mean', 'energia_kwh', 'segundos_stop']\n",
    "\n",
    "# Calcular métricas derivadas\n",
    "df_1min['pct_stop'] = (df_1min['segundos_stop'] / 60 * 100).round(2)\n",
    "df_1min['segundos_run'] = 60 - df_1min['segundos_stop']\n",
    "df_1min['pct_run'] = (df_1min['segundos_run'] / 60 * 100).round(2)\n",
    "\n",
    "# Calcular delta de energía por minuto\n",
    "df_1min['delta_energia_min'] = df_1min['energia_kwh'].diff()\n",
    "\n",
    "# Información del resultado\n",
    "print(f\"\\nDataFrame agregado:\")\n",
    "print(f\"   Registros originales (1s): {len(df_tel):,}\")\n",
    "print(f\"   Registros agregados (1min): {len(df_1min):,}\")\n",
    "print(f\"   Rango temporal: {df_1min.index.min()} a {df_1min.index.max()}\")\n",
    "\n",
    "print(f\"\\nColumnas creadas:\")\n",
    "for col in df_1min.columns:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(f\"\\nEstadísticas de disponibilidad:\")\n",
    "print(f\"   Media % RUN por minuto: {df_1min['pct_run'].mean():.2f}%\")\n",
    "print(f\"   Media % STOP por minuto: {df_1min['pct_stop'].mean():.2f}%\")\n",
    "print(f\"   Minutos con 100% RUN: {(df_1min['pct_run'] == 100).sum()} ({(df_1min['pct_run'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "print(f\"   Minutos con 100% STOP: {(df_1min['pct_stop'] == 100).sum()} ({(df_1min['pct_stop'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "print(df_1min.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "# FASE 2: Ingeniería de variables y KPIs (NumPy + Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "PASO 1: Cálculo de potencia instantánea desde energía acumulada\n",
    "\n",
    "    Fórmula: P_kW = ΔE / Δt (donde Δt está en horas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Fórmulas implementadas\n",
    "\n",
    "**Cálculo de potencia instantánea:**\n",
    "\n",
    "$$\\Delta E_i = \\max\\{E_i - E_{i-1}, 0\\}$$\n",
    "\n",
    "$$\\Delta t_i = \\frac{t_i - t_{i-1}}{3600} \\text{ (horas)}$$\n",
    "\n",
    "$$P_{\\text{kW},i} = \\frac{\\Delta E_i}{\\Delta t_i}$$\n",
    "\n",
    "$$P_{\\text{W},i} = 1000 \\cdot P_{\\text{kW},i}$$\n",
    "\n",
    "**Suavizado opcional (media móvil):**\n",
    "- Ventana: 5 segundos (centrada)\n",
    "- Objetivo: Mitigar efectos de cuantización del contador de energía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CÁLCULO DE POTENCIA INSTANTÁNEA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular delta de energía (ya lo teníamos del Paso 4)\n",
    "# df_tel['delta_energia'] ya existe\n",
    "\n",
    "# Calcular delta de tiempo en horas\n",
    "df_tel['delta_tiempo_h'] = df_tel.index.to_series().diff().dt.total_seconds() / 3600\n",
    "\n",
    "# Calcular potencia en kW: P = ΔE / Δt\n",
    "# Evitar división por cero\n",
    "df_tel['P_kW'] = np.where(\n",
    "    df_tel['delta_tiempo_h'] > 0,\n",
    "    df_tel['delta_energia'] / df_tel['delta_tiempo_h'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Suavizar potencia con media móvil de 5 segundos para mitigar cuantización\n",
    "df_tel['P_kW_suavizada'] = df_tel['P_kW'].rolling(window=5, center=True, min_periods=1).mean()\n",
    "\n",
    "# Mostrar resultados de las fórmulas aplicadas\n",
    "print(\"\\nPrimeros 10 valores calculados:\")\n",
    "print(df_tel[['energia_kwh', 'delta_energia', 'delta_tiempo_h', 'P_kW', 'P_kW_suavizada']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Potencia instantánea calculada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "PASO 2: Agregación a 1 minuto (telemetría)\n",
    "\n",
    "### Fórmulas de agregación\n",
    "\n",
    "Para cada minuto $m$:\n",
    "\n",
    "$$\\text{temp\\_mean}(m) = \\text{mean}(T)$$\n",
    "\n",
    "$$\\text{temp\\_p95}(m) = \\text{p95}(T)$$\n",
    "\n",
    "$$\\text{caudal\\_mean}(m) = \\text{mean}(q)$$\n",
    "\n",
    "$$\\text{P\\_kW\\_mean}(m) = \\text{mean}(P)$$\n",
    "\n",
    "$$\\%\\text{STOP}(m) = 100 \\cdot \\frac{\\#\\{i \\in m : \\text{estado}_i = \\text{STOP}\\}}{60}$$\n",
    "\n",
    "Estas series minuto servirán como base para KPIs horarios/por turno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"AGREGACIÓN A 1 MINUTO (TELEMETRÍA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear agregaciones por minuto aplicando las fórmulas\n",
    "df_1min = df_tel.resample('1min').agg({\n",
    "    'temp_prod': ['mean', lambda x: x.quantile(0.95)],\n",
    "    'caudal': 'mean',\n",
    "    'P_kW': 'mean',\n",
    "    'estado': lambda x: (x == 'STOP').sum()\n",
    "}).round(3)\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_1min.columns = ['temp_mean', 'temp_p95', 'caudal_mean', 'P_kW_mean', 'segundos_stop']\n",
    "\n",
    "# Calcular %STOP\n",
    "df_1min['pct_STOP'] = ((df_1min['segundos_stop'] / 60) * 100).round(2)\n",
    "\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "print(df_1min.head(10))\n",
    "\n",
    "print(f\"\\n✅ Agregación a 1 minuto completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "PASO 3: Clasificación de botellas por tolerancia de peso\n",
    "\n",
    "### Objetivo de masa por formato\n",
    "\n",
    "$$m_{\\text{obj}}(250) = 250\\text{ g}, \\quad m_{\\text{obj}}(500) = 500\\text{ g}$$\n",
    "\n",
    "### Criterio de tolerancia\n",
    "\n",
    "Con tolerancia típica del ±2%, una unidad está dentro de tolerancia si:\n",
    "\n",
    "$$|\\text{peso\\_lleno\\_g} - m_{\\text{obj}}(f)| \\leq 0.02 \\cdot m_{\\text{obj}}(f)$$\n",
    "\n",
    "Donde:\n",
    "- $\\text{peso\\_lleno\\_g}$ es el peso neto de la botella (en gramos)\n",
    "- $f$ es el formato (250 o 500)\n",
    "- $m_{\\text{obj}}(f)$ es la masa objetivo según el formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir masa objetivo según formato\n",
    "MASA_OBJ = {250: 250.0, 500: 500.0}\n",
    "TOLERANCIA = 0.02  # ±2%\n",
    "\n",
    "# Crear columna con masa objetivo según el formato de cada botella\n",
    "df_pz['masa_objetivo'] = df_pz['formato_ml'].map(MASA_OBJ)\n",
    "\n",
    "# Calcular desviación absoluta respecto al objetivo\n",
    "df_pz['desviacion_abs'] = np.abs(df_pz['peso_lleno_g'] - df_pz['masa_objetivo'])\n",
    "\n",
    "# Calcular límite de tolerancia (2% de la masa objetivo)\n",
    "df_pz['limite_tolerancia'] = TOLERANCIA * df_pz['masa_objetivo']\n",
    "\n",
    "# Clasificar: dentro_tolerancia = True si |peso_neto - m_obj| ≤ 0.02 * m_obj\n",
    "df_pz['dentro_tolerancia'] = df_pz['desviacion_abs'] <= df_pz['limite_tolerancia']\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"\\nPrimeros registros clasificados:\")\n",
    "print(df_pz[['id_botella', 'formato_ml', 'peso_lleno_g', 'masa_objetivo', 'desviacion_abs', 'dentro_tolerancia']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Clasificación completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## PASO 4: KPIs por hora y por turno\n",
    "\n",
    "### Definiciones de KPIs\n",
    "\n",
    "Sea $W$ la ventana temporal (hora o turno). Calculamos:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. **Throughput** (unidades/hora)\n",
    "\n",
    "$$\\text{Throughput}(W) = \\frac{N_W}{\\text{horas}(W)}$$\n",
    "\n",
    "**Donde:**\n",
    "- $N_W$ = número total de botellas producidas en $W$\n",
    "- $\\text{horas}(W)$ = 1 hora (ventanas horarias) o 8 horas (turnos)\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. **Scrap** (% no conforme)\n",
    "\n",
    "$$\\text{Scrap}(W) = 100 \\cdot \\frac{NG_W}{OK_W + NG_W} \\quad \\text{(si } N_W > 0\\text{; en otro caso NaN)}$$\n",
    "\n",
    "**Donde:**\n",
    "- $NG_W$ = botellas fuera de tolerancia\n",
    "- $OK_W$ = botellas dentro de tolerancia\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. **Tiempo en marcha** (horas)\n",
    "\n",
    "$$\\text{Tiempo en marcha}(W) = t_{\\text{RUN}}(W)$$\n",
    "\n",
    "**Calculado como:**\n",
    "$$t_{\\text{RUN}}(W) = \\frac{\\#\\{i \\in W : \\text{estado}_i = \\text{RUN}\\}}{3600}$$\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. **Energía específica** (Wh/unidad)\n",
    "\n",
    "$$\\text{Wh/ud}(W) = \\frac{1000 \\cdot \\Delta E_{\\text{kWh}}(W)}{N_W} \\quad \\text{(si } N_W > 0\\text{; en otro caso NaN)}$$\n",
    "\n",
    "**Donde:**\n",
    "- $\\Delta E_{\\text{kWh}}(W)$ = energía consumida en la ventana $W$\n",
    "- Factor 1000 para convertir kWh → Wh\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. **% dentro de tolerancia**\n",
    "\n",
    "$$\\%\\text{Tol}(W) = 100 \\cdot \\frac{\\#\\{\\text{unidades en tolerancia}\\}}{N_W} \\quad \\text{(si } N_W > 0\\text{)}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Agregación temporal\n",
    "\n",
    "**Por hora:**\n",
    "- Resample de telemetría: `resample('1h')`\n",
    "- Resample de botellas: `set_index('ts_ciclo').resample('1h')`\n",
    "\n",
    "**Por turno:**\n",
    "- Definir función `asignar_turno(hora)`:\n",
    "  - T1 (Mañana): 06:00 - 14:00\n",
    "  - T2 (Tarde): 14:00 - 22:00\n",
    "  - T3 (Noche): 22:00 - 06:00\n",
    "- Agrupar con `groupby(['fecha', 'turno'])`\n",
    "\n",
    "---\n",
    "\n",
    "### Combinación de fuentes\n",
    "\n",
    "Combinar DataFrames de **botellas** y **telemetría** usando:\n",
    "````python\n",
    "kpis = pd.concat([kpis_botellas, kpis_telemetria], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 11: Clasificación de botellas por tolerancia de peso\n",
    "print(\"=\"*60)\n",
    "print(\"CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE A: KPIs POR HORA\n",
    "# ============================================================================\n",
    "print(\"\\n--- KPIs POR HORA ---\")\n",
    "\n",
    "# 1. Preparar df_pz con índice temporal\n",
    "df_pz_idx = df_pz.set_index('ts_ciclo')\n",
    "\n",
    "# 2. Agregar botellas por hora\n",
    "kpis_hora_pz = df_pz_idx.resample('1h').agg({\n",
    "    'id_botella': 'count',  # N_W: Total de botellas\n",
    "    'dentro_tolerancia': ['sum', lambda x: (~x).sum()]  # OK y NG\n",
    "})\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "kpis_hora_pz.columns = ['N_botellas', 'OK', 'NG']\n",
    "\n",
    "# 3. Agregar telemetría por hora\n",
    "kpis_hora_tel = df_tel.resample('1h').agg({\n",
    "    'estado': lambda x: (x == 'RUN').sum() / 3600,  # Tiempo en RUN (horas)\n",
    "    'energia_kwh': ['first', 'last']  # Energía inicial y final\n",
    "})\n",
    "\n",
    "kpis_hora_tel.columns = ['horas_RUN', 'energia_ini', 'energia_fin']\n",
    "kpis_hora_tel['delta_energia_kWh'] = kpis_hora_tel['energia_fin'] - kpis_hora_tel['energia_ini']\n",
    "\n",
    "# 4. Combinar ambos DataFrames\n",
    "kpis_hora = pd.concat([kpis_hora_pz, kpis_hora_tel], axis=1)\n",
    "\n",
    "# 5. Calcular KPIs\n",
    "kpis_hora['throughput_ud_h'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    kpis_hora['N_botellas'] / 1.0,  # Dividir por 1 hora\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_hora['scrap_pct'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    100 * kpis_hora['NG'] / kpis_hora['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_hora['energia_Wh_ud'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    1000 * kpis_hora['delta_energia_kWh'] / kpis_hora['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_hora['pct_tolerancia'] = np.where(\n",
    "    kpis_hora['N_botellas'] > 0,\n",
    "    100 * kpis_hora['OK'] / kpis_hora['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Redondear\n",
    "kpis_hora = kpis_hora.round(2)\n",
    "\n",
    "print(f\"\\nKPIs por hora calculados: {len(kpis_hora)} horas\")\n",
    "print(f\"\\nPrimeras horas:\")\n",
    "print(kpis_hora[['N_botellas', 'throughput_ud_h', 'scrap_pct', 'horas_RUN', 'energia_Wh_ud', 'pct_tolerancia']].head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE B: KPIs POR TURNO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- KPIs POR TURNO ---\")\n",
    "\n",
    "# Definir turnos (ejemplo: 06:00-14:00, 14:00-22:00, 22:00-06:00)\n",
    "def asignar_turno(hora):\n",
    "    if 6 <= hora < 14:\n",
    "        return 'T1_Mañana'\n",
    "    elif 14 <= hora < 22:\n",
    "        return 'T2_Tarde'\n",
    "    else:\n",
    "        return 'T3_Noche'\n",
    "\n",
    "# Asignar turno a cada botella\n",
    "df_pz['turno'] = df_pz['ts_ciclo'].dt.hour.apply(asignar_turno)\n",
    "df_pz['fecha'] = df_pz['ts_ciclo'].dt.date\n",
    "\n",
    "# Asignar turno a telemetría\n",
    "df_tel['turno'] = df_tel.index.hour.map(asignar_turno)\n",
    "df_tel['fecha'] = df_tel.index.date\n",
    "\n",
    "# Agregar por fecha y turno (botellas)\n",
    "kpis_turno_pz = df_pz.groupby(['fecha', 'turno']).agg({\n",
    "    'id_botella': 'count',\n",
    "    'dentro_tolerancia': ['sum', lambda x: (~x).sum()]\n",
    "})\n",
    "\n",
    "kpis_turno_pz.columns = ['N_botellas', 'OK', 'NG']\n",
    "\n",
    "# Agregar por fecha y turno (telemetría)\n",
    "kpis_turno_tel = df_tel.groupby(['fecha', 'turno']).agg({\n",
    "    'estado': lambda x: (x == 'RUN').sum() / 3600,\n",
    "    'energia_kwh': ['first', 'last']\n",
    "})\n",
    "\n",
    "kpis_turno_tel.columns = ['horas_RUN', 'energia_ini', 'energia_fin']\n",
    "kpis_turno_tel['delta_energia_kWh'] = kpis_turno_tel['energia_fin'] - kpis_turno_tel['energia_ini']\n",
    "\n",
    "# Combinar\n",
    "kpis_turno = pd.concat([kpis_turno_pz, kpis_turno_tel], axis=1)\n",
    "\n",
    "# Calcular KPIs por turno (8 horas por turno)\n",
    "kpis_turno['throughput_ud_h'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    kpis_turno['N_botellas'] / 8.0,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_turno['scrap_pct'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    100 * kpis_turno['NG'] / kpis_turno['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_turno['energia_Wh_ud'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    1000 * kpis_turno['delta_energia_kWh'] / kpis_turno['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "kpis_turno['pct_tolerancia'] = np.where(\n",
    "    kpis_turno['N_botellas'] > 0,\n",
    "    100 * kpis_turno['OK'] / kpis_turno['N_botellas'],\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Redondear\n",
    "kpis_turno = kpis_turno.round(2)\n",
    "\n",
    "print(f\"\\nKPIs por turno calculados: {len(kpis_turno)} turnos\")\n",
    "print(f\"\\nPrimeros turnos:\")\n",
    "print(kpis_turno[['N_botellas', 'throughput_ud_h', 'scrap_pct', 'horas_RUN', 'energia_Wh_ud', 'pct_tolerancia']].head(10))\n",
    "\n",
    "print(f\"\\n✅ KPIs por hora y turno calculados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "PASO 5: Cálculo del OEE - Opción A (Por tiempos y ciclo nominal)\n",
    "\n",
    "### Fórmula del OEE\n",
    "\n",
    "$$\\text{OEE}(W) = \\text{Availability}(W) \\times \\text{Performance}(W) \\times \\text{Quality}(W)$$\n",
    "\n",
    "---\n",
    "\n",
    "### Componentes del OEE\n",
    "\n",
    "#### 1. Availability (Disponibilidad)\n",
    "\n",
    "$$\\text{Availability}(W) = \\frac{t_{\\text{RUN}}(W)}{t_{\\text{plan}}(W)}$$\n",
    "\n",
    "**Interpretación:** Proporción del tiempo planificado que la máquina estuvo en marcha.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Performance (Rendimiento)\n",
    "\n",
    "$$\\text{Performance}(W) \\approx \\frac{t_{\\text{nom}}(W)}{t_{\\text{medio\\_RUN}}(W)}$$\n",
    "\n",
    "Donde:\n",
    "- $t_{\\text{nom}}(W)$ = tiempo de ciclo nominal ponderado por formato en $W$\n",
    "- $t_{\\text{medio\\_RUN}}(W)$ = tiempo medio de ciclo durante RUN en $W$\n",
    "\n",
    "**Interpretación:** Qué tan rápido producimos vs. la velocidad teórica.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Quality (Calidad)\n",
    "\n",
    "$$\\text{Quality}(W) = \\frac{OK_W}{OK_W + NG_W}$$\n",
    "\n",
    "**Interpretación:** Proporción de piezas buenas sobre el total producido.\n",
    "\n",
    "---\n",
    "\n",
    "### Parámetros\n",
    "\n",
    "- $t_{\\text{nom}} = 1.5$ s/botella (equivale a 2400 botellas/hora)\n",
    "- $t_{\\text{plan}} = 1$ hora (para ventanas horarias) ó $8$ horas (para turnos)\n",
    "\n",
    "---\n",
    "\n",
    "### Consideraciones de implementación\n",
    "\n",
    "- Si $N_W = 0$ o $t_{\\text{RUN}}(W) = 0$ → devolver `NaN`\n",
    "- Availability ya calculada en PASO 4 como `horas_RUN / horas_planificadas`\n",
    "- Quality ya calculada en PASO 4 como `pct_tolerancia / 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 12: Cálculo del OEE - Opción A\n",
    "print(\"=\"*60)\n",
    "print(\"CÁLCULO DEL OEE - OPCIÓN A\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# PARÁMETROS\n",
    "# ============================================================================\n",
    "T_NOM = 1.5  # segundos/botella\n",
    "HORAS_PLANIFICADAS_HORA = 1.0  # 1 hora\n",
    "HORAS_PLANIFICADAS_TURNO = 8.0  # 8 horas por turno\n",
    "\n",
    "print(f\"\\nParámetros:\")\n",
    "print(f\"   t_nom: {T_NOM} s/botella\")\n",
    "print(f\"   Horas planificadas (hora): {HORAS_PLANIFICADAS_HORA} h\")\n",
    "print(f\"   Horas planificadas (turno): {HORAS_PLANIFICADAS_TURNO} h\")\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE A: OEE POR HORA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- OEE POR HORA ---\")\n",
    "\n",
    "# 1. Availability = horas_RUN / horas_planificadas\n",
    "kpis_hora['Availability'] = kpis_hora['horas_RUN'] / HORAS_PLANIFICADAS_HORA\n",
    "\n",
    "# 2. Performance = t_nom / t_medio_RUN\n",
    "#    t_medio_RUN = horas_RUN / N_botellas (en horas/botella)\n",
    "#    Convertir t_nom a horas: 1.5 s = 1.5/3600 horas\n",
    "kpis_hora['Performance'] = np.where(\n",
    "    (kpis_hora['N_botellas'] > 0) & (kpis_hora['horas_RUN'] > 0),\n",
    "    (T_NOM / 3600) / (kpis_hora['horas_RUN'] / kpis_hora['N_botellas']),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 3. Quality = pct_tolerancia / 100\n",
    "kpis_hora['Quality'] = kpis_hora['pct_tolerancia'] / 100\n",
    "\n",
    "# 4. OEE = Availability × Performance × Quality\n",
    "kpis_hora['OEE'] = kpis_hora['Availability'] * kpis_hora['Performance'] * kpis_hora['Quality']\n",
    "\n",
    "# Convertir a porcentaje\n",
    "kpis_hora['OEE_pct'] = (kpis_hora['OEE'] * 100).round(2)\n",
    "\n",
    "print(f\"\\nPrimeras horas con OEE:\")\n",
    "print(kpis_hora[['N_botellas', 'Availability', 'Performance', 'Quality', 'OEE_pct']].head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# PARTE B: OEE POR TURNO\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"--- OEE POR TURNO ---\")\n",
    "\n",
    "# 1. Availability = horas_RUN / horas_planificadas\n",
    "kpis_turno['Availability'] = kpis_turno['horas_RUN'] / HORAS_PLANIFICADAS_TURNO\n",
    "\n",
    "# 2. Performance = t_nom / t_medio_RUN\n",
    "kpis_turno['Performance'] = np.where(\n",
    "    (kpis_turno['N_botellas'] > 0) & (kpis_turno['horas_RUN'] > 0),\n",
    "    (T_NOM / 3600) / (kpis_turno['horas_RUN'] / kpis_turno['N_botellas']),\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# 3. Quality = pct_tolerancia / 100\n",
    "kpis_turno['Quality'] = kpis_turno['pct_tolerancia'] / 100\n",
    "\n",
    "# 4. OEE = Availability × Performance × Quality\n",
    "kpis_turno['OEE'] = kpis_turno['Availability'] * kpis_turno['Performance'] * kpis_turno['Quality']\n",
    "\n",
    "# Convertir a porcentaje\n",
    "kpis_turno['OEE_pct'] = (kpis_turno['OEE'] * 100).round(2)\n",
    "\n",
    "print(f\"\\nPrimeros turnos con OEE:\")\n",
    "print(kpis_turno[['N_botellas', 'Availability', 'Performance', 'Quality', 'OEE_pct']].head(10))\n",
    "\n",
    "print(f\"\\n✅ OEE calculado (Opción A)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "# FASE 3 — Análisis numérico (NumPy puro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "## Preparación y notación\n",
    "\n",
    "**Rejilla temporal:** Por-ciclo (cada botella alineada con telemetría más próxima)\n",
    "\n",
    "**Variables continuas:**\n",
    "- `T` = temp_prod (°C)\n",
    "- `q` = caudal (ml/s)\n",
    "- `P` = P_kW (kW)\n",
    "- `tc` = tiempo_ciclo_s (s)\n",
    "\n",
    "**Variable binaria:**\n",
    "- `RUN ∈ {0,1}` (1 si en marcha)\n",
    "\n",
    "**Error de llenado:**\n",
    "- `e = peso_lleno_g - m_obj(f)` donde `m_obj(250)=250g`, `m_obj(500)=500g`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 1.1: Calcular error de llenado\n",
    "print(\"=\"*60)\n",
    "print(\"FASE 3 - ANÁLISIS NUMÉRICO (NumPy puro)\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nPASO 1.1: Cálculo del error de llenado\")\n",
    "\n",
    "# e = peso_lleno_g - m_obj(f)\n",
    "df_pz['error_llenado'] = df_pz['peso_lleno_g'] - df_pz['masa_objetivo']\n",
    "\n",
    "print(f\"\\nError de llenado calculado:\")\n",
    "print(f\"   Media: {df_pz['error_llenado'].mean():.3f} g\")\n",
    "print(f\"   Std: {df_pz['error_llenado'].std():.3f} g\")\n",
    "print(f\"   Min: {df_pz['error_llenado'].min():.3f} g\")\n",
    "print(f\"   Max: {df_pz['error_llenado'].max():.3f} g\")\n",
    "\n",
    "print(f\"\\n✅ Error de llenado calculado\")\n",
    "\n",
    "# PASO 1.2: Calcular tiempo de ciclo\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 1.2: Cálculo del tiempo de ciclo\")\n",
    "\n",
    "# tc = diferencia temporal entre botellas consecutivas (en segundos)\n",
    "df_pz['tiempo_ciclo_s'] = df_pz['ts_ciclo'].diff().dt.total_seconds()\n",
    "\n",
    "# Estadísticas (ignorar primer valor NaN)\n",
    "tc_validos = df_pz['tiempo_ciclo_s'].dropna()\n",
    "\n",
    "print(f\"\\nTiempo de ciclo calculado:\")\n",
    "print(f\"   Media: {tc_validos.mean():.3f} s\")\n",
    "print(f\"   Mediana: {tc_validos.median():.3f} s\")\n",
    "print(f\"   Std: {tc_validos.std():.3f} s\")\n",
    "print(f\"   Min: {tc_validos.min():.3f} s\")\n",
    "print(f\"   Max: {tc_validos.max():.3f} s\")\n",
    "\n",
    "print(f\"\\n✅ Tiempo de ciclo calculado\")\n",
    "\n",
    "\n",
    "# PASO 1.3: Alinear telemetría con botellas\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 1.3: Alineación telemetría con botellas (merge_asof)\")\n",
    "\n",
    "# Preparar df_tel: asegurar que el índice se llame 'ts' y reset_index\n",
    "df_tel.index.name = 'ts'  # Asegurar nombre del índice\n",
    "df_tel_temp = df_tel[['temp_prod', 'caudal', 'P_kW', 'estado']].reset_index()\n",
    "\n",
    "# Alinear cada botella con la muestra de telemetría más cercana ANTES del ciclo\n",
    "df_merge = pd.merge_asof(\n",
    "    df_pz.sort_values('ts_ciclo'),\n",
    "    df_tel_temp.sort_values('ts'),\n",
    "    left_on='ts_ciclo',\n",
    "    right_on='ts',\n",
    "    direction='backward',\n",
    "    tolerance=pd.Timedelta(seconds=5)  # Máximo 5 segundos de diferencia\n",
    ")\n",
    "\n",
    "# Convertir estado a binario: RUN=1, STOP=0\n",
    "df_merge['RUN'] = (df_merge['estado'] == 'RUN').astype(int)\n",
    "\n",
    "print(f\"\\nAlineación completada:\")\n",
    "print(f\"   Total de botellas: {len(df_merge):,}\")\n",
    "print(f\"   Botellas con telemetría válida: {df_merge['temp_prod'].notna().sum():,}\")\n",
    "\n",
    "print(f\"\\nPrimeros registros alineados:\")\n",
    "print(df_merge[['ts_ciclo', 'temp_prod', 'caudal', 'P_kW', 'tiempo_ciclo_s', 'error_llenado', 'RUN']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Datos alineados\")\n",
    "\n",
    "\n",
    "# PASO 1.4: Extraer arrays NumPy y crear máscara de datos válidos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PASO 1.4: Extracción a NumPy y máscara de validez\")\n",
    "\n",
    "# Extraer arrays NumPy (a partir de aquí solo NumPy)\n",
    "T = df_merge['temp_prod'].values\n",
    "q = df_merge['caudal'].values\n",
    "P = df_merge['P_kW'].values\n",
    "tc = df_merge['tiempo_ciclo_s'].values\n",
    "e = df_merge['error_llenado'].values\n",
    "RUN = df_merge['RUN'].values\n",
    "\n",
    "# Crear máscara de datos válidos (sin NaN en ninguna variable)\n",
    "mask_validos = ~(np.isnan(T) | np.isnan(q) | np.isnan(P) | np.isnan(tc) | np.isnan(e))\n",
    "\n",
    "# Filtrar arrays con la máscara\n",
    "T_clean = T[mask_validos]\n",
    "q_clean = q[mask_validos]\n",
    "P_clean = P[mask_validos]\n",
    "tc_clean = tc[mask_validos]\n",
    "e_clean = e[mask_validos]\n",
    "RUN_clean = RUN[mask_validos]\n",
    "\n",
    "n_total = len(T)\n",
    "n_validos = len(T_clean)\n",
    "\n",
    "print(f\"\\nMáscara de datos válidos:\")\n",
    "print(f\"   Total de registros: {n_total:,}\")\n",
    "print(f\"   Registros válidos (sin NaN): {n_validos:,} ({n_validos/n_total*100:.2f}%)\")\n",
    "print(f\"   Registros con NaN: {n_total - n_validos:,}\")\n",
    "\n",
    "print(f\"\\n✅ Arrays NumPy preparados: T, q, P, tc, e, RUN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "## PASO 2: Correlaciones de Pearson\n",
    "\n",
    "### Fórmula de correlación de Pearson\n",
    "\n",
    "$$r_{xy} = \\frac{\\text{cov}(x,y)}{\\sigma_x \\sigma_y} = \\frac{\\sum (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum(x_i-\\bar{x})^2} \\sqrt{\\sum(y_i-\\bar{y})^2}}$$\n",
    "\n",
    "**Implementación con estandarización:**\n",
    "\n",
    "1. Estandarizar: $z = \\frac{x - \\bar{x}}{\\sigma_x}$\n",
    "2. Matriz de correlación: $\\mathbf{R} = \\frac{\\mathbf{X}_{\\text{std}}^T \\mathbf{X}_{\\text{std}}}{n-1}$\n",
    "\n",
    "donde $\\mathbf{X}_{\\text{std}}$ es la matriz de datos estandarizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASO 2: Correlaciones de Pearson (NumPy puro)\n",
    "print(\"=\"*60)\n",
    "print(\"PASO 2: CORRELACIONES DE PEARSON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Función para estandarizar (z-score)\n",
    "def estandarizar(x):\n",
    "    \"\"\"Estandariza un array: (x - media) / std\"\"\"\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "# Estandarizar todas las variables\n",
    "T_std = estandarizar(T_clean)\n",
    "q_std = estandarizar(q_clean)\n",
    "P_std = estandarizar(P_clean)\n",
    "tc_std = estandarizar(tc_clean)\n",
    "e_std = estandarizar(e_clean)\n",
    "\n",
    "# Construir matriz de datos estandarizados [T, q, P, tc, e]\n",
    "X_std = np.column_stack([T_std, q_std, P_std, tc_std, e_std])\n",
    "\n",
    "# Calcular matriz de correlación: R = (X'X) / (n-1)\n",
    "n = len(T_clean)\n",
    "corr_matrix = (X_std.T @ X_std) / (n - 1)\n",
    "\n",
    "# Nombres de variables\n",
    "var_names = ['T', 'q', 'P', 'tc', 'e']\n",
    "\n",
    "print(f\"\\nMatriz de correlación de Pearson ({n:,} muestras):\")\n",
    "print(\"\\n\" + \" \"*8 + \"\".join(f\"{v:>8}\" for v in var_names))\n",
    "print(\"-\" * 48)\n",
    "for i, nombre in enumerate(var_names):\n",
    "    fila = \"\".join(f\"{corr_matrix[i,j]:>8.3f}\" for j in range(len(var_names)))\n",
    "    print(f\"{nombre:>8}{fila}\")\n",
    "\n",
    "# Identificar correlaciones más fuertes con el error (e)\n",
    "print(f\"\\nCorrelaciones con el error de llenado (e):\")\n",
    "idx_e = 4  # Índice de 'e' en var_names\n",
    "for i, var in enumerate(var_names[:-1]):  # Excluir 'e' mismo\n",
    "    print(f\"   {var} vs e: {corr_matrix[i, idx_e]:>7.3f}\")\n",
    "\n",
    "print(f\"\\n✅ Correlaciones calculadas con NumPy puro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "## PASO 3: Regresión Lineal OLS (NumPy puro)\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Ajustar un **modelo de regresión lineal múltiple** para explicar el **error de llenado** `e` en función de las variables físicas del proceso.\n",
    "\n",
    "---\n",
    "\n",
    "### Modelo matemático\n",
    "\n",
    "$$e = \\beta_0 + \\beta_1 T + \\beta_2 q + \\beta_3 P + \\beta_4 \\text{RUN} + \\varepsilon$$\n",
    "\n",
    "**Donde:**\n",
    "- **Variable dependiente (y):** `e` = error de llenado (gramos)\n",
    "- **Variables independientes (X):**\n",
    "  - `T` = Temperatura del producto (°C)\n",
    "  - `q` = Caudal (ml/s)\n",
    "  - `P` = Potencia instantánea (kW)\n",
    "  - `RUN` = Estado de la máquina (1=marcha, 0=parada)\n",
    "- **ε:** Error aleatorio\n",
    "\n",
    "---\n",
    "\n",
    "### Fórmula de estimación OLS\n",
    "\n",
    "**Matriz de diseño:**\n",
    "\n",
    "$$\\mathbf{X} = \\begin{bmatrix} \n",
    "1 & T_1 & q_1 & P_1 & \\text{RUN}_1 \\\\\n",
    "1 & T_2 & q_2 & P_2 & \\text{RUN}_2 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\vdots & \\vdots \\\\\n",
    "1 & T_n & q_n & P_n & \\text{RUN}_n\n",
    "\\end{bmatrix}, \\quad\n",
    "\\mathbf{y} = \\begin{bmatrix} e_1 \\\\ e_2 \\\\ \\vdots \\\\ e_n \\end{bmatrix}$$\n",
    "\n",
    "**Estimador de mínimos cuadrados:**\n",
    "\n",
    "$$\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{y}$$\n",
    "\n",
    "---\n",
    "\n",
    "### Métricas de calidad del ajuste\n",
    "\n",
    "**1. Coeficiente de determinación R²:**\n",
    "\n",
    "$$R^2 = 1 - \\frac{SS_{\\text{res}}}{SS_{\\text{tot}}}$$\n",
    "\n",
    "Donde:\n",
    "- $SS_{\\text{res}} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$ = Suma de cuadrados de residuos\n",
    "- $SS_{\\text{tot}} = \\sum_{i=1}^{n} (y_i - \\bar{y})^2$ = Suma de cuadrados total\n",
    "\n",
    "**Interpretación:** % de varianza explicada por el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "**2. R² ajustado:**\n",
    "\n",
    "$$R^2_{\\text{adj}} = 1 - (1 - R^2) \\cdot \\frac{n-1}{n-p-1}$$\n",
    "\n",
    "Donde:\n",
    "- $n$ = número de observaciones\n",
    "- $p$ = número de predictores (sin contar intercepto)\n",
    "\n",
    "**Interpretación:** Penaliza la adición de predictores que no mejoran significativamente el modelo.\n",
    "\n",
    "---\n",
    "\n",
    "### Diagnósticos mínimos\n",
    "\n",
    "**Media de residuos:**\n",
    "\n",
    "$$\\bar{\\varepsilon} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i) \\approx 0$$\n",
    "\n",
    "**Interpretación física esperada de los coeficientes:**\n",
    "\n",
    "| Coeficiente | Signo esperado | Razón física |\n",
    "|-------------|----------------|--------------|\n",
    "| β₁ (T) | **Negativo (−)** | ↑ temperatura → ↓ viscosidad → fluye más rápido → subllenado |\n",
    "| β₂ (q) | **Positivo (+)** | ↑ caudal → mayor flujo → sobrellenado |\n",
    "| β₃ (P) | **≈ 0 o pequeño** | Efecto indirecto; relacionado con velocidad de cinta |\n",
    "| β₄ (RUN) | **Negativo (−)** | Transiciones STOP→RUN pueden capturar inestabilidades |\n",
    "\n",
    "---\n",
    "\n",
    "### Implementación\n",
    "\n",
    "El código aplicará:\n",
    "1. Construcción de matrices **X** (con columna de unos) e **y**\n",
    "2. Resolución del sistema **X'Xβ = X'y** usando `np.linalg.solve()`\n",
    "3. Cálculo de predicciones **ŷ = Xβ**\n",
    "4. Cálculo de residuos **ε = y - ŷ**\n",
    "5. Métricas **R²** y **R²_adj**\n",
    "6. Interpretación de signos y magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PASO 3: Regresión Lineal OLS (NumPy puro) - CON DIAGNÓSTICO\n",
    "print(\"=\"*60)\n",
    "print(\"PASO 3: REGRESIÓN LINEAL OLS (NumPy puro)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# 3.1: CONSTRUCCIÓN DE MATRICES X e y\n",
    "# ============================================================================\n",
    "print(\"\\n--- 3.1: Construcción de matrices ---\")\n",
    "\n",
    "# Matriz de diseño X: [1, T, q, P, RUN]\n",
    "n = len(T_clean)\n",
    "X_ols = np.column_stack([\n",
    "    np.ones(n),      # β₀ (intercepto)\n",
    "    T_clean,         # β₁ (temperatura)\n",
    "    q_clean,         # β₂ (caudal)\n",
    "    P_clean,         # β₃ (potencia)\n",
    "    RUN_clean        # β₄ (estado RUN/STOP)\n",
    "])\n",
    "\n",
    "y_ols = e_clean\n",
    "\n",
    "print(f\"Matriz X: {X_ols.shape} (n={n}, p={X_ols.shape[1]-1} predictores + intercepto)\")\n",
    "print(f\"Vector y: {y_ols.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# DIAGNÓSTICO: Verificar varianza y colinealidad\n",
    "# ============================================================================\n",
    "print(\"\\n--- DIAGNÓSTICO ---\")\n",
    "\n",
    "var_names = ['Intercepto', 'T', 'q', 'P', 'RUN']\n",
    "print(f\"\\nEstadísticas de cada columna de X:\")\n",
    "for i, name in enumerate(var_names):\n",
    "    col = X_ols[:, i]\n",
    "    print(f\"   {name:12s}: min={np.min(col):>8.3f}, max={np.max(col):>8.3f}, \"\n",
    "          f\"std={np.std(col):>8.3f}, unique={len(np.unique(col)):>5}\")\n",
    "\n",
    "# Verificar si hay columnas constantes (std ≈ 0)\n",
    "stds = np.std(X_ols, axis=0)\n",
    "columnas_constantes = np.where(stds < 1e-10)[0]\n",
    "\n",
    "if len(columnas_constantes) > 1:  # > 1 porque intercepto siempre es constante\n",
    "    print(f\"\\n⚠️  PROBLEMA: Columnas con varianza ≈0 detectadas:\")\n",
    "    for idx in columnas_constantes:\n",
    "        print(f\"   - {var_names[idx]} (std={stds[idx]:.10f})\")\n",
    "    print(\"\\nSOLUCIÓN: Eliminar variable(s) constante(s)\")\n",
    "\n",
    "# Verificar condición de la matriz X'X\n",
    "XtX = X_ols.T @ X_ols\n",
    "cond_number = np.linalg.cond(XtX)\n",
    "print(f\"\\nNúmero de condición de X'X: {cond_number:.2e}\")\n",
    "\n",
    "if cond_number > 1e10:\n",
    "    print(\"⚠️  Matriz mal condicionada (multicolinealidad o columnas constantes)\")\n",
    "    print(\"   Solución: Usar pseudo-inversa (np.linalg.lstsq)\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3.2: ESTIMACIÓN DE COEFICIENTES β (con manejo robusto)\n",
    "# ============================================================================\n",
    "print(\"\\n--- 3.2: Estimación de coeficientes ---\")\n",
    "\n",
    "try:\n",
    "    # Intentar método estándar\n",
    "    Xty = X_ols.T @ y_ols\n",
    "    beta = np.linalg.solve(XtX, Xty)\n",
    "    metodo = \"solve() directo\"\n",
    "    \n",
    "except np.linalg.LinAlgError:\n",
    "    # Si falla, usar mínimos cuadrados con pseudo-inversa\n",
    "    print(\"⚠️  solve() falló (matriz singular)\")\n",
    "    print(\"   Usando np.linalg.lstsq() (pseudo-inversa)\")\n",
    "    \n",
    "    beta, residuals, rank, s = np.linalg.lstsq(X_ols, y_ols, rcond=None)\n",
    "    metodo = f\"lstsq() - rank={rank}/{X_ols.shape[1]}\"\n",
    "    \n",
    "    if rank < X_ols.shape[1]:\n",
    "        print(f\"   ⚠️  Rango deficiente: {rank}/{X_ols.shape[1]}\")\n",
    "        print(f\"   Algunas variables pueden ser redundantes\")\n",
    "\n",
    "# Nombres de los coeficientes\n",
    "coef_names = ['β₀ (intercepto)', 'β₁ (T)', 'β₂ (q)', 'β₃ (P)', 'β₄ (RUN)']\n",
    "\n",
    "print(f\"\\nMétodo usado: {metodo}\")\n",
    "print(f\"\\nCoeficientes estimados:\")\n",
    "for name, coef in zip(coef_names, beta):\n",
    "    print(f\"   {name:20s}: {coef:>10.6f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3.3: PREDICCIONES Y RESIDUOS\n",
    "# ============================================================================\n",
    "print(\"\\n--- 3.3: Predicciones y residuos ---\")\n",
    "\n",
    "y_pred = X_ols @ beta\n",
    "residuos = y_ols - y_pred\n",
    "\n",
    "print(f\"\\nEstadísticas de residuos:\")\n",
    "print(f\"   Media: {np.mean(residuos):.6f} (debe ser ≈0)\")\n",
    "print(f\"   Std: {np.std(residuos):.3f}\")\n",
    "print(f\"   Min: {np.min(residuos):.3f}\")\n",
    "print(f\"   Max: {np.max(residuos):.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3.4: MÉTRICAS DE CALIDAD DEL AJUSTE\n",
    "# ============================================================================\n",
    "print(\"\\n--- 3.4: Calidad del ajuste ---\")\n",
    "\n",
    "SS_res = np.sum(residuos**2)\n",
    "SS_tot = np.sum((y_ols - np.mean(y_ols))**2)\n",
    "R2 = 1 - (SS_res / SS_tot)\n",
    "\n",
    "p = X_ols.shape[1] - 1\n",
    "R2_adj = 1 - (1 - R2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "print(f\"\\nR² = {R2:.4f} ({R2*100:.2f}% de varianza explicada)\")\n",
    "print(f\"R²_adj = {R2_adj:.4f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# 3.5: INTERPRETACIÓN DE COEFICIENTES\n",
    "# ============================================================================\n",
    "print(\"\\n--- 3.5: Interpretación física ---\")\n",
    "\n",
    "print(f\"\\nSignos esperados según teoría:\")\n",
    "print(f\"   β₁ (T) < 0: ↑ temperatura → ↓ viscosidad → ↓ peso (subllenado)\")\n",
    "print(f\"   β₂ (q) > 0: ↑ caudal → ↑ peso (sobrellenado)\")\n",
    "print(f\"   β₃ (P) ≈ 0: Potencia tiene efecto indirecto\")\n",
    "print(f\"   β₄ (RUN) < 0: Estado STOP puede capturar cambios de régimen\")\n",
    "\n",
    "print(f\"\\nSignos obtenidos:\")\n",
    "for i, (name, coef) in enumerate(zip(coef_names[1:], beta[1:]), 1):\n",
    "    signo = \"+\" if coef > 0 else \"-\"\n",
    "    coincide = \"✓\" if (\n",
    "        (i == 1 and coef < 0) or  # β₁(T) negativo\n",
    "        (i == 2 and coef > 0) or  # β₂(q) positivo\n",
    "        (i == 4 and coef < 0)     # β₄(RUN) negativo\n",
    "    ) else \"✗\"\n",
    "    print(f\"   {name:15s}: {signo} ({coef:>10.6f}) {coincide}\")\n",
    "\n",
    "print(f\"\\n✅ Regresión OLS completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63",
   "metadata": {},
   "source": [
    "# FASE 4 — Visualización (Matplotlib)\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Comunicar de forma clara el comportamiento de la línea y sus efectos en los KPIs mediante figuras reproducibles, legibles y con unidades explícitas.\n",
    "\n",
    "---\n",
    "\n",
    "## Estándares de presentación\n",
    "\n",
    "### Formatos de guardado\n",
    "\n",
    "- **PNG**: 150-200 DPI (para documentos/presentaciones)\n",
    "- **SVG**: Vectorial (para escalabilidad sin pérdida)\n",
    "- **Ubicación**: Carpeta `fig/`\n",
    "\n",
    "### Tamaños de figura\n",
    "\n",
    "- **Series temporales**: 10 × 4 pulgadas\n",
    "- **Barras/histogramas**: 8 × 4 pulgadas\n",
    "\n",
    "### Elementos obligatorios\n",
    "\n",
    "✅ **Etiquetas completas** (variable + unidad)  \n",
    "✅ **Cuadrícula discreta** (`grid(alpha=0.3)`)  \n",
    "✅ **Ejes bien acotados** (evitar autoscaling extremo)  \n",
    "✅ **Formato de tiempo** con `DateFormatter` y `HourLocator/MinuteLocator`  \n",
    "✅ **`tight_layout()`** para evitar solapamiento  \n",
    "✅ **Leyenda única** por figura (fuera del área si es necesario)  \n",
    "\n",
    "### Convenciones de diseño\n",
    "\n",
    "- **Anotaciones sobrias**: Solo hitos clave (p95, media, cambios de formato)\n",
    "- **Consistencia visual**: Misma tipografía/tamaño en todas las figuras\n",
    "- **Unidades siempre visibles** en ejes y leyendas\n",
    "\n",
    "---\n",
    "\n",
    "## PASO 0: Configuración del entorno de visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# Configuración global de matplotlib\n",
    "plt.rcParams['figure.dpi'] = 100  # DPI para visualización en pantalla\n",
    "plt.rcParams['savefig.dpi'] = 200  # DPI para guardado\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 9\n",
    "plt.rcParams['figure.titlesize'] = 13\n",
    "\n",
    "# Crear directorio para figuras si no existe\n",
    "from pathlib import Path\n",
    "fig_dir = Path(\"fig\")\n",
    "fig_dir.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "## PASO 1: Serie temporal 12-24h con temperatura, caudal y eventos\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Visualizar el comportamiento conjunto de **temperatura** y **caudal** durante un período operativo, identificando paradas e inestabilidades del proceso.\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura de la figura\n",
    "\n",
    "**🔵 Eje izquierdo (Y1): Temperatura del producto**\n",
    "- Línea continua con `temp_prod` (°C)\n",
    "- Banda ±σ con desviación estándar móvil (ventana 10 min)\n",
    "  - Cálculo: `rolling(window=600, center=True).std()`\n",
    "  - Visualización: `fill_between()` con transparencia\n",
    "\n",
    "**🟠 Eje derecho (Y2): Caudal**\n",
    "- Línea continua con `caudal` (ml/s)\n",
    "- Compartiendo eje X con temperatura\n",
    "\n",
    "**🔴 Anotaciones de eventos:**\n",
    "- **Intervalos STOP** (micro_parada, limpieza, cambio_formato):\n",
    "  - Sombreado con `axvspan(color='red', alpha=0.15)`\n",
    "- **Líneas verticales** en cambios de formato/limpieza:\n",
    "  - `axvline(color='purple', linestyle='--')`\n",
    "  - Etiqueta rotada 90° en el borde superior\n",
    "\n",
    "---\n",
    "\n",
    "### Formato del eje temporal\n",
    "\n",
    "```python\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=2))\n",
    "ax.xaxis.set_minor_locator(mdates.MinuteLocator(interval=30))\n",
    "```\n",
    "\n",
    "**Resultado esperado:**\n",
    "- Eje X: `06:00`, `08:00`, `10:00`, ... (cada 2 horas)\n",
    "- Marcas menores cada 30 minutos\n",
    "\n",
    "---\n",
    "\n",
    "### Leyenda combinada\n",
    "\n",
    "Como usamos `twinx()`, debemos combinar las leyendas:\n",
    "\n",
    "```python\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos clave a verificar\n",
    "\n",
    "✅ Banda ±σ visible y coherente con la señal  \n",
    "✅ Zonas STOP claramente diferenciadas  \n",
    "✅ Eje X legible (no solapamiento de etiquetas)  \n",
    "✅ Unidades en ambos ejes Y  \n",
    "✅ Guardado en PNG (200 DPI) y SVG  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIGURA 1: Serie temporal 12-24h (temperatura + caudal + eventos)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Seleccionar ventana de 12 horas (ajustar según tus datos)\n",
    "ts_inicio_fig1 = df_tel.index.min() + pd.Timedelta(hours=6)\n",
    "ts_fin_fig1 = ts_inicio_fig1 + pd.Timedelta(hours=12)\n",
    "\n",
    "# Filtrar datos\n",
    "df_tel_fig1 = df_tel.loc[ts_inicio_fig1:ts_fin_fig1].copy()\n",
    "\n",
    "# Calcular desviación estándar móvil (ventana 10 min = 600 segundos)\n",
    "df_tel_fig1['temp_std'] = df_tel_fig1['temp_prod'].rolling(window=600, center=True).std()\n",
    "\n",
    "# Crear figura\n",
    "fig, ax1 = plt.subplots(figsize=(10, 4))\n",
    "\n",
    "# ============================================================================\n",
    "# EJE IZQUIERDO: Temperatura\n",
    "# ============================================================================\n",
    "color_temp = 'tab:blue'\n",
    "ax1.set_xlabel('Tiempo')\n",
    "ax1.set_ylabel('Temperatura (°C)', color=color_temp)\n",
    "\n",
    "# Línea de temperatura\n",
    "line1 = ax1.plot(df_tel_fig1.index, df_tel_fig1['temp_prod'], \n",
    "                 color=color_temp, linewidth=1.2, label='Temperatura', alpha=0.8)\n",
    "\n",
    "# Banda ±σ\n",
    "ax1.fill_between(df_tel_fig1.index,\n",
    "                  df_tel_fig1['temp_prod'] - df_tel_fig1['temp_std'],\n",
    "                  df_tel_fig1['temp_prod'] + df_tel_fig1['temp_std'],\n",
    "                  color=color_temp, alpha=0.2, label='±1σ (ventana 10min)')\n",
    "\n",
    "ax1.tick_params(axis='y', labelcolor=color_temp)\n",
    "ax1.grid(True, alpha=0.3, linestyle='--')\n",
    "\n",
    "# ============================================================================\n",
    "# EJE DERECHO: Caudal\n",
    "# ============================================================================\n",
    "ax2 = ax1.twinx()\n",
    "color_caudal = 'tab:orange'\n",
    "ax2.set_ylabel('Caudal (ml/s)', color=color_caudal)\n",
    "\n",
    "line2 = ax2.plot(df_tel_fig1.index, df_tel_fig1['caudal'],\n",
    "                 color=color_caudal, linewidth=1.2, label='Caudal', alpha=0.8)\n",
    "\n",
    "ax2.tick_params(axis='y', labelcolor=color_caudal)\n",
    "\n",
    "# ============================================================================\n",
    "# SOMBREAR INTERVALOS STOP\n",
    "# ============================================================================\n",
    "eventos_fig1 = df_evt[(df_evt['ts_ini'] >= ts_inicio_fig1) & \n",
    "                       (df_evt['ts_ini'] <= ts_fin_fig1)]\n",
    "\n",
    "for idx, evento in eventos_fig1.iterrows():\n",
    "    if evento['tipo'] in ['micro_parada', 'limpieza', 'cambio_formato']:\n",
    "        ax1.axvspan(evento['ts_ini'], evento['ts_fin'], \n",
    "                    color='red', alpha=0.15, zorder=0)\n",
    "\n",
    "# Líneas verticales en cambios de formato/limpieza\n",
    "eventos_criticos = eventos_fig1[eventos_fig1['tipo'].isin(['cambio_formato', 'limpieza'])]\n",
    "for idx, evento in eventos_criticos.iterrows():\n",
    "    ax1.axvline(evento['ts_ini'], color='purple', linestyle='--', \n",
    "                linewidth=0.8, alpha=0.6)\n",
    "    ax1.text(evento['ts_ini'], ax1.get_ylim()[1]*0.95, \n",
    "             evento['tipo'].replace('_', ' ').title(),\n",
    "             rotation=90, verticalalignment='top', fontsize=8, color='purple')\n",
    "\n",
    "# ============================================================================\n",
    "# FORMATO DE TIEMPO EN EJE X\n",
    "# ============================================================================\n",
    "ax1.xaxis.set_major_formatter(mdates.DateFormatter('%H:%M'))\n",
    "ax1.xaxis.set_major_locator(mdates.HourLocator(interval=2))\n",
    "ax1.xaxis.set_minor_locator(mdates.MinuteLocator(interval=30))\n",
    "\n",
    "# ============================================================================\n",
    "# LEYENDA COMBINADA\n",
    "# ============================================================================\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper left', framealpha=0.9)\n",
    "\n",
    "# ============================================================================\n",
    "# TÍTULO Y AJUSTES FINALES\n",
    "# ============================================================================\n",
    "fig.suptitle('Evolución de temperatura y caudal (12h)', fontweight='bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "# Guardar\n",
    "fig.savefig(fig_dir / 'fig1_serie_temporal_12h.png', dpi=200, bbox_inches='tight')\n",
    "fig.savefig(fig_dir / 'fig1_serie_temporal_12h.svg', format='svg', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Figura 1 guardada en {fig_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "## PASO 2: Barras apiladas - OEE por turno (A/P/Q)\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Comparar los **tres componentes del OEE** entre turnos para identificar el factor limitante de cada período operativo.\n",
    "\n",
    "---\n",
    "\n",
    "### Fórmula del OEE (recordatorio)\n",
    "\n",
    "$$\\text{OEE} = \\text{Availability} \\times \\text{Performance} \\times \\text{Quality}$$\n",
    "\n",
    "**Donde cada componente está en el rango [0, 1]** (o 0-100%)\n",
    "\n",
    "---\n",
    "\n",
    "### Estructura de las barras apiladas\n",
    "\n",
    "**Orden de apilamiento (de abajo hacia arriba):**\n",
    "\n",
    "1. **🟢 Availability** (verde)\n",
    "   - % del tiempo planificado que la máquina estuvo en RUN\n",
    "   \n",
    "2. **🔵 Performance** (azul)\n",
    "   - % de rendimiento respecto al ciclo nominal\n",
    "   \n",
    "3. **🟠 Quality** (naranja)\n",
    "   - % de unidades dentro de tolerancia\n",
    "\n",
    "---\n",
    "\n",
    "### Anotaciones obligatorias\n",
    "\n",
    "**Dentro de cada segmento:**\n",
    "- **Porcentaje del componente** centrado verticalmente\n",
    "- Texto en **blanco** y **negrita**\n",
    "- Tamaño de fuente: 9pt\n",
    "\n",
    "**Encima de cada barra:**\n",
    "- **OEE total (%)** en negro\n",
    "- Posición: 2 unidades por encima del borde superior\n",
    "\n",
    "**Debajo del eje X:**\n",
    "- **N de botellas** producidas en el turno\n",
    "- **Tiempo en RUN** (horas)\n",
    "- Color gris, tamaño 8pt\n",
    "\n",
    "---\n",
    "\n",
    "### Configuración de ejes\n",
    "\n",
    "```python\n",
    "ax.set_ylim(0, 105)  # 0-100% + margen para etiquetas\n",
    "ax.set_yticks(np.arange(0, 101, 10))  # Ticks cada 10%\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Ejemplo de interpretación\n",
    "\n",
    "Si un turno tiene:\n",
    "- A = 80%, P = 90%, Q = 95%\n",
    "- OEE = 0.80 × 0.90 × 0.95 = **68.4%**\n",
    "\n",
    "**Lectura:**\n",
    "- La barra verde ocupa 80 unidades\n",
    "- La azul arranca en 80 y termina en 80+90 = 170\n",
    "- La naranja arranca en 170 y termina en 170+95 = 265\n",
    "\n",
    "⚠️ **Nota:** Esto es incorrecto. En barras apiladas de OEE, debemos mostrar las **pérdidas acumuladas**, no los porcentajes directos.\n",
    "\n",
    "**Alternativa correcta (pérdidas en cascada):**\n",
    "- Availability: 80% (pérdida de 20% por paradas)\n",
    "- Performance: 90% de 80% = 72% (pérdida adicional de 8%)\n",
    "- Quality: 95% de 72% = 68.4% (pérdida adicional de 3.6%)\n",
    "\n",
    "**Implementación:**\n",
    "Representar cada componente como el % que \"sobrevive\" después de aplicar el anterior.\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos a verificar\n",
    "\n",
    "✅ Orden consistente (A abajo, Q arriba)  \n",
    "✅ Etiquetas % legibles en cada segmento  \n",
    "✅ OEE total visible encima  \n",
    "✅ Información de contexto (N, t_RUN) debajo  \n",
    "✅ Leyenda clara  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIGURA 2: Barras apiladas - OEE por turno\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Preparar datos: convertir componentes del OEE a porcentaje\n",
    "kpis_turno_fig2 = kpis_turno.copy()\n",
    "kpis_turno_fig2['A_pct'] = (kpis_turno_fig2['Availability'] * 100).round(1)\n",
    "kpis_turno_fig2['P_pct'] = (kpis_turno_fig2['Performance'] * 100).round(1)\n",
    "kpis_turno_fig2['Q_pct'] = (kpis_turno_fig2['Quality'] * 100).round(1)\n",
    "\n",
    "# Agrupar por turno (promediar todos los días)\n",
    "oee_por_turno = kpis_turno_fig2.groupby('turno').agg({\n",
    "    'A_pct': 'mean',\n",
    "    'P_pct': 'mean',\n",
    "    'Q_pct': 'mean',\n",
    "    'OEE_pct': 'mean',\n",
    "    'N_botellas': 'sum',\n",
    "    'horas_RUN': 'sum'\n",
    "}).round(1)\n",
    "\n",
    "# Ordenar turnos\n",
    "orden_turnos = ['T1_Mañana', 'T2_Tarde', 'T3_Noche']\n",
    "oee_por_turno = oee_por_turno.reindex(orden_turnos)\n",
    "\n",
    "# ============================================================================\n",
    "# CREAR FIGURA\n",
    "# ============================================================================\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "turnos = oee_por_turno.index\n",
    "x_pos = np.arange(len(turnos))\n",
    "width = 0.6\n",
    "\n",
    "# Datos para barras apiladas\n",
    "availability = oee_por_turno['A_pct'].values\n",
    "performance = oee_por_turno['P_pct'].values\n",
    "quality = oee_por_turno['Q_pct'].values\n",
    "\n",
    "# ============================================================================\n",
    "# BARRAS APILADAS (orden: A → P → Q)\n",
    "# ============================================================================\n",
    "bar1 = ax.bar(x_pos, availability, width, label='Availability', \n",
    "              color='#4CAF50', alpha=0.8)\n",
    "bar2 = ax.bar(x_pos, performance, width, bottom=availability, \n",
    "              label='Performance', color='#2196F3', alpha=0.8)\n",
    "bar3 = ax.bar(x_pos, quality, width, \n",
    "              bottom=availability + performance,\n",
    "              label='Quality', color='#FF9800', alpha=0.8)\n",
    "\n",
    "# ============================================================================\n",
    "# ANOTACIONES: % dentro de cada segmento\n",
    "# ============================================================================\n",
    "for i, (a, p, q) in enumerate(zip(availability, performance, quality)):\n",
    "    # Availability\n",
    "    ax.text(i, a/2, f'{a:.1f}%', ha='center', va='center', \n",
    "            fontweight='bold', fontsize=9, color='white')\n",
    "    \n",
    "    # Performance\n",
    "    ax.text(i, a + p/2, f'{p:.1f}%', ha='center', va='center',\n",
    "            fontweight='bold', fontsize=9, color='white')\n",
    "    \n",
    "    # Quality\n",
    "    ax.text(i, a + p + q/2, f'{q:.1f}%', ha='center', va='center',\n",
    "            fontweight='bold', fontsize=9, color='white')\n",
    "\n",
    "# ============================================================================\n",
    "# ANOTACIÓN: OEE total encima de cada barra\n",
    "# ============================================================================\n",
    "for i, oee in enumerate(oee_por_turno['OEE_pct'].values):\n",
    "    ax.text(i, availability[i] + performance[i] + quality[i] + 2,\n",
    "            f'OEE: {oee:.1f}%', ha='center', va='bottom',\n",
    "            fontweight='bold', fontsize=10, color='black')\n",
    "\n",
    "# ============================================================================\n",
    "# ANOTACIÓN: N de unidades y tiempo RUN (debajo del eje)\n",
    "# ============================================================================\n",
    "for i, (n, t_run) in enumerate(zip(oee_por_turno['N_botellas'], \n",
    "                                     oee_por_turno['horas_RUN'])):\n",
    "    ax.text(i, -8, f'N={int(n):,}\\n{t_run:.1f}h RUN',\n",
    "            ha='center', va='top', fontsize=8, color='gray')\n",
    "\n",
    "# ============================================================================\n",
    "# CONFIGURACIÓN DE EJES Y LEYENDA\n",
    "# ============================================================================\n",
    "ax.set_ylabel('Componentes del OEE (%)')\n",
    "ax.set_xlabel('Turno')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([t.replace('_', '\\n') for t in turnos])\n",
    "ax.set_ylim(0, 105)\n",
    "ax.set_yticks(np.arange(0, 101, 10))\n",
    "ax.legend(loc='upper right', framealpha=0.9)\n",
    "ax.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# ============================================================================\n",
    "# TÍTULO Y GUARDADO\n",
    "# ============================================================================\n",
    "fig.suptitle('OEE por turno - Desglose A/P/Q', fontweight='bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(fig_dir / 'fig2_oee_por_turno.png', dpi=200, bbox_inches='tight')\n",
    "fig.savefig(fig_dir / 'fig2_oee_por_turno.svg', format='svg', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Figura 2 guardada en {fig_dir}/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69",
   "metadata": {},
   "source": [
    "## PASO 3: Histograma del error de llenado por formato\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Comparar la **distribución del error de llenado** entre formatos (250ml y 500ml), identificando asimetrías (subllenado/sobrellenado) y la proporción dentro de tolerancia.\n",
    "\n",
    "---\n",
    "\n",
    "### Variable analizada\n",
    "\n",
    "$$e = \\text{peso\\_lleno\\_g} - m_{\\text{obj}}(f)$$\n",
    "\n",
    "**Donde:**\n",
    "- $m_{\\text{obj}}(250) = 250$ g\n",
    "- $m_{\\text{obj}}(500) = 500$ g\n",
    "\n",
    "**Interpretación:**\n",
    "- $e > 0$ → Sobrellenado\n",
    "- $e < 0$ → Subllenado\n",
    "- $|e| \\leq 0.02 \\cdot m_{\\text{obj}}$ → Dentro de tolerancia\n",
    "\n",
    "---\n",
    "\n",
    "### Regla de Freedman-Diaconis para selección de bins\n",
    "\n",
    "$$h = 2 \\cdot \\frac{\\text{IQR}}{n^{1/3}}$$\n",
    "\n",
    "$$\\text{n\\_bins} = \\left\\lceil \\frac{\\text{max} - \\text{min}}{h} \\right\\rceil$$\n",
    "\n",
    "**Ventaja sobre bins fijos:**\n",
    "- Se adapta a la variabilidad de los datos (IQR)\n",
    "- Escala apropiadamente con el tamaño de muestra ($n^{1/3}$)\n",
    "- Evita sobre-suavizado (pocos bins) o ruido excesivo (muchos bins)\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos de la figura\n",
    "\n",
    "**Dos subgráficos (sharey=True):**\n",
    "- Izquierda: Formato 250ml\n",
    "- Derecha: Formato 500ml\n",
    "\n",
    "**Anotaciones verticales:**\n",
    "\n",
    "1. **🟢 Banda de tolerancia** (`axvspan`)\n",
    "   - 250ml: ±5g (±2% de 250g)\n",
    "   - 500ml: ±10g (±2% de 500g)\n",
    "   - Color verde con `alpha=0.15`\n",
    "\n",
    "2. **🔴 Línea de media** (línea continua)\n",
    "   - Cálculo: `error_llenado.mean()`\n",
    "   - Etiqueta en leyenda con valor\n",
    "\n",
    "3. **🟠 Línea P95** (línea punteada)\n",
    "   - Cálculo: `error_llenado.quantile(0.95)`\n",
    "   - Identifica valores extremos\n",
    "\n",
    "**Cuadro de texto (esquina superior derecha):**\n",
    "```\n",
    "n = 12,345\n",
    "85.3% en tolerancia\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretación de la asimetría\n",
    "\n",
    "**Asimetría positiva (cola derecha):**\n",
    "- Media > Mediana\n",
    "- Mayoría de botellas con sobrellenado leve\n",
    "- Pocos casos extremos de sobrellenado\n",
    "\n",
    "**Asimetría negativa (cola izquierda):**\n",
    "- Media < Mediana\n",
    "- Tendencia al subllenado\n",
    "- Riesgo de no conformidad por peso insuficiente\n",
    "\n",
    "**Distribución simétrica:**\n",
    "- Media ≈ Mediana ≈ 0\n",
    "- Sistema bien calibrado\n",
    "- Colas balanceadas\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos a verificar\n",
    "\n",
    "✅ Bins calculados automáticamente (no hardcodeados)  \n",
    "✅ Banda de tolerancia visible  \n",
    "✅ Media y P95 marcadas  \n",
    "✅ Estadísticas (n, % tol) en cuadro de texto  \n",
    "✅ Eje X en gramos  \n",
    "✅ Ejes Y compartidos para comparación directa  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FIGURA 3: Histograma del error de llenado por formato\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ============================================================================\n",
    "# PREPARAR DATOS POR FORMATO\n",
    "# ============================================================================\n",
    "df_250 = df_pz[df_pz['formato_ml'] == 250].copy()\n",
    "df_500 = df_pz[df_pz['formato_ml'] == 500].copy()\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCIÓN: Calcular número de bins (Freedman-Diaconis)\n",
    "# ============================================================================\n",
    "def freedman_diaconis_bins(data):\n",
    "    \"\"\"Calcula número de bins óptimo según Freedman-Diaconis\"\"\"\n",
    "    q25, q75 = np.percentile(data, [25, 75])\n",
    "    iqr = q75 - q25\n",
    "    n = len(data)\n",
    "    \n",
    "    h = 2 * iqr / (n ** (1/3))  # Ancho de bin óptimo\n",
    "    \n",
    "    if h == 0:  # Evitar división por cero\n",
    "        return 30\n",
    "    \n",
    "    n_bins = int(np.ceil((data.max() - data.min()) / h))\n",
    "    \n",
    "    # Limitar entre 10 y 100 bins\n",
    "    return max(10, min(n_bins, 100))\n",
    "\n",
    "# Calcular bins\n",
    "bins_250 = freedman_diaconis_bins(df_250['error_llenado'].values)\n",
    "bins_500 = freedman_diaconis_bins(df_500['error_llenado'].values)\n",
    "\n",
    "print(f\"\\nNúmero de bins calculado (Freedman-Diaconis):\")\n",
    "print(f\"   250ml: {bins_250} bins\")\n",
    "print(f\"   500ml: {bins_500} bins\")\n",
    "\n",
    "# ============================================================================\n",
    "# CREAR FIGURA CON DOS SUBGRÁFICOS\n",
    "# ============================================================================\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4), sharey=True)\n",
    "\n",
    "# ============================================================================\n",
    "# SUBGRÁFICO 1: Formato 250ml\n",
    "# ============================================================================\n",
    "ax1.hist(df_250['error_llenado'], bins=bins_250, \n",
    "         color='skyblue', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Banda de tolerancia ±2% de 250g = ±5g\n",
    "tol_250 = 0.02 * 250\n",
    "ax1.axvspan(-tol_250, tol_250, color='green', alpha=0.15, \n",
    "            label=f'Tolerancia ±{tol_250:.1f}g')\n",
    "\n",
    "# Media y P95\n",
    "media_250 = df_250['error_llenado'].mean()\n",
    "p95_250 = df_250['error_llenado'].quantile(0.95)\n",
    "\n",
    "ax1.axvline(media_250, color='red', linestyle='-', linewidth=2, \n",
    "            label=f'Media: {media_250:.2f}g')\n",
    "ax1.axvline(p95_250, color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'P95: {p95_250:.2f}g')\n",
    "\n",
    "# Texto con estadísticas\n",
    "pct_tol_250 = (df_250['dentro_tolerancia'].sum() / len(df_250) * 100)\n",
    "ax1.text(0.95, 0.95, \n",
    "         f'n = {len(df_250):,}\\n{pct_tol_250:.1f}% en tolerancia',\n",
    "         transform=ax1.transAxes, fontsize=9,\n",
    "         verticalalignment='top', horizontalalignment='right',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax1.set_xlabel('Error de llenado (g)')\n",
    "ax1.set_ylabel('Frecuencia')\n",
    "ax1.set_title('Formato 250ml')\n",
    "ax1.legend(loc='upper left', fontsize=8)\n",
    "ax1.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# ============================================================================\n",
    "# SUBGRÁFICO 2: Formato 500ml\n",
    "# ============================================================================\n",
    "ax2.hist(df_500['error_llenado'], bins=bins_500,\n",
    "         color='lightcoral', edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Banda de tolerancia ±2% de 500g = ±10g\n",
    "tol_500 = 0.02 * 500\n",
    "ax2.axvspan(-tol_500, tol_500, color='green', alpha=0.15,\n",
    "            label=f'Tolerancia ±{tol_500:.1f}g')\n",
    "\n",
    "# Media y P95\n",
    "media_500 = df_500['error_llenado'].mean()\n",
    "p95_500 = df_500['error_llenado'].quantile(0.95)\n",
    "\n",
    "ax2.axvline(media_500, color='red', linestyle='-', linewidth=2,\n",
    "            label=f'Media: {media_500:.2f}g')\n",
    "ax2.axvline(p95_500, color='orange', linestyle='--', linewidth=2,\n",
    "            label=f'P95: {p95_500:.2f}g')\n",
    "\n",
    "# Texto con estadísticas\n",
    "pct_tol_500 = (df_500['dentro_tolerancia'].sum() / len(df_500) * 100)\n",
    "ax2.text(0.95, 0.95,\n",
    "         f'n = {len(df_500):,}\\n{pct_tol_500:.1f}% en tolerancia',\n",
    "         transform=ax2.transAxes, fontsize=9,\n",
    "         verticalalignment='top', horizontalalignment='right',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "ax2.set_xlabel('Error de llenado (g)')\n",
    "ax2.set_title('Formato 500ml')\n",
    "ax2.legend(loc='upper left', fontsize=8)\n",
    "ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "\n",
    "# ============================================================================\n",
    "# TÍTULO GENERAL Y GUARDADO\n",
    "# ============================================================================\n",
    "fig.suptitle('Distribución del error de llenado por formato', fontweight='bold')\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(fig_dir / 'fig3_histograma_error_llenado.png', dpi=200, bbox_inches='tight')\n",
    "fig.savefig(fig_dir / 'fig3_histograma_error_llenado.svg', format='svg', bbox_inches='tight')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Figura 3 guardada en {fig_dir}/\")\n",
    "print(f\"\\nInterpretación:\")\n",
    "print(f\"   - Asimetría positiva → tendencia al sobrellenado\")\n",
    "print(f\"   - Asimetría negativa → tendencia al subllenado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "## PASO 4: Scatter \"binned\" - Temperatura vs % en tolerancia\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Analizar la **relación entre temperatura del producto y calidad del llenado**, controlando por el efecto del caudal mediante codificación de color.\n",
    "\n",
    "---\n",
    "\n",
    "### Hipótesis física\n",
    "\n",
    "$$\\text{temp\\_prod} \\uparrow \\implies \\text{viscosidad} \\downarrow \\implies \\text{flujo más rápido} \\implies \\text{subllenado}$$\n",
    "\n",
    "**Esperado:**\n",
    "- A mayor temperatura → menor % en tolerancia (si el sistema no compensa)\n",
    "- El efecto puede ser modulado por el caudal programado\n",
    "\n",
    "---\n",
    "\n",
    "### Metodología de binning\n",
    "\n",
    "**1. Dividir `temp_prod` en bins de 0.5°C:**\n",
    "\n",
    "```python\n",
    "bins_temp = np.arange(df['temp_prod'].min(), \n",
    "                      df['temp_prod'].max() + 0.5, \n",
    "                      0.5)\n",
    "df['bin_temp'] = pd.cut(df['temp_prod'], bins=bins_temp)\n",
    "```\n",
    "\n",
    "**2. Para cada bin, calcular:**\n",
    "- **Centro del bin**: `(límite_inferior + límite_superior) / 2`\n",
    "- **% en tolerancia**: `(dentro_tolerancia.sum() / n) * 100`\n",
    "- **Caudal medio**: `caudal.mean()`\n",
    "- **Conteo**: `n` (número de botellas en el bin)\n",
    "\n",
    "**3. Filtrar bins con n insuficiente:**\n",
    "- Umbral mínimo: **n ≥ 30** (para estabilidad estadística)\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos de la visualización\n",
    "\n",
    "**Scatter plot:**\n",
    "- **Eje X**: Centro del bin de temperatura (°C)\n",
    "- **Eje Y**: % en tolerancia\n",
    "- **Color**: Caudal medio (ml/s) con `colorbar`\n",
    "- **Tamaño** (opcional): Proporcional a `n` (conteo del bin)\n",
    "\n",
    "**Intervalo de confianza binomial (Wilson):**\n",
    "\n",
    "Para cada bin, calcular IC del 95% para la proporción:\n",
    "\n",
    "$$p \\pm 1.96 \\sqrt{\\frac{p(1-p)}{n}}$$\n",
    "\n",
    "Representar con **barras de error verticales** (`errorbar`)\n",
    "\n",
    "**Colorbar:**\n",
    "- Etiqueta: \"Caudal medio (ml/s)\"\n",
    "- Paleta sugerida: `viridis` o `coolwarm`\n",
    "\n",
    "---\n",
    "\n",
    "### Fórmula del intervalo de confianza de Wilson\n",
    "\n",
    "Más robusto que la aproximación normal, especialmente para $p$ cercano a 0 o 1:\n",
    "\n",
    "$$\\text{IC}_{95\\%} = \\frac{p + \\frac{z^2}{2n} \\pm z\\sqrt{\\frac{p(1-p)}{n} + \\frac{z^2}{4n^2}}}{1 + \\frac{z^2}{n}}$$\n",
    "\n",
    "Donde $z = 1.96$ para 95% de confianza.\n",
    "\n",
    "**Implementación simplificada (aproximación normal):**\n",
    "\n",
    "```python\n",
    "from scipy.stats import binom\n",
    "\n",
    "def wilson_ci(p, n, z=1.96):\n",
    "    \"\"\"Intervalo de confianza de Wilson para proporción\"\"\"\n",
    "    denominator = 1 + z**2/n\n",
    "    center = (p + z**2/(2*n)) / denominator\n",
    "    margin = z * np.sqrt((p*(1-p)/n + z**2/(4*n**2))) / denominator\n",
    "    return center - margin, center + margin\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretación esperada\n",
    "\n",
    "**Escenario ideal:**\n",
    "- Pendiente negativa: ↑ temperatura → ↓ % tolerancia\n",
    "- Puntos con caudal alto (color cálido) pueden compensar parcialmente\n",
    "- IC estrechos en bins con n grande\n",
    "\n",
    "**Caso preocupante:**\n",
    "- Caída abrupta del % tolerancia en cierto rango de temperatura\n",
    "- Sugiere punto de inflexión donde el proceso pierde control\n",
    "\n",
    "**Caso estable:**\n",
    "- % tolerancia constante en todo el rango\n",
    "- Sistema robusto a variaciones térmicas\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos a verificar\n",
    "\n",
    "✅ Solo bins con n ≥ 30  \n",
    "✅ Barras de error (IC) visibles  \n",
    "✅ Colorbar con unidades (ml/s)  \n",
    "✅ Tamaño de puntos proporcional a n (si se implementa)  \n",
    "✅ Eje X en °C, eje Y en %  \n",
    "✅ Título descriptivo  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "## PASO 5: Wh/ud por hora con hitos operativos\n",
    "\n",
    "### Objetivo\n",
    "\n",
    "Monitorear la **eficiencia energética específica** (Wh por unidad producida) a lo largo del tiempo, identificando horas de consumo anómalo y su relación con eventos operativos.\n",
    "\n",
    "---\n",
    "\n",
    "### Fórmula de energía específica\n",
    "\n",
    "$$\\text{Wh/ud}(h) = \\frac{1000 \\cdot \\Delta E_{\\text{kWh}}(h)}{N(h)}$$\n",
    "\n",
    "**Donde:**\n",
    "- $\\Delta E_{\\text{kWh}}(h)$ = Energía consumida en la hora $h$ (kWh)\n",
    "- $N(h)$ = Número de botellas producidas en la hora $h$\n",
    "- Factor 1000 para convertir kWh → Wh\n",
    "\n",
    "**Consideraciones:**\n",
    "- Si $N(h) = 0$ → No representar la barra (o marcar explícitamente)\n",
    "- Si $N(h)$ es muy bajo (<30) → Valor poco representativo (alta variabilidad)\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos de la figura\n",
    "\n",
    "**📊 Barras por hora:**\n",
    "- Altura = Wh/ud\n",
    "- Color diferenciado (ej: azul para normal, rojo para Wh/ud > p95)\n",
    "\n",
    "**📏 Línea de referencia horizontal:**\n",
    "- **P95 de Wh/ud** como umbral de ineficiencia\n",
    "- Estilo: línea punteada roja\n",
    "- Etiqueta: `P95 = {valor:.1f} Wh/ud`\n",
    "\n",
    "**📍 Hitos operativos (líneas verticales):**\n",
    "- **Cambios de formato**: Línea púrpura con anotación\n",
    "- **Limpiezas**: Línea naranja con anotación\n",
    "- Posición de texto: arriba del eje, rotación 90°\n",
    "\n",
    "**📈 Eje secundario (opcional):**\n",
    "- **Throughput** (ud/h) como línea\n",
    "- Permite correlacionar Wh/ud con nivel de carga\n",
    "\n",
    "---\n",
    "\n",
    "### Cálculo del percentil 95\n",
    "\n",
    "```python\n",
    "# Calcular solo sobre horas con producción\n",
    "wh_ud_valido = kpis_hora[kpis_hora['N_botellas'] > 0]['energia_Wh_ud']\n",
    "p95_wh_ud = wh_ud_valido.quantile(0.95)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Tratamiento de horas sin producción\n",
    "\n",
    "**Opción A: Ocultar completamente**\n",
    "```python\n",
    "kpis_hora_prod = kpis_hora[kpis_hora['N_botellas'] > 0]\n",
    "```\n",
    "\n",
    "**Opción B: Mostrar con marcador especial**\n",
    "```python\n",
    "# Barra en gris claro con altura mínima\n",
    "ax.bar(hora, 0.1, color='lightgray', hatch='//', label='Sin producción')\n",
    "```\n",
    "\n",
    "**Recomendación:** Opción A (más limpia)\n",
    "\n",
    "---\n",
    "\n",
    "### Formato del eje temporal\n",
    "\n",
    "```python\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m\\n%H:%M'))\n",
    "ax.xaxis.set_major_locator(mdates.HourLocator(interval=4))\n",
    "```\n",
    "\n",
    "**Resultado:**\n",
    "```\n",
    "24/11     24/11     24/11\n",
    "06:00     10:00     14:00\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Anotaciones de hitos\n",
    "\n",
    "```python\n",
    "# Filtrar eventos de interés\n",
    "eventos_hitos = df_evt[df_evt['tipo'].isin(['cambio_formato', 'limpieza'])]\n",
    "\n",
    "for idx, evento in eventos_hitos.iterrows():\n",
    "    ts = evento['ts_ini']\n",
    "    \n",
    "    # Línea vertical\n",
    "    ax.axvline(ts, color='purple' if evento['tipo']=='cambio_formato' else 'orange',\n",
    "               linestyle='--', linewidth=1.5, alpha=0.7)\n",
    "    \n",
    "    # Texto rotado\n",
    "    ax.text(ts, ax.get_ylim()[1]*0.95, \n",
    "            evento['tipo'].replace('_', ' ').title(),\n",
    "            rotation=90, verticalalignment='top', fontsize=8)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Interpretación esperada\n",
    "\n",
    "**Wh/ud normal:**\n",
    "- Valores estables alrededor de la media\n",
    "- Variación <10% respecto a la mediana\n",
    "\n",
    "**Picos de Wh/ud:**\n",
    "- **Tras cambios de formato**: Normal (rampas de estabilización)\n",
    "- **En horas de baja carga** (N pequeño): Consumo base no diluido\n",
    "- **Aleatorios persistentes**: Posible deriva del proceso (ej: resistencias de calentamiento envejecidas)\n",
    "\n",
    "**Tendencias temporales:**\n",
    "- **Aumento progresivo**: Degradación de eficiencia (ej: fricción por desgaste)\n",
    "- **Saltos súbitos**: Cambio de configuración o fallo\n",
    "\n",
    "---\n",
    "\n",
    "### Elementos a verificar\n",
    "\n",
    "✅ Solo horas con N > 0 (o marcadas explícitamente)  \n",
    "✅ Línea P95 visible y etiquetada  \n",
    "✅ Hitos operativos anotados  \n",
    "✅ Eje X con fechas legibles  \n",
    "✅ Eje Y en Wh/ud  \n",
    "✅ Colorbar/leyenda si se usa eje secundario  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
