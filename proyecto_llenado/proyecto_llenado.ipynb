{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a58ce4",
   "metadata": {},
   "source": [
    "# Proyecto 1 — Estación de llenado y taponado\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb3bd33",
   "metadata": {},
   "source": [
    "Importación de las librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6f4a8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d78916",
   "metadata": {},
   "source": [
    "Definir las rutas de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "49beaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"data\")\n",
    "\n",
    "telemetria_file = data_path / \"telemetria.csv\"\n",
    "eventos_file = data_path / \"eventos.csv\"\n",
    "botellas_file = data_path / \"botellas.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ba8245",
   "metadata": {},
   "source": [
    "# FASE 1 --->Ingesta y validación (Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657c0a79",
   "metadata": {},
   "source": [
    "\n",
    "PASO 1: Carga y tipado de datos\n",
    "\n",
    "    1.1 Definir tipos de datos explícitos para cada CSV utilizando un diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "faa031ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dtype_tel = {\n",
    "    'temp_prod': 'float32',\n",
    "    'vel_cinta': 'float32',\n",
    "    'caudal': 'float32',\n",
    "    'energia_kwh': 'float64'\n",
    "}\n",
    "\n",
    "dtype_evt = {\n",
    "    'tipo': 'category',\n",
    "    'id_botella': 'Int64'\n",
    "}\n",
    "\n",
    "dtype_pz = {\n",
    "    'id_botella': 'int64',\n",
    "    'peso_neto': 'float32',\n",
    "    'formato': 'category'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db836bc4",
   "metadata": {},
   "source": [
    "    1.2 Cargar los csv en los dataFrames parseando el tiempo a datetime64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f12c248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar telemetría con parseo de fecha\n",
    "df_tel = pd.read_csv(\n",
    "    telemetria_file,\n",
    "    dtype=dtype_tel,\n",
    "    parse_dates=['ts'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "# Convertir ts a UTC y establecer como índice\n",
    "df_tel['ts'] = pd.to_datetime(df_tel['ts'], utc=True) # Convierte a datetime con zona horaria UTC\n",
    "df_tel = df_tel.set_index('ts').sort_index() # Establece la columna de tiempo como índice del DataFrame\n",
    "\n",
    "# Cargar eventos\n",
    "df_evt = pd.read_csv(\n",
    "    eventos_file,\n",
    "    dtype=dtype_evt,\n",
    "    parse_dates=['ts_ini', 'ts_fin'],\n",
    "    date_format='ISO8601'\n",
    ") # Lee el CSV y convierte automáticamente las columnas de fecha\n",
    "df_evt['ts_ini'] = pd.to_datetime(df_evt['ts_ini'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt['ts_fin'] = pd.to_datetime(df_evt['ts_fin'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_evt = df_evt.sort_values('ts_ini').reset_index(drop=True)\n",
    "\n",
    "# Cargar botellas\n",
    "df_pz = pd.read_csv(\n",
    "    botellas_file,\n",
    "    dtype=dtype_pz,\n",
    "    parse_dates=['ts_ciclo'],\n",
    "    date_format='ISO8601'\n",
    ")\n",
    "df_pz['ts_ciclo'] = pd.to_datetime(df_pz['ts_ciclo'], utc=True) #Convierte a datetime con zona horaria UTC\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True) #\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aef66b8",
   "metadata": {},
   "source": [
    "PASO 2. Orden y duplicados\n",
    "\n",
    "    2.1 Telemetría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "84130e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telemetria:\n",
      "Duplicados eliminados: 0\n",
      "Índice monótono: True\n",
      "No hay timestamps duplicados\n"
     ]
    }
   ],
   "source": [
    "print(\"Telemetria:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "duplicados_antes_tel = df_tel.duplicated().sum()\n",
    "df_tel = df_tel[~df_tel.duplicated(keep='first')]\n",
    "\n",
    "#df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Verificar monotonía del índice\n",
    "es_monotono_tel = df_tel.index.is_monotonic_increasing #Comprobacion de la monotonia: Los indices temporales avanzan correctamente de menor a mayor\n",
    "\n",
    "print(f\"Duplicados eliminados: {duplicados_antes_tel}\")\n",
    "print(f\"Índice monótono: {es_monotono_tel}\")\n",
    "\n",
    "# Verificar si hay duplicados en el índice temporal\n",
    "duplicados_index = df_tel.index.duplicated().sum()\n",
    "if duplicados_index > 0:\n",
    "    print(f\"Hay {duplicados_index} timestamps duplicados en el índice\")\n",
    "    df_tel = df_tel[~df_tel.index.duplicated(keep='first')]\n",
    "else:\n",
    "    print(\"No hay timestamps duplicados\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858598a8",
   "metadata": {},
   "source": [
    "    2.2 Eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e0c877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eventos:\n",
      "Duplicados eliminados: 0\n",
      "Orden por ts_ini monótono: True\n",
      "Eventos con ts_fin < ts_ini: 0\n",
      "Timestamps ts_ini duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Eventos:\")\n",
    "# Eliminar duplicados exactos en telemetría\n",
    "dup_evt = df_evt.duplicated().sum()\n",
    "df_evt = df_evt[~df_evt.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por tiempo de inicio (y fin como desempate)\n",
    "df_evt = df_evt.sort_values(['ts_ini', 'ts_fin']).reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_evt = df_evt['ts_ini'].is_monotonic_increasing\n",
    "neg_dur = (df_evt['ts_fin'] < df_evt['ts_ini']).sum()\n",
    "dup_ts_ini = df_evt['ts_ini'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_evt}\")\n",
    "print(f\"Orden por ts_ini monótono: {es_monotono_evt}\")\n",
    "print(f\"Eventos con ts_fin < ts_ini: {neg_dur}\")\n",
    "print(f\"Timestamps ts_ini duplicados: {dup_ts_ini}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28764a4",
   "metadata": {},
   "source": [
    "    2.3 Botellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9fc0860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Botellas:\n",
      "Duplicados eliminados: 0\n",
      "Orden por ts_ciclo monótono: True\n",
      "Timestamps ts_ciclo duplicados: 0\n",
      "id_botella duplicados: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Botellas:\")\n",
    "dup_pz = df_pz.duplicated().sum()\n",
    "df_pz = df_pz[~df_pz.duplicated(keep='first')]\n",
    "\n",
    "# Ordenar por ts_ciclo\n",
    "df_pz = df_pz.sort_values('ts_ciclo').reset_index(drop=True)\n",
    "\n",
    "# Chequeos\n",
    "es_monotono_pz = df_pz['ts_ciclo'].is_monotonic_increasing\n",
    "dup_ts_ciclo = df_pz['ts_ciclo'].duplicated().sum()\n",
    "dup_id_botella = df_pz['id_botella'].duplicated().sum()\n",
    "\n",
    "print(f\"Duplicados eliminados: {dup_pz}\")\n",
    "print(f\"Orden por ts_ciclo monótono: {es_monotono_pz}\")\n",
    "print(f\"Timestamps ts_ciclo duplicados: {dup_ts_ciclo}\")\n",
    "print(f\"id_botella duplicados: {dup_id_botella}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef0f7dd",
   "metadata": {},
   "source": [
    "PASO 3: Validaciones de rango\n",
    "\n",
    "    3.1 Marcar valores fuera de rango (sin eliminar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c35d8d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDACIÓN DE RANGOS\n",
      "============================================================\n",
      "temp_prod fuera de [18.0, 35.0] °C: 0 (0.00%)\n",
      "vel_cinta fuera de [0.0, 0.5] m/s: 0 (0.00%)\n",
      "caudal fuera de [0.0, 12.0] ml/s: 0 (0.00%)\n",
      "\n",
      "Estadísticas descriptivas:\n",
      "           temp_prod      vel_cinta         caudal    energia_kwh\n",
      "count  129601.000000  129601.000000  129601.000000  129601.000000\n",
      "mean       25.646635       0.269995       7.735915      64.876601\n",
      "std         2.545803       0.092667       2.532649      37.845824\n",
      "min        18.000000       0.000000       0.000000       0.000000\n",
      "25%        23.802999       0.246000       7.443000      31.746546\n",
      "50%        25.648001       0.284000       8.321000      64.762093\n",
      "75%        27.365999       0.330000       9.101000      97.557688\n",
      "max        33.855000       0.380000      11.723000     130.067508\n"
     ]
    }
   ],
   "source": [
    "RANGO_TEMP = (18.0,35.0)\n",
    "RANGO_VEL = (0.0,0.5)\n",
    "RANGO_CAUDAL = (0.0,12.0)\n",
    "\n",
    "df_tel['fuera_RANGO_TEMP'] = (df_tel['temp_prod'] < RANGO_TEMP[0]) | (df_tel['temp_prod'] > RANGO_TEMP[1])\n",
    "df_tel['fuera_RANGO_VEL'] = (df_tel['vel_cinta'] < RANGO_VEL[0]) | (df_tel['vel_cinta'] > RANGO_VEL[1])\n",
    "df_tel['fuera_RANGO_CAUDAL'] = (df_tel['caudal'] < RANGO_CAUDAL[0]) | (df_tel['caudal'] > RANGO_CAUDAL[1])\n",
    "\n",
    "n_temp_fuera = df_tel['fuera_RANGO_TEMP'].sum()\n",
    "n_vel_fuera = df_tel['fuera_RANGO_VEL'].sum()\n",
    "n_caudal_fuera = df_tel['fuera_RANGO_CAUDAL'].sum()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE RANGOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"temp_prod fuera de [{RANGO_TEMP[0]}, {RANGO_TEMP[1]}] °C: {n_temp_fuera} ({n_temp_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"vel_cinta fuera de [{RANGO_VEL[0]}, {RANGO_VEL[1]}] m/s: {n_vel_fuera} ({n_vel_fuera/len(df_tel)*100:.2f}%)\")\n",
    "print(f\"caudal fuera de [{RANGO_CAUDAL[0]}, {RANGO_CAUDAL[1]}] ml/s: {n_caudal_fuera} ({n_caudal_fuera/len(df_tel)*100:.2f}%)\")\n",
    "\n",
    "# Mostrar estadísticas descriptivas\n",
    "print(\"\\nEstadísticas descriptivas:\")\n",
    "print(df_tel[['temp_prod', 'vel_cinta', 'caudal', 'energia_kwh']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a3eeaf",
   "metadata": {},
   "source": [
    "    3.2 Validar que energia_kwh no decrece (salvo cuantización)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3a121c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDACIÓN DE ENERGÍA NO DECRECIENTE\n",
      "============================================================\n",
      "Total de cambios: 129,600\n",
      "Decrementos detectados: 0 (0.000%)\n",
      "\n",
      " No se detectaron decrementos en energia_kwh\n"
     ]
    }
   ],
   "source": [
    "# Calcular diferencias entre valores consecutivos de energía\n",
    "df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "\n",
    "# Contar cuántas veces la energía DECRECE (delta < 0)\n",
    "# Nota: diff() genera NaN en la primera fila, lo ignoramos\n",
    "decrementos = (df_tel['delta_energia'] < 0).sum() \n",
    "total_cambios = df_tel['delta_energia'].notna().sum() #Va a contar cuantas veces decrece\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN DE ENERGÍA NO DECRECIENTE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total de cambios: {total_cambios:,}\")\n",
    "print(f\"Decrementos detectados: {decrementos} ({decrementos/total_cambios*100:.3f}%)\")\n",
    "\n",
    "# Mostrar algunos ejemplos de decrementos (si existen)\n",
    "if decrementos > 0:\n",
    "    print(\"\\n Ejemplos de energía que decrece:\")\n",
    "    ejemplos_decremento = df_tel[df_tel['delta_energia'] < 0][['energia_kwh', 'delta_energia']].head(10)\n",
    "    print(ejemplos_decremento)\n",
    "    \n",
    "    # Estadísticas de los decrementos\n",
    "    print(\"\\n Estadísticas de los decrementos:\")\n",
    "    print(df_tel[df_tel['delta_energia'] < 0]['delta_energia'].describe())\n",
    "else:\n",
    "    print(\"\\n No se detectaron decrementos en energia_kwh\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af01bab0",
   "metadata": {},
   "source": [
    "PASO 4: Monotonicidad de energía (corrección de decrementos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23534c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No se requieren correcciones en energia_kwh\n",
      "La señal es naturalmente monótona creciente\n",
      "\n",
      "Verificación final: 0 decrementos después de corrección\n"
     ]
    }
   ],
   "source": [
    "# PASO 4: Corregir decrementos de energía (si los hubiera)\n",
    "# Guardamos la columna original para comparación\n",
    "df_tel['energia_kwh_original'] = df_tel['energia_kwh'].copy()\n",
    "\n",
    "# Identificar decrementos\n",
    "decrementos_mask = df_tel['delta_energia'] < 0\n",
    "n_correcciones = decrementos_mask.sum()\n",
    "\n",
    "if n_correcciones > 0:\n",
    "    print(f\"Se encontraron {n_correcciones} decrementos. Corrigiendo...\")\n",
    "    \n",
    "    # Hacer clip de deltas negativos a 0\n",
    "    df_tel['delta_energia_corregida'] = df_tel['delta_energia'].clip(lower=0)\n",
    "    \n",
    "    # Reconstruir energía acumulada desde el primer valor\n",
    "    energia_inicial = df_tel['energia_kwh'].iloc[0]\n",
    "    df_tel['energia_kwh'] = energia_inicial + df_tel['delta_energia_corregida'].fillna(0).cumsum()\n",
    "    \n",
    "    # Recalcular delta_energia con valores corregidos\n",
    "    df_tel['delta_energia'] = df_tel['energia_kwh'].diff()\n",
    "    \n",
    "    print(f\"{n_correcciones} correcciones aplicadas\")\n",
    "else:\n",
    "    print(\"No se requieren correcciones en energia_kwh\")\n",
    "    print(\"La señal es naturalmente monótona creciente\")\n",
    "\n",
    "# Verificación final\n",
    "decrementos_final = (df_tel['delta_energia'] < 0).sum()\n",
    "print(f\"\\nVerificación final: {decrementos_final} decrementos después de corrección\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2d090",
   "metadata": {},
   "source": [
    "PASO 5: Frecuencia y huecos temporales\n",
    "\n",
    "    5.1 Confirmar frecuencia nominal de 1 Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "873af9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ANÁLISIS DE FRECUENCIA DE MUESTREO\n",
      "============================================================\n",
      "\n",
      "Muestras con intervalo de 1s: 129600/129600\n",
      "\n",
      "Huecos detectados (intervalos > 1s): 0\n",
      "El numero de huecos es: 0\n",
      "La frecuencia nominal es de 1 Hz. Todos los saltos son de un segundo\n",
      "No es necesario interpolar ni marcar segmentos invalidos\n"
     ]
    }
   ],
   "source": [
    "# 5.1 Analizar la frecuencia de muestreo\n",
    "print(\"=\"*60)\n",
    "print(\"ANÁLISIS DE FRECUENCIA DE MUESTREO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular diferencias de tiempo entre muestras consecutivas\n",
    "time_diffs = df_tel.index.to_series().diff()\n",
    "\n",
    "# Contar muestras con intervalo de 1 segundo\n",
    "intervalo_1s = time_diffs == pd.Timedelta(seconds=1)\n",
    "n_1s = intervalo_1s.sum()\n",
    "total = len(time_diffs) - 1  # -1 porque el primer valor es NaN\n",
    "\n",
    "print(f\"\\nMuestras con intervalo de 1s: {n_1s}/{total}\")\n",
    "\n",
    "# Identificar huecos (intervalos > 1s)\n",
    "huecos = time_diffs[time_diffs > pd.Timedelta(seconds=1)]\n",
    "n_huecos = len(huecos)\n",
    "\n",
    "print(f\"\\nHuecos detectados (intervalos > 1s): {n_huecos}\")\n",
    "\n",
    "if n_huecos > 0:\n",
    "    print(f\"\\nEstadísticas de los huecos:\")\n",
    "    print(huecos.describe())\n",
    "    \n",
    "    # Clasificar huecos\n",
    "    huecos_pequenos = huecos[huecos <= pd.Timedelta(seconds=10)]\n",
    "    huecos_grandes = huecos[huecos > pd.Timedelta(seconds=10)]\n",
    "    \n",
    "    print(f\"\\nHuecos pequeños (≤10s): {len(huecos_pequenos)}\")\n",
    "    print(f\"Huecos grandes (>10s): {len(huecos_grandes)}\")\n",
    "else:\n",
    "    print(f\"El numero de huecos es: {n_huecos}\")\n",
    "    print(\"La frecuencia nominal es de 1 Hz. Todos los saltos son de un segundo\")\n",
    "    print(\"No es necesario interpolar ni marcar segmentos invalidos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e235834",
   "metadata": {},
   "source": [
    "    5.2 Reindexar a rejilla de 1 segundo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "01a14063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "REINDEXACIÓN A REJILLA DE 1 SEGUNDO\n",
      "============================================================\n",
      "\n",
      "Rango temporal:\n",
      "   Inicio: 2025-02-12 08:00:00+00:00\n",
      "   Fin: 2025-02-13 20:00:00+00:00\n",
      "   Duración: 1 days 12:00:00\n",
      "\n",
      "Tamaño de los datos:\n",
      "   Muestras originales: 129,601\n",
      "   Rejilla de 1s: 129,601\n",
      "   Diferencia (huecos): 0\n",
      "\n",
      "DataFrame reindexado\n"
     ]
    }
   ],
   "source": [
    "# 5.2 Reindexar a rejilla regular de 1 segundo\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REINDEXACIÓN A REJILLA DE 1 SEGUNDO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear rejilla temporal de 1s desde el primer al último timestamp\n",
    "ts_inicio = df_tel.index.min()\n",
    "ts_fin = df_tel.index.max()\n",
    "rejilla_1s = pd.date_range(start=ts_inicio, end=ts_fin, freq='1s')\n",
    "\n",
    "print(f\"\\nRango temporal:\")\n",
    "print(f\"   Inicio: {ts_inicio}\")\n",
    "print(f\"   Fin: {ts_fin}\")\n",
    "print(f\"   Duración: {ts_fin - ts_inicio}\")\n",
    "\n",
    "print(f\"\\nTamaño de los datos:\")\n",
    "print(f\"   Muestras originales: {len(df_tel):,}\")\n",
    "print(f\"   Rejilla de 1s: {len(rejilla_1s):,}\")\n",
    "print(f\"   Diferencia (huecos): {len(rejilla_1s) - len(df_tel):,}\")\n",
    "\n",
    "# Reindexar el DataFrame a la rejilla de 1s\n",
    "df_tel = df_tel.reindex(rejilla_1s)\n",
    "\n",
    "print(f\"\\nDataFrame reindexado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3405109",
   "metadata": {},
   "source": [
    "5.3 Rellenar huecos pequeños (≤10s) con interpolación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "359c9c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "RELLENADO DE HUECOS PEQUEÑOS (≤10s)\n",
      "============================================================\n",
      "\n",
      "Bloques de NaN detectados:\n",
      "   Total de bloques: 0\n",
      "   Bloques ≤10s: 0 (se interpolarán)\n",
      "   Bloques >10s: 0 (se marcarán como inválidos)\n",
      "\n",
      "Interpolando temp_prod y caudal...\n",
      "Forward-fill en vel_cinta...\n"
     ]
    }
   ],
   "source": [
    "# 5.3 Rellenar huecos ≤ 10s\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RELLENADO DE HUECOS PEQUEÑOS (≤10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Identificar bloques de NaN consecutivos\n",
    "df_tel['es_nan'] = df_tel['temp_prod'].isna()\n",
    "df_tel['bloque_nan'] = (df_tel['es_nan'] != df_tel['es_nan'].shift()).cumsum()\n",
    "\n",
    "# Calcular tamaño de cada bloque de NaN\n",
    "tamano_bloques = df_tel[df_tel['es_nan']].groupby('bloque_nan').size()\n",
    "\n",
    "# Clasificar bloques\n",
    "bloques_pequenos = tamano_bloques[tamano_bloques <= 10]\n",
    "bloques_grandes = tamano_bloques[tamano_bloques > 10]\n",
    "\n",
    "print(f\"\\nBloques de NaN detectados:\")\n",
    "print(f\"   Total de bloques: {len(tamano_bloques)}\")\n",
    "print(f\"   Bloques ≤10s: {len(bloques_pequenos)} (se interpolarán)\")\n",
    "print(f\"   Bloques >10s: {len(bloques_grandes)} (se marcarán como inválidos)\")\n",
    "\n",
    "# Crear máscara para huecos pequeños (≤10s)\n",
    "mask_huecos_pequenos = df_tel['bloque_nan'].isin(bloques_pequenos.index) & df_tel['es_nan']\n",
    "\n",
    "# Interpolación lineal para temp_prod y caudal en huecos pequeños\n",
    "print(f\"\\nInterpolando temp_prod y caudal...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'temp_prod'] = df_tel['temp_prod'].interpolate(method='linear', limit=10)\n",
    "df_tel.loc[mask_huecos_pequenos, 'caudal'] = df_tel['caudal'].interpolate(method='linear', limit=10)\n",
    "\n",
    "# Forward-fill para vel_cinta (propagar último valor válido)\n",
    "print(f\"Forward-fill en vel_cinta...\")\n",
    "df_tel.loc[mask_huecos_pequenos, 'vel_cinta'] = df_tel['vel_cinta'].ffill(limit=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c32aca",
   "metadata": {},
   "source": [
    "    5.4 Marcar huecos grandes (>10s) como inválidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06242975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MARCADO DE HUECOS GRANDES (>10s)\n",
      "============================================================\n",
      "\n",
      "Segmentos marcados como inválidos:\n",
      "   Total de segundos inválidos: 0\n",
      "   Porcentaje: 0.00%\n",
      "\n",
      "✅ Proceso de huecos completado\n"
     ]
    }
   ],
   "source": [
    "# 5.4 Marcar huecos grandes como inválidos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MARCADO DE HUECOS GRANDES (>10s)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna para marcar segmentos inválidos\n",
    "mask_huecos_grandes = df_tel['bloque_nan'].isin(bloques_grandes.index) & df_tel['es_nan']\n",
    "df_tel['segmento_invalido'] = mask_huecos_grandes\n",
    "\n",
    "# Contar segundos marcados como inválidos\n",
    "n_invalidos = df_tel['segmento_invalido'].sum()\n",
    "total_segundos = len(df_tel)\n",
    "\n",
    "print(f\"\\nSegmentos marcados como inválidos:\")\n",
    "print(f\"   Total de segundos inválidos: {n_invalidos:,}\")\n",
    "print(f\"   Porcentaje: {n_invalidos/total_segundos*100:.2f}%\")\n",
    "\n",
    "if len(bloques_grandes) > 0:\n",
    "    print(f\"\\nDetalle de huecos grandes:\")\n",
    "    for i, (bloque_id, tamano) in enumerate(bloques_grandes.items(), 1):\n",
    "        inicio_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.min()\n",
    "        fin_hueco = df_tel[df_tel['bloque_nan'] == bloque_id].index.max()\n",
    "        print(f\"   Hueco {i}: {tamano}s desde {inicio_hueco} hasta {fin_hueco}\")\n",
    "        if i >= 5:\n",
    "            print(f\"   ... y {len(bloques_grandes)-5} huecos más\")\n",
    "            break\n",
    "\n",
    "# Limpiar columnas auxiliares\n",
    "df_tel = df_tel.drop(columns=['es_nan', 'bloque_nan'])\n",
    "\n",
    "print(f\"\\n✅ Proceso de huecos completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e50ca",
   "metadata": {},
   "source": [
    "PASO 6: Detección de atípicos\n",
    "\n",
    "    6.1 Detección por z-score (umbral ±3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee0c9b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DETECCIÓN DE ATÍPICOS POR Z-SCORE\n",
      "============================================================\n",
      "\n",
      "Atípicos detectados (|z-score| > 3):\n",
      "   temp_prod: 43 (0.033%)\n",
      "   vel_cinta: 0 (0.000%)\n",
      "   caudal: 10833 (8.359%)\n",
      "\n",
      "Ejemplos de atípicos en temp_prod:\n",
      "                           temp_prod    z_temp\n",
      "2025-02-13 03:59:56+00:00       18.0 -3.003624\n",
      "2025-02-13 03:59:57+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:03+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:04+00:00       18.0 -3.003624\n",
      "2025-02-13 04:00:05+00:00       18.0 -3.003624\n"
     ]
    }
   ],
   "source": [
    "# 6.1 Detección de atípicos por z-score\n",
    "print(\"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR Z-SCORE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral estándar: valores con |z-score| > 3 son atípicos\n",
    "UMBRAL_Z = 3\n",
    "\n",
    "# Calcular z-score para cada variable\n",
    "# z-score = (valor - media) / desviación estándar\n",
    "df_tel['z_temp'] = (df_tel['temp_prod'] - df_tel['temp_prod'].mean()) / df_tel['temp_prod'].std()\n",
    "df_tel['z_vel'] = (df_tel['vel_cinta'] - df_tel['vel_cinta'].mean()) / df_tel['vel_cinta'].std()\n",
    "df_tel['z_caudal'] = (df_tel['caudal'] - df_tel['caudal'].mean()) / df_tel['caudal'].std()\n",
    "\n",
    "# Marcar atípicos (|z| > 3)\n",
    "df_tel['atipico_z_temp'] = df_tel['z_temp'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_vel'] = df_tel['z_vel'].abs() > UMBRAL_Z\n",
    "df_tel['atipico_z_caudal'] = df_tel['z_caudal'].abs() > UMBRAL_Z\n",
    "\n",
    "# Contar atípicos detectados\n",
    "n_atip_temp = df_tel['atipico_z_temp'].sum()\n",
    "n_atip_vel = df_tel['atipico_z_vel'].sum()\n",
    "n_atip_caudal = df_tel['atipico_z_caudal'].sum()\n",
    "\n",
    "print(f\"\\nAtípicos detectados (|z-score| > {UMBRAL_Z}):\")\n",
    "print(f\"   temp_prod: {n_atip_temp} ({n_atip_temp/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   vel_cinta: {n_atip_vel} ({n_atip_vel/len(df_tel)*100:.3f}%)\")\n",
    "print(f\"   caudal: {n_atip_caudal} ({n_atip_caudal/len(df_tel)*100:.3f}%)\")\n",
    "\n",
    "# Mostrar ejemplos si existen\n",
    "if n_atip_temp > 0:\n",
    "    print(\"\\nEjemplos de atípicos en temp_prod:\")\n",
    "    print(df_tel[df_tel['atipico_z_temp']][['temp_prod', 'z_temp']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b40235",
   "metadata": {},
   "source": [
    "    6.2 Detección por IQR (rango intercuartílico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b2d62e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DETECCIÓN DE ATÍPICOS POR IQR\n",
      "============================================================\n",
      "\n",
      "temp_prod:\n",
      "   Q1: 23.803\n",
      "   Q3: 27.366\n",
      "   IQR: 3.563\n",
      "   Límites: [18.458, 32.710]\n",
      "   Atípicos: 125 (0.096%)\n",
      "\n",
      "vel_cinta:\n",
      "   Q1: 0.246\n",
      "   Q3: 0.330\n",
      "   IQR: 0.084\n",
      "   Límites: [0.120, 0.456]\n",
      "   Atípicos: 10833 (8.359%)\n",
      "\n",
      "caudal:\n",
      "   Q1: 7.443\n",
      "   Q3: 9.101\n",
      "   IQR: 1.658\n",
      "   Límites: [4.956, 11.588]\n",
      "   Atípicos: 10834 (8.360%)\n"
     ]
    }
   ],
   "source": [
    "# 6.2 Detección de atípicos por IQR\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DETECCIÓN DE ATÍPICOS POR IQR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular cuartiles y rango intercuartílico (IQR)\n",
    "# IQR = Q3 - Q1\n",
    "# Límites: [Q1 - 1.5*IQR, Q3 + 1.5*IQR]\n",
    "\n",
    "for var in ['temp_prod', 'vel_cinta', 'caudal']:\n",
    "    Q1 = df_tel[var].quantile(0.25)\n",
    "    Q3 = df_tel[var].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Marcar atípicos\n",
    "    col_name = f'atipico_iqr_{var.split(\"_\")[0]}'  # atipico_iqr_temp, atipico_iqr_vel, atipico_iqr_caudal\n",
    "    df_tel[col_name] = (df_tel[var] < limite_inferior) | (df_tel[var] > limite_superior)\n",
    "    \n",
    "    n_atipicos = df_tel[col_name].sum()\n",
    "    \n",
    "    print(f\"\\n{var}:\")\n",
    "    print(f\"   Q1: {Q1:.3f}\")\n",
    "    print(f\"   Q3: {Q3:.3f}\")\n",
    "    print(f\"   IQR: {IQR:.3f}\")\n",
    "    print(f\"   Límites: [{limite_inferior:.3f}, {limite_superior:.3f}]\")\n",
    "    print(f\"   Atípicos: {n_atipicos} ({n_atipicos/len(df_tel)*100:.3f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad4f3e3",
   "metadata": {},
   "source": [
    "    6.3 Consolidar marcas de atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "362cd0b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONSOLIDACIÓN DE ATÍPICOS\n",
      "============================================================\n",
      "\n",
      "Registros con al menos un valor atípico:\n",
      "   Total: 10,959\n",
      "   Porcentaje: 8.46%\n",
      "\n",
      "Comparación de métodos:\n",
      "   Z-score: 10,876\n",
      "   IQR: 10,959\n"
     ]
    }
   ],
   "source": [
    "# 6.3 Consolidar detección de atípicos\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONSOLIDACIÓN DE ATÍPICOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear columna que marca si hay algún atípico (OR lógico)\n",
    "# Un registro es atípico si al menos una variable lo es (por cualquier método)\n",
    "df_tel['es_atipico'] = (\n",
    "    df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal'] |\n",
    "    df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']\n",
    ")\n",
    "\n",
    "total_atipicos = df_tel['es_atipico'].sum()\n",
    "porcentaje = total_atipicos / len(df_tel) * 100\n",
    "\n",
    "print(f\"\\nRegistros con al menos un valor atípico:\")\n",
    "print(f\"   Total: {total_atipicos:,}\")\n",
    "print(f\"   Porcentaje: {porcentaje:.2f}%\")\n",
    "\n",
    "# Resumen por método\n",
    "print(f\"\\nComparación de métodos:\")\n",
    "print(f\"   Z-score: {(df_tel['atipico_z_temp'] | df_tel['atipico_z_vel'] | df_tel['atipico_z_caudal']).sum():,}\")\n",
    "print(f\"   IQR: {(df_tel['atipico_iqr_temp'] | df_tel['atipico_iqr_vel'] | df_tel['atipico_iqr_caudal']).sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a92c2f",
   "metadata": {},
   "source": [
    "PASO 7: Etiqueta RUN/STOP por segundo\n",
    "\n",
    "    7.1 Construir máscara de paradas desde eventos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9bb9b0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONSTRUCCIÓN DE MÁSCARA RUN/STOP\n",
      "============================================================\n",
      "\n",
      "Eventos de parada encontrados:\n",
      "   Total: 78\n",
      "   micro_parada: 71\n",
      "   cambio_formato: 5\n",
      "   limpieza: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Segundos marcados como STOP por eventos: 10,755 (8.30%)\n"
     ]
    }
   ],
   "source": [
    "# 7.1 Construir máscara STOP_evt desde eventos.csv\n",
    "print(\"=\"*60)\n",
    "print(\"CONSTRUCCIÓN DE MÁSCARA RUN/STOP\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Filtrar eventos que implican parada\n",
    "eventos_parada = df_evt[df_evt['tipo'].isin(['micro_parada', 'cambio_formato', 'limpieza'])].copy()\n",
    "\n",
    "print(f\"\\nEventos de parada encontrados:\")\n",
    "print(f\"   Total: {len(eventos_parada)}\")\n",
    "print(f\"   micro_parada: {(eventos_parada['tipo'] == 'micro_parada').sum()}\")\n",
    "print(f\"   cambio_formato: {(eventos_parada['tipo'] == 'cambio_formato').sum()}\")\n",
    "print(f\"   limpieza: {(eventos_parada['tipo'] == 'limpieza').sum()}\")\n",
    "\n",
    "# Inicializar columna STOP_evt en False (por defecto está en marcha)\n",
    "df_tel['STOP_evt'] = False\n",
    "\n",
    "# Marcar como True los segundos que caen en intervalos [ts_ini, ts_fin)\n",
    "for idx, evento in eventos_parada.iterrows():\n",
    "    mascara_tiempo = (df_tel.index >= evento['ts_ini']) & (df_tel.index < evento['ts_fin'])\n",
    "    df_tel.loc[mascara_tiempo, 'STOP_evt'] = True\n",
    "\n",
    "n_stop_evt = df_tel['STOP_evt'].sum()\n",
    "print(f\"\\nSegundos marcados como STOP por eventos: {n_stop_evt:,} ({n_stop_evt/len(df_tel)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9425947",
   "metadata": {},
   "source": [
    "7.2 Definir RUN basado en velocidad de cinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "119ee02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DEFINICIÓN DE RUN_vel\n",
      "============================================================\n",
      "\n",
      "Umbral de velocidad: 0.05 m/s\n",
      "Segundos con RUN_vel=True: 118,768\n",
      "Segundos con RUN_vel=False: 10,833\n"
     ]
    }
   ],
   "source": [
    "# 7.2 Definir RUN_vel basado en velocidad de cinta\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"DEFINICIÓN DE RUN_vel\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Umbral de velocidad para considerar que la máquina está en marcha\n",
    "UMBRAL_VEL_RUN = 0.05  # m/s\n",
    "\n",
    "# RUN_vel = True si vel_cinta >= 0.05 m/s\n",
    "df_tel['RUN_vel'] = df_tel['vel_cinta'] >= UMBRAL_VEL_RUN\n",
    "\n",
    "n_run_vel = df_tel['RUN_vel'].sum()\n",
    "print(f\"\\nUmbral de velocidad: {UMBRAL_VEL_RUN} m/s\")\n",
    "print(f\"Segundos con RUN_vel=True: {n_run_vel:,}\")\n",
    "print(f\"Segundos con RUN_vel=False: {len(df_tel)-n_run_vel:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8252d970",
   "metadata": {},
   "source": [
    "7.3 Combinar en estado final (RUN/STOP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5def909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "COMBINACIÓN DE CONDICIONES\n",
      "============================================================\n",
      "\n",
      "Distribución de estados:\n",
      "   RUN: 118,768\n",
      "   STOP: 10,833\n",
      "\n",
      "Transiciones de estado detectadas: 151\n"
     ]
    }
   ],
   "source": [
    "# 7.3 Definir estado final: RUN si RUN_vel=True Y STOP_evt=False\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMBINACIÓN DE CONDICIONES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# estado = RUN si (RUN_vel AND NOT STOP_evt), STOP en otro caso\n",
    "df_tel['estado'] = 'STOP'\n",
    "df_tel.loc[df_tel['RUN_vel'] & ~df_tel['STOP_evt'], 'estado'] = 'RUN'\n",
    "\n",
    "# Convertir a tipo category para ahorrar memoria\n",
    "df_tel['estado'] = df_tel['estado'].astype('category')\n",
    "\n",
    "# Contar estados\n",
    "n_run = (df_tel['estado'] == 'RUN').sum()\n",
    "n_stop = (df_tel['estado'] == 'STOP').sum()\n",
    "\n",
    "print(f\"\\nDistribución de estados:\")\n",
    "print(f\"   RUN: {n_run:,}\")\n",
    "print(f\"   STOP: {n_stop:,}\")\n",
    "\n",
    "# Análisis de transiciones\n",
    "df_tel['cambio_estado'] = df_tel['estado'] != df_tel['estado'].shift()\n",
    "n_transiciones = df_tel['cambio_estado'].sum() - 1  # -1 para excluir el primer valor\n",
    "\n",
    "print(f\"\\nTransiciones de estado detectadas: {n_transiciones}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c44588",
   "metadata": {},
   "source": [
    "PASO 8: Agregación a 1 minuto (diagnóstico temprano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2c3ea154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGREGACIÓN A 1 MINUTO\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame agregado:\n",
      "   Registros originales (1s): 129,601\n",
      "   Registros agregados (1min): 2,161\n",
      "   Rango temporal: 2025-02-12 08:00:00+00:00 a 2025-02-13 20:00:00+00:00\n",
      "\n",
      "Columnas creadas:\n",
      "   - temp_mean\n",
      "   - temp_p95\n",
      "   - caudal_mean\n",
      "   - vel_cinta_mean\n",
      "   - energia_kwh\n",
      "   - segundos_stop\n",
      "   - pct_stop\n",
      "   - segundos_run\n",
      "   - pct_run\n",
      "   - delta_energia_min\n",
      "\n",
      "Estadísticas de disponibilidad:\n",
      "   Media % RUN por minuto: 91.65%\n",
      "   Media % STOP por minuto: 8.35%\n",
      "   Minutos con 100% RUN: 1910 (88.39%)\n",
      "   Minutos con 100% STOP: 120 (5.55%)\n",
      "\n",
      "Primeros registros:\n",
      "                           temp_mean  temp_p95  caudal_mean  vel_cinta_mean  \\\n",
      "2025-02-12 08:00:00+00:00  24.997999    25.672          0.0             0.0   \n",
      "2025-02-12 08:01:00+00:00  24.575001    24.756          0.0             0.0   \n",
      "2025-02-12 08:02:00+00:00  24.604000    24.876          0.0             0.0   \n",
      "2025-02-12 08:03:00+00:00  25.184000    25.523          0.0             0.0   \n",
      "2025-02-12 08:04:00+00:00  25.219000    25.513          0.0             0.0   \n",
      "\n",
      "                           energia_kwh  segundos_stop  pct_stop  segundos_run  \\\n",
      "2025-02-12 08:00:00+00:00        0.018             60     100.0             0   \n",
      "2025-02-12 08:01:00+00:00        0.038             60     100.0             0   \n",
      "2025-02-12 08:02:00+00:00        0.057             60     100.0             0   \n",
      "2025-02-12 08:03:00+00:00        0.076             60     100.0             0   \n",
      "2025-02-12 08:04:00+00:00        0.096             60     100.0             0   \n",
      "\n",
      "                           pct_run  delta_energia_min  \n",
      "2025-02-12 08:00:00+00:00      0.0                NaN  \n",
      "2025-02-12 08:01:00+00:00      0.0              0.020  \n",
      "2025-02-12 08:02:00+00:00      0.0              0.019  \n",
      "2025-02-12 08:03:00+00:00      0.0              0.019  \n",
      "2025-02-12 08:04:00+00:00      0.0              0.020  \n"
     ]
    }
   ],
   "source": [
    "# PASO 8: Agregación temporal a 1 minuto\n",
    "print(\"=\"*60)\n",
    "print(\"AGREGACIÓN A 1 MINUTO\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear agregaciones por minuto\n",
    "df_1min = df_tel.resample('1min').agg({\n",
    "    'temp_prod': ['mean', lambda x: x.quantile(0.95)],\n",
    "    'caudal': 'mean',\n",
    "    'vel_cinta': 'mean',\n",
    "    'energia_kwh': 'last',  # Último valor del minuto (acumulado)\n",
    "    'estado': lambda x: (x == 'STOP').sum()  # Contar segundos en STOP\n",
    "}).round(3)\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_1min.columns = ['temp_mean', 'temp_p95', 'caudal_mean', 'vel_cinta_mean', 'energia_kwh', 'segundos_stop']\n",
    "\n",
    "# Calcular métricas derivadas\n",
    "df_1min['pct_stop'] = (df_1min['segundos_stop'] / 60 * 100).round(2)\n",
    "df_1min['segundos_run'] = 60 - df_1min['segundos_stop']\n",
    "df_1min['pct_run'] = (df_1min['segundos_run'] / 60 * 100).round(2)\n",
    "\n",
    "# Calcular delta de energía por minuto\n",
    "df_1min['delta_energia_min'] = df_1min['energia_kwh'].diff()\n",
    "\n",
    "# Información del resultado\n",
    "print(f\"\\nDataFrame agregado:\")\n",
    "print(f\"   Registros originales (1s): {len(df_tel):,}\")\n",
    "print(f\"   Registros agregados (1min): {len(df_1min):,}\")\n",
    "print(f\"   Rango temporal: {df_1min.index.min()} a {df_1min.index.max()}\")\n",
    "\n",
    "print(f\"\\nColumnas creadas:\")\n",
    "for col in df_1min.columns:\n",
    "    print(f\"   - {col}\")\n",
    "\n",
    "print(f\"\\nEstadísticas de disponibilidad:\")\n",
    "print(f\"   Media % RUN por minuto: {df_1min['pct_run'].mean():.2f}%\")\n",
    "print(f\"   Media % STOP por minuto: {df_1min['pct_stop'].mean():.2f}%\")\n",
    "print(f\"   Minutos con 100% RUN: {(df_1min['pct_run'] == 100).sum()} ({(df_1min['pct_run'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "print(f\"   Minutos con 100% STOP: {(df_1min['pct_stop'] == 100).sum()} ({(df_1min['pct_stop'] == 100).sum()/len(df_1min)*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "print(df_1min.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7288176",
   "metadata": {},
   "source": [
    "# FASE 2: Ingeniería de variables y KPIs (NumPy + Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2ba5c6",
   "metadata": {},
   "source": [
    "PASO 1: Cálculo de potencia instantánea desde energía acumulada\n",
    "\n",
    "    Fórmula: P_kW = ΔE / Δt (donde Δt está en horas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28ef3fe",
   "metadata": {},
   "source": [
    "### Fórmulas implementadas\n",
    "\n",
    "**Cálculo de potencia instantánea:**\n",
    "\n",
    "$$\\Delta E_i = \\max\\{E_i - E_{i-1}, 0\\}$$\n",
    "\n",
    "$$\\Delta t_i = \\frac{t_i - t_{i-1}}{3600} \\text{ (horas)}$$\n",
    "\n",
    "$$P_{\\text{kW},i} = \\frac{\\Delta E_i}{\\Delta t_i}$$\n",
    "\n",
    "$$P_{\\text{W},i} = 1000 \\cdot P_{\\text{kW},i}$$\n",
    "\n",
    "**Suavizado opcional (media móvil):**\n",
    "- Ventana: 5 segundos (centrada)\n",
    "- Objetivo: Mitigar efectos de cuantización del contador de energía"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31d17c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CÁLCULO DE POTENCIA INSTANTÁNEA\n",
      "============================================================\n",
      "\n",
      "Primeros 10 valores calculados:\n",
      "                           energia_kwh  delta_energia  delta_tiempo_h    P_kW  \\\n",
      "2025-02-12 08:00:00+00:00     0.000000            NaN             NaN  0.0000   \n",
      "2025-02-12 08:00:01+00:00     0.000336       0.000336        0.000278  1.2096   \n",
      "2025-02-12 08:00:02+00:00     0.000625       0.000289        0.000278  1.0404   \n",
      "2025-02-12 08:00:03+00:00     0.000943       0.000318        0.000278  1.1448   \n",
      "2025-02-12 08:00:04+00:00     0.001175       0.000232        0.000278  0.8352   \n",
      "2025-02-12 08:00:05+00:00     0.001420       0.000245        0.000278  0.8820   \n",
      "2025-02-12 08:00:06+00:00     0.001709       0.000289        0.000278  1.0404   \n",
      "2025-02-12 08:00:07+00:00     0.002075       0.000366        0.000278  1.3176   \n",
      "2025-02-12 08:00:08+00:00     0.002328       0.000253        0.000278  0.9108   \n",
      "2025-02-12 08:00:09+00:00     0.002617       0.000289        0.000278  1.0404   \n",
      "\n",
      "                           P_kW_suavizada  \n",
      "2025-02-12 08:00:00+00:00         0.75000  \n",
      "2025-02-12 08:00:01+00:00         0.84870  \n",
      "2025-02-12 08:00:02+00:00         0.84600  \n",
      "2025-02-12 08:00:03+00:00         1.02240  \n",
      "2025-02-12 08:00:04+00:00         0.98856  \n",
      "2025-02-12 08:00:05+00:00         1.04400  \n",
      "2025-02-12 08:00:06+00:00         0.99720  \n",
      "2025-02-12 08:00:07+00:00         1.03824  \n",
      "2025-02-12 08:00:08+00:00         1.15416  \n",
      "2025-02-12 08:00:09+00:00         1.24200  \n",
      "\n",
      "✅ Potencia instantánea calculada\n"
     ]
    }
   ],
   "source": [
    "# PASO 9: Calcular potencia instantánea\n",
    "print(\"=\"*60)\n",
    "print(\"CÁLCULO DE POTENCIA INSTANTÁNEA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Calcular delta de energía (ya lo teníamos del Paso 4)\n",
    "# df_tel['delta_energia'] ya existe\n",
    "\n",
    "# Calcular delta de tiempo en horas\n",
    "df_tel['delta_tiempo_h'] = df_tel.index.to_series().diff().dt.total_seconds() / 3600\n",
    "\n",
    "# Calcular potencia en kW: P = ΔE / Δt\n",
    "# Evitar división por cero\n",
    "df_tel['P_kW'] = np.where(\n",
    "    df_tel['delta_tiempo_h'] > 0,\n",
    "    df_tel['delta_energia'] / df_tel['delta_tiempo_h'],\n",
    "    0\n",
    ")\n",
    "\n",
    "# Suavizar potencia con media móvil de 5 segundos para mitigar cuantización\n",
    "df_tel['P_kW_suavizada'] = df_tel['P_kW'].rolling(window=5, center=True, min_periods=1).mean()\n",
    "\n",
    "# Mostrar resultados de las fórmulas aplicadas\n",
    "print(\"\\nPrimeros 10 valores calculados:\")\n",
    "print(df_tel[['energia_kwh', 'delta_energia', 'delta_tiempo_h', 'P_kW', 'P_kW_suavizada']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Potencia instantánea calculada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d904d0",
   "metadata": {},
   "source": [
    "PASO 2: Agregación a 1 minuto (telemetría)\n",
    "\n",
    "### Fórmulas de agregación\n",
    "\n",
    "Para cada minuto $m$:\n",
    "\n",
    "$$\\text{temp\\_mean}(m) = \\text{mean}(T)$$\n",
    "\n",
    "$$\\text{temp\\_p95}(m) = \\text{p95}(T)$$\n",
    "\n",
    "$$\\text{caudal\\_mean}(m) = \\text{mean}(q)$$\n",
    "\n",
    "$$\\text{P\\_kW\\_mean}(m) = \\text{mean}(P)$$\n",
    "\n",
    "$$\\%\\text{STOP}(m) = 100 \\cdot \\frac{\\#\\{i \\in m : \\text{estado}_i = \\text{STOP}\\}}{60}$$\n",
    "\n",
    "Estas series minuto servirán como base para KPIs horarios/por turno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e596a3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AGREGACIÓN A 1 MINUTO (TELEMETRÍA)\n",
      "============================================================\n",
      "\n",
      "Primeros registros:\n",
      "                           temp_mean  temp_p95  caudal_mean  P_kW_mean  \\\n",
      "2025-02-12 08:00:00+00:00  24.997999    25.672        0.000      1.104   \n",
      "2025-02-12 08:01:00+00:00  24.575001    24.756        0.000      1.155   \n",
      "2025-02-12 08:02:00+00:00  24.604000    24.876        0.000      1.141   \n",
      "2025-02-12 08:03:00+00:00  25.184000    25.523        0.000      1.167   \n",
      "2025-02-12 08:04:00+00:00  25.219000    25.513        0.000      1.208   \n",
      "2025-02-12 08:05:00+00:00  25.625000    25.908        0.000      1.118   \n",
      "2025-02-12 08:06:00+00:00  25.892000    26.101        0.000      1.199   \n",
      "2025-02-12 08:07:00+00:00  26.014999    26.525        0.000      1.208   \n",
      "2025-02-12 08:08:00+00:00  25.455000    25.874        8.709      3.881   \n",
      "2025-02-12 08:09:00+00:00  24.711000    24.880        9.011      3.837   \n",
      "\n",
      "                           segundos_stop  pct_STOP  \n",
      "2025-02-12 08:00:00+00:00             60    100.00  \n",
      "2025-02-12 08:01:00+00:00             60    100.00  \n",
      "2025-02-12 08:02:00+00:00             60    100.00  \n",
      "2025-02-12 08:03:00+00:00             60    100.00  \n",
      "2025-02-12 08:04:00+00:00             60    100.00  \n",
      "2025-02-12 08:05:00+00:00             60    100.00  \n",
      "2025-02-12 08:06:00+00:00             60    100.00  \n",
      "2025-02-12 08:07:00+00:00             60    100.00  \n",
      "2025-02-12 08:08:00+00:00              1      1.67  \n",
      "2025-02-12 08:09:00+00:00              0      0.00  \n",
      "\n",
      "✅ Agregación a 1 minuto completada\n"
     ]
    }
   ],
   "source": [
    "# PASO 10: Agregación a 1 minuto (telemetría)\n",
    "print(\"=\"*60)\n",
    "print(\"AGREGACIÓN A 1 MINUTO (TELEMETRÍA)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Crear agregaciones por minuto aplicando las fórmulas\n",
    "df_1min = df_tel.resample('1min').agg({\n",
    "    'temp_prod': ['mean', lambda x: x.quantile(0.95)],\n",
    "    'caudal': 'mean',\n",
    "    'P_kW': 'mean',\n",
    "    'estado': lambda x: (x == 'STOP').sum()\n",
    "}).round(3)\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_1min.columns = ['temp_mean', 'temp_p95', 'caudal_mean', 'P_kW_mean', 'segundos_stop']\n",
    "\n",
    "# Calcular %STOP\n",
    "df_1min['pct_STOP'] = ((df_1min['segundos_stop'] / 60) * 100).round(2)\n",
    "\n",
    "print(f\"\\nPrimeros registros:\")\n",
    "print(df_1min.head(10))\n",
    "\n",
    "print(f\"\\n✅ Agregación a 1 minuto completada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d84efa6",
   "metadata": {},
   "source": [
    "PASO 3: Clasificación de botellas por tolerancia de peso\n",
    "\n",
    "### Objetivo de masa por formato\n",
    "\n",
    "$$m_{\\text{obj}}(250) = 250\\text{ g}, \\quad m_{\\text{obj}}(500) = 500\\text{ g}$$\n",
    "\n",
    "### Criterio de tolerancia\n",
    "\n",
    "Con tolerancia típica del ±2%, una unidad está dentro de tolerancia si:\n",
    "\n",
    "$$|\\text{peso\\_lleno\\_g} - m_{\\text{obj}}(f)| \\leq 0.02 \\cdot m_{\\text{obj}}(f)$$\n",
    "\n",
    "Donde:\n",
    "- $\\text{peso\\_lleno\\_g}$ es el peso neto de la botella (en gramos)\n",
    "- $f$ es el formato (250 o 500)\n",
    "- $m_{\\text{obj}}(f)$ es la masa objetivo según el formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07e7a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'formato'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Master\\Python\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'formato'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m TOLERANCIA = \u001b[32m0.02\u001b[39m  \u001b[38;5;66;03m# ±2%\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Crear columna con masa objetivo según el formato de cada botella\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m df_pz[\u001b[33m'\u001b[39m\u001b[33mmasa_objetivo\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mdf_pz\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mformato\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m.map(MASA_OBJ)\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Calcular desviación absoluta respecto al objetivo\u001b[39;00m\n\u001b[32m     14\u001b[39m df_pz[\u001b[33m'\u001b[39m\u001b[33mdesviacion_abs\u001b[39m\u001b[33m'\u001b[39m] = np.abs(df_pz[\u001b[33m'\u001b[39m\u001b[33mpeso_neto\u001b[39m\u001b[33m'\u001b[39m] - df_pz[\u001b[33m'\u001b[39m\u001b[33mmasa_objetivo\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Master\\Python\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Master\\Python\\Proyecto\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'formato'"
     ]
    }
   ],
   "source": [
    "# PASO 11: Clasificación de botellas por tolerancia de peso\n",
    "print(\"=\"*60)\n",
    "print(\"CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Definir masa objetivo según formato\n",
    "MASA_OBJ = {250: 250.0, 500: 500.0}\n",
    "TOLERANCIA = 0.02  # ±2%\n",
    "\n",
    "# Crear columna con masa objetivo según el formato de cada botella\n",
    "df_pz['masa_objetivo'] = df_pz['formato_ml'].map(MASA_OBJ)\n",
    "\n",
    "# Calcular desviación absoluta respecto al objetivo\n",
    "df_pz['desviacion_abs'] = np.abs(df_pz['peso_neto'] - df_pz['masa_objetivo'])\n",
    "\n",
    "# Calcular límite de tolerancia (2% de la masa objetivo)\n",
    "df_pz['limite_tolerancia'] = TOLERANCIA * df_pz['masa_objetivo']\n",
    "\n",
    "# Clasificar: dentro_tolerancia = True si |peso_neto - m_obj| ≤ 0.02 * m_obj\n",
    "df_pz['dentro_tolerancia'] = df_pz['desviacion_abs'] <= df_pz['limite_tolerancia']\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"\\nPrimeros registros clasificados:\")\n",
    "print(df_pz[['id_botella', 'formato_ml', 'peso_neto', 'masa_objetivo', 'desviacion_abs', 'dentro_tolerancia']].head(10))\n",
    "\n",
    "print(f\"\\n✅ Clasificación completada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be036a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\n",
      "============================================================\n",
      "\n",
      "Columnas de df_pz:\n",
      "['ts_ciclo', 'id_botella', 'formato_ml', 'tiempo_ciclo_s', 'peso_lleno_g', 'ok_ng']\n",
      "\n",
      "Primeras filas de df_pz:\n",
      "                   ts_ciclo  id_botella  formato_ml  tiempo_ciclo_s  \\\n",
      "0 2025-02-12 08:08:03+00:00           1         500           483.0   \n",
      "1 2025-02-12 08:08:06+00:00           2         500             3.0   \n",
      "2 2025-02-12 08:08:09+00:00           3         500             3.0   \n",
      "3 2025-02-12 08:08:12+00:00           4         500             3.0   \n",
      "4 2025-02-12 08:08:15+00:00           5         500             3.0   \n",
      "\n",
      "   peso_lleno_g ok_ng  \n",
      "0        499.69    OK  \n",
      "1        498.71    OK  \n",
      "2        501.08    OK  \n",
      "3        503.04    OK  \n",
      "4        498.84    OK  \n"
     ]
    }
   ],
   "source": [
    "# PASO 11: Clasificación de botellas por tolerancia de peso\n",
    "print(\"=\"*60)\n",
    "print(\"CLASIFICACIÓN DE BOTELLAS POR TOLERANCIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Primero verificar las columnas disponibles\n",
    "print(f\"\\nColumnas de df_pz:\")\n",
    "print(df_pz.columns.tolist())\n",
    "print(f\"\\nPrimeras filas de df_pz:\")\n",
    "print(df_pz.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
